{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"3-building-deep-learning-models-with-keras.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMFGrawEOCdsedyonFBe7QI"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["# Building deep learning models with keras\r\n",">  In this chapter, you'll use the Keras library to build deep learning models for both regression and classification. You'll learn about the Specify-Compile-Fit workflow that you can use to make predictions, and by the end of the chapter, you'll have all the tools necessary to build deep neural networks.\r\n","\r\n","- toc: true \r\n","- badges: true\r\n","- comments: true\r\n","- author: Lucas Nunes\r\n","- categories: [Datacamp]\r\n","- image: images/datacamp/___"],"metadata":{"id":"f5FTJNcbC9gb"}},{"cell_type":"markdown","source":["> Note: This is a summary of the course's chapter 3 exercises \"Introduction to Deep Learning in Python\" at datacamp. <br>[Github repo](https://github.com/lnunesAI/Datacamp/) / [Course link](https://www.datacamp.com/tracks/machine-learning-scientist-with-python)"],"metadata":{}},{"cell_type":"code","execution_count":39,"source":["import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","plt.rcParams['figure.figsize'] = (8, 8)\r\n","\r\n","# Import necessary modules\r\n","import keras\r\n","from keras.layers import Dense\r\n","from keras.models import Sequential\r\n","from keras.utils import to_categorical"],"outputs":[],"metadata":{"id":"7SbXqsjxFOUG","executionInfo":{"status":"ok","timestamp":1613227415059,"user_tz":180,"elapsed":575,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["## Creating a keras model\r\n"],"metadata":{"id":"UvrKEMkeEF2g"}},{"cell_type":"markdown","source":["### Understanding your data"],"metadata":{"id":"Ho1eZTss8AvH"}},{"cell_type":"markdown","source":["<div class=\"\"><p>You will soon start building models in Keras to predict wages based on various professional and demographic factors. Before you start building a model, it's good to understand your data by performing some exploratory analysis.</p>\r\n","<p>The data is pre-loaded into a pandas DataFrame called <code>df</code>.  Use the <code>.head()</code> and <code>.describe()</code> methods in the IPython Shell for a quick overview of the DataFrame.</p>\r\n","<p>The target variable you'll be predicting is <code>wage_per_hour</code>. Some of the predictor variables are binary indicators, where a value of 1 represents <code>True</code>, and 0 represents <code>False</code>.</p>\r\n","<p>Of the 9 predictor variables in the DataFrame, how many are binary indicators? The min and max values as shown by <code>.describe()</code> will be informative here.\r\n","How many binary indicator predictors are there?</p></div>"],"metadata":{"id":"qNtQYWhfjmIV"}},{"cell_type":"code","execution_count":19,"source":["df = pd.read_csv('https://github.com/lnunesAI/Datacamp/raw/main/2-machine-learning-scientist-with-python/15-introduction-to-deep-learning-in-python/datasets/wages_534x10.csv')"],"outputs":[],"metadata":{"id":"1QUZo1RHnpnd","executionInfo":{"status":"ok","timestamp":1613224575152,"user_tz":180,"elapsed":614,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"code","execution_count":21,"source":["df.describe()"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>wage_per_hour</th>\n","      <th>union</th>\n","      <th>education_yrs</th>\n","      <th>experience_yrs</th>\n","      <th>age</th>\n","      <th>female</th>\n","      <th>marr</th>\n","      <th>south</th>\n","      <th>manufacturing</th>\n","      <th>construction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>534.000000</td>\n","      <td>534.000000</td>\n","      <td>534.000000</td>\n","      <td>534.000000</td>\n","      <td>534.000000</td>\n","      <td>534.000000</td>\n","      <td>534.000000</td>\n","      <td>534.000000</td>\n","      <td>534.000000</td>\n","      <td>534.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>9.024064</td>\n","      <td>0.179775</td>\n","      <td>13.018727</td>\n","      <td>17.822097</td>\n","      <td>36.833333</td>\n","      <td>0.458801</td>\n","      <td>0.655431</td>\n","      <td>0.292135</td>\n","      <td>0.185393</td>\n","      <td>0.044944</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>5.139097</td>\n","      <td>0.384360</td>\n","      <td>2.615373</td>\n","      <td>12.379710</td>\n","      <td>11.726573</td>\n","      <td>0.498767</td>\n","      <td>0.475673</td>\n","      <td>0.455170</td>\n","      <td>0.388981</td>\n","      <td>0.207375</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>0.000000</td>\n","      <td>18.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>5.250000</td>\n","      <td>0.000000</td>\n","      <td>12.000000</td>\n","      <td>8.000000</td>\n","      <td>28.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>7.780000</td>\n","      <td>0.000000</td>\n","      <td>12.000000</td>\n","      <td>15.000000</td>\n","      <td>35.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>11.250000</td>\n","      <td>0.000000</td>\n","      <td>15.000000</td>\n","      <td>26.000000</td>\n","      <td>44.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>44.500000</td>\n","      <td>1.000000</td>\n","      <td>18.000000</td>\n","      <td>55.000000</td>\n","      <td>64.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       wage_per_hour       union  ...  manufacturing  construction\n","count     534.000000  534.000000  ...     534.000000    534.000000\n","mean        9.024064    0.179775  ...       0.185393      0.044944\n","std         5.139097    0.384360  ...       0.388981      0.207375\n","min         1.000000    0.000000  ...       0.000000      0.000000\n","25%         5.250000    0.000000  ...       0.000000      0.000000\n","50%         7.780000    0.000000  ...       0.000000      0.000000\n","75%        11.250000    0.000000  ...       0.000000      0.000000\n","max        44.500000    1.000000  ...       1.000000      1.000000\n","\n","[8 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":21}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"EWjRk9VRrXpn","executionInfo":{"status":"ok","timestamp":1613224584165,"user_tz":180,"elapsed":587,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"3b50953f-cee2-4e15-94ec-6dfa3cba0865"}},{"cell_type":"markdown","source":["<pre>\r\n","Possible Answers\r\n","\r\n","0.\r\n","\r\n","5.\r\n","\r\n","<b>6.</b>\r\n","\r\n","</pre>"],"metadata":{"id":"60aSIfZvrWDU"}},{"cell_type":"markdown","source":["**There are 6 binary indicators.**"],"metadata":{"id":"RmsZvKlZkRkR"}},{"cell_type":"markdown","source":["### Specifying a model"],"metadata":{"id":"Gnp8CtcKsh6F"}},{"cell_type":"markdown","source":["<div class=\"\"><p>Now you'll get to work with your first model in Keras, and will immediately be able to run more complex neural network models on larger datasets compared to the first two chapters.</p>\r\n","<p>To start, you'll take the skeleton of a neural network and add a hidden layer and an output layer. You'll then fit that model and see Keras do the optimization so your model continually gets better.</p>\r\n","<p>As a start, you'll predict workers wages based on characteristics like their industry, education and level of experience.  You can find the dataset in a pandas dataframe called <code>df</code>.  For convenience, everything in <code>df</code> except for the target has been converted to a NumPy matrix called <code>predictors</code>. The target, <code>wage_per_hour</code>, is available as a NumPy matrix called <code>target</code>.</p>\r\n","<p>For all exercises in this chapter, we've imported the <code>Sequential</code> model constructor, the <code>Dense</code> layer constructor, and pandas.</p></div>"],"metadata":{"id":"yW3pxAzBsk3X"}},{"cell_type":"code","execution_count":25,"source":["predictors = df.iloc[:, 1:].to_numpy()\r\n","target = df.iloc[:, 0].to_numpy()"],"outputs":[],"metadata":{"id":"v7lY3QaWtN6i","executionInfo":{"status":"ok","timestamp":1613225090969,"user_tz":180,"elapsed":617,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["Instrutions\r\n","<ul>\r\n","<li>Store the number of columns in the <code>predictors</code> data to <code>n_cols</code>. This has been done for you.</li>\r\n","<li>Start by creating a <code>Sequential</code> model called <code>model</code>.</li>\r\n","<li>Use the <code>.add()</code> method on <code>model</code> to add a <code>Dense</code> layer.<ul>\r\n","<li>Add <code>50</code> units, specify <code>activation='relu'</code>, and the <code>input_shape</code> parameter to be the tuple <code>(n_cols,)</code> which means it has <code>n_cols</code> items in each row of data, and any number of rows of data are acceptable as inputs.</li></ul></li>\r\n","<li>Add another <code>Dense</code> layer. This should have <code>32</code> units and a <code>'relu'</code> activation.</li>\r\n","<li>Finally, add an output layer, which is a <code>Dense</code> layer with a single node. Don't use any activation function here.</li>\r\n","</ul>"],"metadata":{"id":"wjoBxO_Fso2v"}},{"cell_type":"code","execution_count":26,"source":["# Import necessary modules\r\n","import keras\r\n","from keras.layers import Dense\r\n","from keras.models import Sequential\r\n","\r\n","# Save the number of columns in predictors: n_cols\r\n","n_cols = predictors.shape[1]\r\n","\r\n","# Set up the model: model\r\n","model = Sequential()\r\n","\r\n","# Add the first layer\r\n","model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\r\n","\r\n","# Add the second layer\r\n","model.add(Dense(32, activation='relu'))\r\n","\r\n","# Add the output layer\r\n","model.add(Dense(1))"],"outputs":[],"metadata":{"id":"EwFZSe49tEjN","executionInfo":{"status":"ok","timestamp":1613225095211,"user_tz":180,"elapsed":2909,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["**Now that you've specified the model, the next step is to compile it.**"],"metadata":{"id":"1Wq3T0PDtGQH"}},{"cell_type":"markdown","source":["## Compiling and fitting a model"],"metadata":{"id":"05kctgCktaAW"}},{"cell_type":"markdown","source":["### Compiling the model"],"metadata":{"id":"jvhJrGH9uUKn"}},{"cell_type":"markdown","source":["<div class=\"\"><p>You're now going to compile the model you specified earlier. To compile the model, you need to specify the optimizer and loss function to use. In the video, Dan mentioned that the Adam optimizer is an excellent choice. You can read more about it as well as other keras optimizers <a href=\"https://keras.io/optimizers/#adam\" target=\"_blank\" rel=\"noopener noreferrer\">here</a>, and if you are really curious to learn more, you can read the <a href=\"https://arxiv.org/abs/1412.6980v8\" target=\"_blank\" rel=\"noopener noreferrer\">original paper</a> that introduced the Adam optimizer.</p>\r\n","<p>In this exercise, you'll use the Adam optimizer and the mean squared error loss function. Go for it!</p></div>"],"metadata":{"id":"Nsn9TPEMuXiA"}},{"cell_type":"markdown","source":["Instructions\r\n","<li>Compile the model using <code>model.compile()</code>.  Your <code>optimizer</code> should be <code>'adam'</code> and the <code>loss</code> should be <code>'mean_squared_error'</code>.</li>"],"metadata":{"id":"kFB0SryBuZW4"}},{"cell_type":"code","execution_count":27,"source":["# Compile the model\r\n","model.compile(optimizer='adam', loss='mean_squared_error')\r\n","\r\n","# Verify that model contains information from compiling\r\n","print(\"Loss function: \" + model.loss)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Loss function: mean_squared_error\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wv23x3Kkuq78","executionInfo":{"status":"ok","timestamp":1613225465097,"user_tz":180,"elapsed":618,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"8de72042-afca-49c7-a6dd-bf037e646197"}},{"cell_type":"markdown","source":["**all that's left now is to fit the model!**"],"metadata":{"id":"D5JjUQV9uz_p"}},{"cell_type":"markdown","source":["### Fitting the model"],"metadata":{"id":"qOq0nzOmu2Fa"}},{"cell_type":"markdown","source":["<p>You're at the most fun part. You'll now fit the model. Recall that the data to be used as predictive features is loaded in a NumPy matrix called <code>predictors</code> and the data to be predicted is stored in a NumPy matrix called <code>target</code>. Your <code>model</code> is pre-written and it has been compiled with the code from the previous exercise.</p>"],"metadata":{"id":"6S_Rp6vLu5I6"}},{"cell_type":"markdown","source":["Instructions\r\n","<li>Fit the <code>model</code>.  Remember that the first argument is the predictive features (<code>predictors</code>), and the data to be predicted (<code>target</code>) is the second argument.</li>"],"metadata":{"id":"SvraQjnBu6pq"}},{"cell_type":"code","execution_count":31,"source":["# Fit the model\r\n","model.fit(predictors, target, epochs=10);"],"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","17/17 [==============================] - 0s 1ms/step - loss: 19.8993\n","Epoch 2/10\n","17/17 [==============================] - 0s 2ms/step - loss: 19.9013\n","Epoch 3/10\n","17/17 [==============================] - 0s 1ms/step - loss: 20.1189\n","Epoch 4/10\n","17/17 [==============================] - 0s 2ms/step - loss: 20.2880\n","Epoch 5/10\n","17/17 [==============================] - 0s 1ms/step - loss: 20.0484\n","Epoch 6/10\n","17/17 [==============================] - 0s 1ms/step - loss: 20.0449\n","Epoch 7/10\n","17/17 [==============================] - 0s 1ms/step - loss: 19.8863\n","Epoch 8/10\n","17/17 [==============================] - 0s 1ms/step - loss: 19.5427\n","Epoch 9/10\n","17/17 [==============================] - 0s 1ms/step - loss: 19.4669\n","Epoch 10/10\n","17/17 [==============================] - 0s 1ms/step - loss: 19.4366\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4d5xsZJvB2W","executionInfo":{"status":"ok","timestamp":1613225599958,"user_tz":180,"elapsed":846,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"aaf1a134-2ad6-4aa6-cb1a-42162e795319"}},{"cell_type":"markdown","source":["**You now know how to specify, compile, and fit a deep learning model using keras!**"],"metadata":{"id":"lgtRx4HAvNAv"}},{"cell_type":"markdown","source":["## Classification models"],"metadata":{"id":"jvK1UIpgvYES"}},{"cell_type":"markdown","source":["### Understanding your classification data"],"metadata":{"id":"7ubaP80Zz30J"}},{"cell_type":"markdown","source":["<div class=\"\"><p>Now you will start modeling with a new dataset for a classification problem. This data includes information about passengers on the Titanic.  You will use predictors such as <code>age</code>, <code>fare</code> and where each passenger embarked from to predict who will survive.  This data is from <a href=\"https://www.kaggle.com/c/titanic\" target=\"_blank\" rel=\"noopener noreferrer\">a tutorial on data science competitions</a>.  Look <a href=\"https://www.kaggle.com/c/titanic/data\" target=\"_blank\" rel=\"noopener noreferrer\">here</a> for descriptions of the features.</p>\r\n","<p>The data is pre-loaded in a pandas DataFrame called <code>df</code>.</p>\r\n","<p>It's smart to review the maximum and minimum values of each variable to ensure the data isn't misformatted or corrupted.  What was the maximum age of passengers on the Titanic? Use the <code>.describe()</code> method in the IPython Shell to answer this question.</p></div>"],"metadata":{"id":"1z4g_Q4Fz-yi"}},{"cell_type":"code","execution_count":42,"source":["df = pd.read_csv('https://github.com/lnunesAI/Datacamp/raw/main/2-machine-learning-scientist-with-python/15-introduction-to-deep-learning-in-python/datasets/titanic_891x11.csv')"],"outputs":[],"metadata":{"id":"-xiSJbpE01QA","executionInfo":{"status":"ok","timestamp":1613227429343,"user_tz":180,"elapsed":805,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["<pre>\r\n","Possible Answers\r\n","\r\n","29.699.\r\n","\r\n","<b>80.</b>\r\n","\r\n","891.\r\n","\r\n","It is not listed.\r\n","\r\n","</pre>"],"metadata":{"id":"Jr3He4ob0BDD"}},{"cell_type":"code","execution_count":33,"source":["df.describe()"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>survived</th>\n","      <th>pclass</th>\n","      <th>age</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>fare</th>\n","      <th>male</th>\n","      <th>embarked_from_cherbourg</th>\n","      <th>embarked_from_queenstown</th>\n","      <th>embarked_from_southampton</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.383838</td>\n","      <td>2.308642</td>\n","      <td>29.699118</td>\n","      <td>0.523008</td>\n","      <td>0.381594</td>\n","      <td>32.204208</td>\n","      <td>0.647587</td>\n","      <td>0.188552</td>\n","      <td>0.086420</td>\n","      <td>0.722783</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.486592</td>\n","      <td>0.836071</td>\n","      <td>13.002015</td>\n","      <td>1.102743</td>\n","      <td>0.806057</td>\n","      <td>49.693429</td>\n","      <td>0.477990</td>\n","      <td>0.391372</td>\n","      <td>0.281141</td>\n","      <td>0.447876</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.420000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>22.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.910400</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>29.699118</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>14.454200</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>35.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>31.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>80.000000</td>\n","      <td>8.000000</td>\n","      <td>6.000000</td>\n","      <td>512.329200</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         survived  ...  embarked_from_southampton\n","count  891.000000  ...                 891.000000\n","mean     0.383838  ...                   0.722783\n","std      0.486592  ...                   0.447876\n","min      0.000000  ...                   0.000000\n","25%      0.000000  ...                   0.000000\n","50%      0.000000  ...                   1.000000\n","75%      1.000000  ...                   1.000000\n","max      1.000000  ...                   1.000000\n","\n","[8 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":33}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"5efjvgRh03m8","executionInfo":{"status":"ok","timestamp":1613227069110,"user_tz":180,"elapsed":619,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"b50a31c5-9851-436b-cad3-f17e37d0c6d5"}},{"cell_type":"markdown","source":["**The maximum age in the data is 80.**"],"metadata":{"id":"DJRs57dr0bwr"}},{"cell_type":"markdown","source":["### Last steps in classification models"],"metadata":{"id":"nt0BXT7y08WM"}},{"cell_type":"markdown","source":["<div class=\"\"><p>You'll now create a classification model using the titanic dataset, which has been pre-loaded into a DataFrame called <code>df</code>. You'll take information about the passengers and predict which ones survived. </p>\r\n","<p>The predictive variables are stored in a NumPy array <code>predictors</code>. The target to predict is in <code>df.survived</code>, though you'll have to manipulate it for keras. The number of predictive features is stored in <code>n_cols</code>. </p>\r\n","<p>Here, you'll use the <code>'sgd'</code> optimizer, which stands for <a href=\"https://en.wikipedia.org/wiki/Stochastic_gradient_descent\" target=\"_blank\" rel=\"noopener noreferrer\">Stochastic Gradient Descent</a>. You'll learn more about this in the next chapter!</p></div>"],"metadata":{"id":"6i2SYP6l1Ame"}},{"cell_type":"code","execution_count":57,"source":["predictors = df.iloc[:, 1:].astype(np.float32).to_numpy()\r\n","n_cols = predictors.shape[1]"],"outputs":[],"metadata":{"id":"v9TBuQ4a12nG","executionInfo":{"status":"ok","timestamp":1613227600074,"user_tz":180,"elapsed":556,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Convert <code>df.survived</code> to a categorical variable using the <code>to_categorical()</code> function.</li>\r\n","<li>Specify a <code>Sequential</code> model called <code>model</code>.</li>\r\n","<li>Add a <code>Dense</code> layer with <code>32</code> nodes. Use <code>'relu'</code> as the <code>activation</code> and <code>(n_cols,)</code> as the <code>input_shape</code>.</li>\r\n","<li>Add the <code>Dense</code> output layer. Because there are two outcomes, it should have 2 units, and because it is a classification model, the <code>activation</code> should be <code>'softmax'</code>. </li>\r\n","<li>Compile the model, using <code>'sgd'</code> as the <code>optimizer</code>, <code>'categorical_crossentropy'</code> as the loss function, and <code>metrics=['accuracy']</code> to see the accuracy (what fraction of predictions were correct) at the end of each epoch.</li>\r\n","<li>Fit the model using the <code>predictors</code> and the <code>target</code>.</li>\r\n","</ul>"],"metadata":{"id":"GMlDZYZ81CyX"}},{"cell_type":"code","execution_count":63,"source":["# Convert the target to categorical: target\r\n","target = to_categorical(df.survived)\r\n","\r\n","# Set up the model\r\n","model = Sequential()\r\n","\r\n","# Add the first layer\r\n","model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\r\n","\r\n","# Add the output layer\r\n","model.add(Dense(2, activation='softmax'))\r\n","\r\n","# Compile the model\r\n","model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\r\n","\r\n","# Fit the model\r\n","model.fit(predictors, target, epochs=10);"],"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","28/28 [==============================] - 0s 1ms/step - loss: 4.7389 - accuracy: 0.5953\n","Epoch 2/10\n","28/28 [==============================] - 0s 1ms/step - loss: 1.1958 - accuracy: 0.6005\n","Epoch 3/10\n","28/28 [==============================] - 0s 1ms/step - loss: 0.7414 - accuracy: 0.6692\n","Epoch 4/10\n","28/28 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 0.6394\n","Epoch 5/10\n","28/28 [==============================] - 0s 1ms/step - loss: 0.6003 - accuracy: 0.6915\n","Epoch 6/10\n","28/28 [==============================] - 0s 1ms/step - loss: 0.6625 - accuracy: 0.6653\n","Epoch 7/10\n","28/28 [==============================] - 0s 1ms/step - loss: 0.6033 - accuracy: 0.6811\n","Epoch 8/10\n","28/28 [==============================] - 0s 1ms/step - loss: 0.6292 - accuracy: 0.6707\n","Epoch 9/10\n","28/28 [==============================] - 0s 1ms/step - loss: 0.6127 - accuracy: 0.6875\n","Epoch 10/10\n","28/28 [==============================] - 0s 1ms/step - loss: 0.6097 - accuracy: 0.6935\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2XxAOYk81y0b","executionInfo":{"status":"ok","timestamp":1613228201978,"user_tz":180,"elapsed":1223,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"d366eb56-e0fd-4f77-d4db-036351aa3c1a"}},{"cell_type":"markdown","source":["**This simple model is generating an accuracy of 68!**"],"metadata":{"id":"um8-o5Ha2sC-"}},{"cell_type":"markdown","source":["## Using models"],"metadata":{"id":"X_5X0JWx3Cjk"}},{"cell_type":"markdown","source":["### Making predictions"],"metadata":{"id":"7IHP1ec335rE"}},{"cell_type":"markdown","source":["<div class=\"\"><p>The trained network from your previous coding exercise is now stored as <code>model</code>. New data to make predictions is stored in a NumPy array as <code>pred_data</code>.  Use <code>model</code> to make predictions on your new data.</p>\r\n","<p>In this exercise, your predictions will be probabilities, which is the most common way for data scientists to communicate their predictions to colleagues.</p></div>"],"metadata":{"id":"ugW_CGhc38zZ"}},{"cell_type":"code","execution_count":74,"source":["#@title â € { display-mode: \"form\" }\r\n","pred_data = np.array([[2, 34.0, 0, 0, 13.0, 1, False, 0, 0, 1],\r\n","       [2, 31.0, 1, 1, 26.25, 0, False, 0, 0, 1],\r\n","       [1, 11.0, 1, 2, 120.0, 1, False, 0, 0, 1],\r\n","       [3, 0.42, 0, 1, 8.5167, 1, False, 1, 0, 0],\r\n","       [3, 27.0, 0, 0, 6.975, 1, False, 0, 0, 1],\r\n","       [3, 31.0, 0, 0, 7.775, 1, False, 0, 0, 1],\r\n","       [1, 39.0, 0, 0, 0.0, 1, False, 0, 0, 1],\r\n","       [3, 18.0, 0, 0, 7.775, 0, False, 0, 0, 1],\r\n","       [2, 39.0, 0, 0, 13.0, 1, False, 0, 0, 1],\r\n","       [1, 33.0, 1, 0, 53.1, 0, False, 0, 0, 1],\r\n","       [3, 26.0, 0, 0, 7.8875, 1, False, 0, 0, 1],\r\n","       [3, 39.0, 0, 0, 24.15, 1, False, 0, 0, 1],\r\n","       [2, 35.0, 0, 0, 10.5, 1, False, 0, 0, 1],\r\n","       [3, 6.0, 4, 2, 31.275, 0, False, 0, 0, 1],\r\n","       [3, 30.5, 0, 0, 8.05, 1, False, 0, 0, 1],\r\n","       [1, 29.69911764705882, 0, 0, 0.0, 1, True, 0, 0, 1],\r\n","       [3, 23.0, 0, 0, 7.925, 0, False, 0, 0, 1],\r\n","       [2, 31.0, 1, 1, 37.0042, 1, False, 1, 0, 0],\r\n","       [3, 43.0, 0, 0, 6.45, 1, False, 0, 0, 1],\r\n","       [3, 10.0, 3, 2, 27.9, 1, False, 0, 0, 1],\r\n","       [1, 52.0, 1, 1, 93.5, 0, False, 0, 0, 1],\r\n","       [3, 27.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\r\n","       [1, 38.0, 0, 0, 0.0, 1, False, 0, 0, 1],\r\n","       [3, 27.0, 0, 1, 12.475, 0, False, 0, 0, 1],\r\n","       [3, 2.0, 4, 1, 39.6875, 1, False, 0, 0, 1],\r\n","       [3, 29.69911764705882, 0, 0, 6.95, 1, True, 0, 1, 0],\r\n","       [3, 29.69911764705882, 0, 0, 56.4958, 1, True, 0, 0, 1],\r\n","       [2, 1.0, 0, 2, 37.0042, 1, False, 1, 0, 0],\r\n","       [3, 29.69911764705882, 0, 0, 7.75, 1, True, 0, 1, 0],\r\n","       [1, 62.0, 0, 0, 80.0, 0, False, 0, 0, 0],\r\n","       [3, 15.0, 1, 0, 14.4542, 0, False, 1, 0, 0],\r\n","       [2, 0.83, 1, 1, 18.75, 1, False, 0, 0, 1],\r\n","       [3, 29.69911764705882, 0, 0, 7.2292, 1, True, 1, 0, 0],\r\n","       [3, 23.0, 0, 0, 7.8542, 1, False, 0, 0, 1],\r\n","       [3, 18.0, 0, 0, 8.3, 1, False, 0, 0, 1],\r\n","       [1, 39.0, 1, 1, 83.1583, 0, False, 1, 0, 0],\r\n","       [3, 21.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\r\n","       [3, 29.69911764705882, 0, 0, 8.05, 1, True, 0, 0, 1],\r\n","       [3, 32.0, 0, 0, 56.4958, 1, False, 0, 0, 1],\r\n","       [1, 29.69911764705882, 0, 0, 29.7, 1, True, 1, 0, 0],\r\n","       [3, 20.0, 0, 0, 7.925, 1, False, 0, 0, 1],\r\n","       [2, 16.0, 0, 0, 10.5, 1, False, 0, 0, 1],\r\n","       [1, 30.0, 0, 0, 31.0, 0, False, 1, 0, 0],\r\n","       [3, 34.5, 0, 0, 6.4375, 1, False, 1, 0, 0],\r\n","       [3, 17.0, 0, 0, 8.6625, 1, False, 0, 0, 1],\r\n","       [3, 42.0, 0, 0, 7.55, 1, False, 0, 0, 1],\r\n","       [3, 29.69911764705882, 8, 2, 69.55, 1, True, 0, 0, 1],\r\n","       [3, 35.0, 0, 0, 7.8958, 1, False, 1, 0, 0],\r\n","       [2, 28.0, 0, 1, 33.0, 1, False, 0, 0, 1],\r\n","       [1, 29.69911764705882, 1, 0, 89.1042, 0, True, 1, 0, 0],\r\n","       [3, 4.0, 4, 2, 31.275, 1, False, 0, 0, 1],\r\n","       [3, 74.0, 0, 0, 7.775, 1, False, 0, 0, 1],\r\n","       [3, 9.0, 1, 1, 15.2458, 0, False, 1, 0, 0],\r\n","       [1, 16.0, 0, 1, 39.4, 0, False, 0, 0, 1],\r\n","       [2, 44.0, 1, 0, 26.0, 0, False, 0, 0, 1],\r\n","       [3, 18.0, 0, 1, 9.35, 0, False, 0, 0, 1],\r\n","       [1, 45.0, 1, 1, 164.8667, 0, False, 0, 0, 1],\r\n","       [1, 51.0, 0, 0, 26.55, 1, False, 0, 0, 1],\r\n","       [3, 24.0, 0, 3, 19.2583, 0, False, 1, 0, 0],\r\n","       [3, 29.69911764705882, 0, 0, 7.2292, 1, True, 1, 0, 0],\r\n","       [3, 41.0, 2, 0, 14.1083, 1, False, 0, 0, 1],\r\n","       [2, 21.0, 1, 0, 11.5, 1, False, 0, 0, 1],\r\n","       [1, 48.0, 0, 0, 25.9292, 0, False, 0, 0, 1],\r\n","       [3, 29.69911764705882, 8, 2, 69.55, 0, True, 0, 0, 1],\r\n","       [2, 24.0, 0, 0, 13.0, 1, False, 0, 0, 1],\r\n","       [2, 42.0, 0, 0, 13.0, 0, False, 0, 0, 1],\r\n","       [2, 27.0, 1, 0, 13.8583, 0, False, 1, 0, 0],\r\n","       [1, 31.0, 0, 0, 50.4958, 1, False, 0, 0, 1],\r\n","       [3, 29.69911764705882, 0, 0, 9.5, 1, True, 0, 0, 1],\r\n","       [3, 4.0, 1, 1, 11.1333, 1, False, 0, 0, 1],\r\n","       [3, 26.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\r\n","       [1, 47.0, 1, 1, 52.5542, 0, False, 0, 0, 1],\r\n","       [1, 33.0, 0, 0, 5.0, 1, False, 0, 0, 1],\r\n","       [3, 47.0, 0, 0, 9.0, 1, False, 0, 0, 1],\r\n","       [2, 28.0, 1, 0, 24.0, 0, False, 1, 0, 0],\r\n","       [3, 15.0, 0, 0, 7.225, 0, False, 1, 0, 0],\r\n","       [3, 20.0, 0, 0, 9.8458, 1, False, 0, 0, 1],\r\n","       [3, 19.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\r\n","       [3, 29.69911764705882, 0, 0, 7.8958, 1, True, 0, 0, 1],\r\n","       [1, 56.0, 0, 1, 83.1583, 0, False, 1, 0, 0],\r\n","       [2, 25.0, 0, 1, 26.0, 0, False, 0, 0, 1],\r\n","       [3, 33.0, 0, 0, 7.8958, 1, False, 0, 0, 1],\r\n","       [3, 22.0, 0, 0, 10.5167, 0, False, 0, 0, 1],\r\n","       [2, 28.0, 0, 0, 10.5, 1, False, 0, 0, 1],\r\n","       [3, 25.0, 0, 0, 7.05, 1, False, 0, 0, 1],\r\n","       [3, 39.0, 0, 5, 29.125, 0, False, 0, 1, 0],\r\n","       [2, 27.0, 0, 0, 13.0, 1, False, 0, 0, 1],\r\n","       [1, 19.0, 0, 0, 30.0, 0, False, 0, 0, 1],\r\n","       [3, 29.69911764705882, 1, 2, 23.45, 0, True, 0, 0, 1],\r\n","       [1, 26.0, 0, 0, 30.0, 1, False, 1, 0, 0],\r\n","       [3, 32.0, 0, 0, 7.75, 1, False, 0, 1, 0]], dtype=np.float32)"],"outputs":[],"metadata":{"id":"vmGxkoTS4op1","executionInfo":{"status":"ok","timestamp":1613228406586,"user_tz":180,"elapsed":835,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Create your predictions using the model's <code>.predict()</code> method on <code>pred_data</code>.</li>\r\n","<li>Use NumPy indexing to find the column corresponding to predicted probabilities of survival being True. This is the second <em>column</em> (index <code>1</code>) of <code>predictions</code>. Store the result in <code>predicted_prob_true</code> and print it.</li>\r\n","</ul>"],"metadata":{"id":"y5fOaquF3-pO"}},{"cell_type":"code","execution_count":75,"source":["# Calculate predictions: predictions\r\n","predictions = model.predict(pred_data)\r\n","\r\n","# Calculate predicted probability of survival: predicted_prob_true\r\n","predicted_prob_true = predictions[:,1]\r\n","\r\n","# print predicted_prob_true\r\n","print(predicted_prob_true)"],"outputs":[{"output_type":"stream","name":"stdout","text":["[0.3636128  0.4642847  0.89648247 0.44344747 0.27284613 0.24466737\n"," 0.05226173 0.38314727 0.31875077 0.59537274 0.32326803 0.3873374\n"," 0.28885946 0.43714145 0.26184428 0.07697893 0.35285476 0.54077506\n"," 0.10991497 0.471074   0.69401085 0.32706165 0.05579389 0.38805586\n"," 0.49784222 0.22459869 0.5780343  0.6327546  0.24931833 0.6614537\n"," 0.48113307 0.50135946 0.21434593 0.3414769  0.38206545 0.73016024\n"," 0.36361426 0.25401694 0.58288765 0.5114947  0.36100915 0.43345025\n"," 0.55804276 0.15186702 0.39526019 0.13278006 0.4971881  0.181598\n"," 0.5326694  0.80516404 0.4273352  0.01515844 0.5105397  0.62301004\n"," 0.39082706 0.40628543 0.96102506 0.38467184 0.46937194 0.21434593\n"," 0.28413895 0.3918298  0.41083246 0.5222768  0.40713668 0.31658205\n"," 0.38481817 0.5780905  0.3037875  0.4463112  0.32357866 0.589653\n"," 0.17968316 0.12169021 0.4738799  0.39387208 0.3878369  0.36846337\n"," 0.24905227 0.6689958  0.5308471  0.2218818  0.3914006  0.37333944\n"," 0.30684435 0.49534294 0.39389095 0.5524359  0.42888433 0.5375582\n"," 0.23354101]\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0xXkBEA4cYl","executionInfo":{"status":"ok","timestamp":1613228410855,"user_tz":180,"elapsed":582,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"bac4044a-3d03-4639-f41c-dd0f22c07a98"}},{"cell_type":"markdown","source":["**You're now ready to begin learning how to fine-tune your models.**"],"metadata":{"id":"UnCSEVPC4es4"}}]}