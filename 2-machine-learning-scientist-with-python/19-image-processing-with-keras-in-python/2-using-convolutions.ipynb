{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"2-using-convolutions.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOMNzIlV0r/BCENpepAxnSb"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["# Using Convolutions\r\n",">  Convolutions are the fundamental building blocks of convolutional neural networks. In this chapter, you will be introducted to convolutions and learn how they operate on image data. You will also see how you incorporate convolutions into Keras neural networks.\r\n","\r\n","- toc: true \r\n","- badges: true\r\n","- comments: true\r\n","- author: Lucas Nunes\r\n","- categories: [Datacamp]\r\n","- image: images/datacamp/___"],"metadata":{"id":"f5FTJNcbC9gb"}},{"cell_type":"markdown","source":["> Note: This is a summary of the course's chapter 2 exercises \"Image Processing with Keras in Python\" at datacamp. <br>[Github repo](https://github.com/lnunesAI/Datacamp/) / [Course link](https://www.datacamp.com/tracks/machine-learning-scientist-with-python)"],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","plt.rcParams['figure.figsize'] = (8, 8)\r\n","import tensorflow as tf"],"outputs":[],"metadata":{"id":"7SbXqsjxFOUG","executionInfo":{"status":"ok","timestamp":1614005042390,"user_tz":180,"elapsed":3331,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["## Convolutions"],"metadata":{"id":"UvrKEMkeEF2g"}},{"cell_type":"markdown","source":["### One dimensional convolutions"],"metadata":{"id":"Ho1eZTss8AvH"}},{"cell_type":"markdown","source":["<p>A convolution of an one-dimensional array with a kernel comprises of taking the kernel, sliding it along the array, multiplying it with the items in the array that overlap with the kernel in that location and summing this product.</p>"],"metadata":{"id":"PhhRGhlV57aT"}},{"cell_type":"markdown","source":["Instructions\r\n","<p>Multiply each window in the input array with the kernel and sum the multiplied result and allocate the result into the correct entry in the output array (<code>conv</code>).</p>"],"metadata":{"id":"_gN6WnKQ589r"}},{"cell_type":"code","execution_count":null,"source":["array = np.array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])\r\n","kernel = np.array([1, -1, 0])\r\n","conv = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\r\n","\r\n","# Output array\r\n","for ii in range(8):\r\n","    conv[ii] = (kernel * array[ii:ii+3]).sum()\r\n","\r\n","# Print conv\r\n","print(conv)"],"outputs":[{"output_type":"stream","name":"stdout","text":["[ 1 -1  1 -1  1 -1  1 -1  0  0]\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IOH7UfM76LZE","executionInfo":{"status":"ok","timestamp":1613916682535,"user_tz":180,"elapsed":520,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"299a4f22-f3a0-4d51-c60a-82e1b150626f"}},{"cell_type":"markdown","source":["**Notice that we've only multiplied the kernel with eight different positions**"],"metadata":{"id":"2Y84W1wD6PTg"}},{"cell_type":"markdown","source":["### Image convolutions"],"metadata":{"id":"wwKewOdR7mP-"}},{"cell_type":"markdown","source":["<p>The convolution of an image with a kernel summarizes a part of the image as the sum of the multiplication of that part of the image with the kernel. In this exercise, you will write the code that executes a convolution of an image with a kernel using Numpy. Given a black and white image that is stored in the variable <code>im</code>, write the operations inside the loop that would execute the convolution with the provided kernel.</p>"],"metadata":{"id":"vI_rtM5M7pis"}},{"cell_type":"code","execution_count":null,"source":["%%capture\r\n","!wget https://github.com/lnunesAI/Datacamp/raw/main/2-machine-learning-scientist-with-python/19-image-processing-with-keras-in-python/datasets/im.npz\r\n","im = np.load('im.npz')\r\n","im = im.f.arr_0"],"outputs":[],"metadata":{"id":"ityoDJus-EM8"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Select the right window from the image in each iteration and multiply this part of the image with the kernel.</li>\r\n","<li>Sum the result and allocate the sum to the correct entry in the output array (<code>results</code>).</li>\r\n","</ul>"],"metadata":{"id":"6zok1cDd7rd2"}},{"cell_type":"code","execution_count":null,"source":["kernel = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])\r\n","result = np.zeros(im.shape)\r\n","\r\n","# Output array\r\n","for ii in range(im.shape[0] - 3):\r\n","    for jj in range(im.shape[1] - 3):\r\n","        result[ii, jj] = (im[ii:ii+3, jj:jj+3] * kernel).sum()\r\n","\r\n","# Print result\r\n","print(result)"],"outputs":[{"output_type":"stream","name":"stdout","text":["[[2.68104586 2.95947725 2.84313735 ... 0.         0.         0.        ]\n"," [3.01830077 3.07058835 3.05098051 ... 0.         0.         0.        ]\n"," [2.95163405 3.09934652 3.20261449 ... 0.         0.         0.        ]\n"," ...\n"," [0.         0.         0.         ... 0.         0.         0.        ]\n"," [0.         0.         0.         ... 0.         0.         0.        ]\n"," [0.         0.         0.         ... 0.         0.         0.        ]]\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"icgIxrCZ8Hbz","executionInfo":{"status":"ok","timestamp":1613917347524,"user_tz":180,"elapsed":688,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"839231bf-71a5-4b11-d11d-5e916224a410"}},{"cell_type":"markdown","source":["### Defining image convolution kernels"],"metadata":{"id":"bN3F32RP-LHU"}},{"cell_type":"markdown","source":["<div class=\"\"><p>In the previous exercise, you wrote code that performs a convolution given an image and a kernel. This code is now stored in a function called <code>convolution()</code> that takes two inputs: <code>image</code> and <code>kernel</code> and produces the convolved image. In this exercise, you will be asked to define the kernel that finds a particular feature in the image. </p>\r\n","<p>For example, the following kernel finds a vertical line in images: </p>\r\n","<pre><code>np.array([[-1, 1, -1], \r\n","          [-1, 1, -1], \r\n","          [-1, 1, -1]])\r\n","</code></pre></div>"],"metadata":{"id":"0AXiw0mA-YXh"}},{"cell_type":"markdown","source":["Instructions 1/3\r\n","<p>Define a kernel that finds horizontal lines in images.</p>"],"metadata":{"id":"GmgoZCwe-bgH"}},{"cell_type":"code","execution_count":null,"source":["kernel = np.array([[-1, -1, -1], \r\n","                   [1, 1, 1],\r\n","                   [-1, -1, -1]])"],"outputs":[],"metadata":{"id":"wm8kdUR5_A92"}},{"cell_type":"markdown","source":["Instructions 2/3\r\n","<p>Define a kernel that finds a light spot surrounded by dark pixels.</p>"],"metadata":{"id":"exJDFJ8o-bgU"}},{"cell_type":"code","execution_count":null,"source":["kernel = np.array([[-1, -1, -1], \r\n","                   [-1, 1, -1],\r\n","                   [-1, -1, -1]])"],"outputs":[],"metadata":{"id":"fvrWnOm0_P8i"}},{"cell_type":"markdown","source":["Instructions 3/3\r\n","<p>Define a kernel that finds a dark spot surrounded by bright pixels.</p>"],"metadata":{"id":"LNt8rPjj-bgU"}},{"cell_type":"code","execution_count":null,"source":["kernel = np.array([[1, 1, 1], \r\n","                   [1, -1, 1],\r\n","                   [1, 1, 1]])"],"outputs":[],"metadata":{"id":"EyXslAL4_erW"}},{"cell_type":"markdown","source":["### Implementing image convolutions in Keras"],"metadata":{"id":"ndHxi8Dg_g2m"}},{"cell_type":"markdown","source":["### Convolutional network for image classification"],"metadata":{"id":"83EWKh0qEU97"}},{"cell_type":"markdown","source":["<p>Convolutional networks for classification are constructed from a sequence of convolutional layers (for image processing) and fully connected (<code>Dense</code>) layers  (for readout). In this exercise, you will construct a small convolutional network for classification of the data from the fashion dataset.</p>"],"metadata":{"id":"BvbTXrrbEa9V"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Add a <code>Conv2D</code> layer to construct the input layer of the network. Use a kernel size of 3 by 3. You can use the <code>img_rows</code> and <code>img_cols</code> objects available in your workspace to define the <code>input_shape</code> of this layer.</li>\r\n","<li>Add a <code>Flatten</code> layer to translate between the image processing and classification part of your network.</li>\r\n","<li>Add a <code>Dense</code> layer to classify the 3 different categories of clothing in the dataset.</li>\r\n","</ul>"],"metadata":{"id":"2teceWyoEcrd"}},{"cell_type":"code","execution_count":3,"source":["# Import the necessary components from Keras\r\n","from keras.models import Sequential\r\n","from keras.layers import Dense, Conv2D, Flatten\r\n","\r\n","img_rows, img_cols = 28, 28\r\n","\r\n","# Initialize the model object\r\n","model = Sequential()\r\n","\r\n","# Add a convolutional layer\r\n","model.add(Conv2D(10, kernel_size=3, activation='relu', \r\n","               input_shape=(img_rows, img_cols, 1)))\r\n","\r\n","# Flatten the output of the convolutional layer\r\n","model.add(Flatten())\r\n","# Add an output layer for the 3 categories\r\n","model.add(Dense(3, activation='softmax'))"],"outputs":[],"metadata":{"id":"-uWCuqSxE0U7","executionInfo":{"status":"ok","timestamp":1614005053205,"user_tz":180,"elapsed":1143,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["### Training a CNN to classify clothing types"],"metadata":{"id":"MNf2kLAjFApR"}},{"cell_type":"markdown","source":["<div class=\"\"><p>Before training a neural network it needs to be compiled with the right cost function, using the right optimizer. During compilation, you can also define metrics that the network calculates and reports in every epoch. Model fitting requires a training data set, together with the training labels to the network. </p>\r\n","<p>The Conv2D <code>model</code> you built in the previous exercise is available in your workspace.</p></div>"],"metadata":{"id":"npQeYv1QFDlB"}},{"cell_type":"code","execution_count":2,"source":["%%capture\r\n","!wget https://github.com/lnunesAI/Datacamp/raw/main/2-machine-learning-scientist-with-python/19-image-processing-with-keras-in-python/datasets/fashion.h5\r\n","import h5py\r\n","h5f = h5py.File('fashion.h5','r')\r\n","train_data = h5f['train_data'][:]\r\n","train_labels = h5f['train_labels'][:]\r\n","test_data = h5f['test_data'][:]\r\n","test_labels = h5f['test_labels'][:]\r\n","h5f.close()"],"outputs":[],"metadata":{"id":"MzvQArI0ISvI","executionInfo":{"status":"ok","timestamp":1614005047649,"user_tz":180,"elapsed":1734,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Compile the network using the <code>'adam'</code> optimizer and the <code>'categorical_crossentropy'</code> cost function. In the metrics list define that the network to report <code>'accuracy'</code>.</li>\r\n","<li>Fit the network on <code>train_data</code> and <code>train_labels</code>. Train for 3 epochs with a batch size of 10 images. In training, set aside 20% of the data as a validation set, using the <code>validation_split</code> keyword argument.</li>\r\n","</ul>"],"metadata":{"id":"Mn_4sEk_FFuh"}},{"cell_type":"code","execution_count":4,"source":["# Compile the model\r\n","model.compile(optimizer='adam',\r\n","              loss='categorical_crossentropy',\r\n","              metrics=['accuracy'])\r\n","\r\n","# Fit the model on a training set\r\n","model.fit(train_data, train_labels, \r\n","            validation_split=0.2,\r\n","          epochs=3, batch_size=10)"],"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","4/4 [==============================] - 1s 149ms/step - loss: 0.9888 - accuracy: 0.4500 - val_loss: 0.5594 - val_accuracy: 1.0000\n","Epoch 2/3\n","4/4 [==============================] - 0s 15ms/step - loss: 0.5267 - accuracy: 0.8667 - val_loss: 0.3285 - val_accuracy: 0.9000\n","Epoch 3/3\n","4/4 [==============================] - 0s 17ms/step - loss: 0.3250 - accuracy: 0.8367 - val_loss: 0.2548 - val_accuracy: 1.0000\n"]},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fe44ec224e0>"]},"metadata":{"tags":[]},"execution_count":4}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kj2HLQH2IL4f","executionInfo":{"status":"ok","timestamp":1614005059513,"user_tz":180,"elapsed":2344,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"fc505678-1365-4d9c-fff4-795d72d6c79b"}},{"cell_type":"markdown","source":["**Validation accuracy converges to 100%!**"],"metadata":{"id":"SP87-1m5Ijh7"}},{"cell_type":"markdown","source":["### Evaluating a CNN with test data"],"metadata":{"id":"iXTWJFwkIra_"}},{"cell_type":"markdown","source":["<p>To evaluate a trained neural network, you should provide a separate testing data set of labeled images. The <code>model</code> you fit in the previous exercise is available in your workspace.</p>"],"metadata":{"id":"TWz_sUi4Itx4"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Evaluate the data on a separate test set: <code>test_data</code> and <code>test_labels</code>. </li>\r\n","<li>Use the same batch size that was used for fitting (10 images per batch).</li>\r\n","</ul>"],"metadata":{"id":"hIN6Yu3hIvTZ"}},{"cell_type":"code","execution_count":5,"source":["# Evaluate the model on separate test data\r\n","model.evaluate(test_data, test_labels, batch_size=10)"],"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 16ms/step - loss: 0.2863 - accuracy: 0.9000\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.28630316257476807, 0.8999999761581421]"]},"metadata":{"tags":[]},"execution_count":5}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XldWnmg7I4zq","executionInfo":{"status":"ok","timestamp":1614005063464,"user_tz":180,"elapsed":886,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"7c4e6a53-3388-430a-db56-c85bb3350222"}},{"cell_type":"markdown","source":["**The first number in the output is the value of the cross-entropy loss, the second is the value of the accuracy. For this model, it's 100%!**"],"metadata":{"id":"JXFrj02pI9Wl"}},{"cell_type":"markdown","source":["## Tweaking your convolutions"],"metadata":{"id":"T_ggWqpVJC-X"}},{"cell_type":"markdown","source":["### Add padding to a CNN"],"metadata":{"id":"a5Fmd5HuWWjx"}},{"cell_type":"markdown","source":["<p>Padding allows a convolutional layer to retain the resolution of the input into this layer. This is done by adding zeros around the edges of the input image, so that the convolution kernel can overlap with the pixels on the edge of the image.</p>"],"metadata":{"id":"Xc9YD3XcWZTR"}},{"cell_type":"markdown","source":["Instructions\r\n","<p>Add a <code>Conv2D</code> layer and choose a padding such that the output has the same size as the input.</p>"],"metadata":{"id":"uuKe4rsiWa1B"}},{"cell_type":"code","execution_count":6,"source":["# Initialize the model\r\n","model = Sequential()\r\n","\r\n","# Add the convolutional layer\r\n","model.add(Conv2D(10, kernel_size=3, activation='relu', \r\n","                 input_shape=(img_rows, img_cols, 1), \r\n","                 padding='same'))\r\n","\r\n","# Feed into output layer\r\n","model.add(Flatten())\r\n","model.add(Dense(3, activation='softmax'))"],"outputs":[],"metadata":{"id":"cllvkLxHWrA2","executionInfo":{"status":"ok","timestamp":1614005067294,"user_tz":180,"elapsed":839,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["### Add strides to a convolutional network"],"metadata":{"id":"vebr4X9NW14Z"}},{"cell_type":"markdown","source":["<p>The size of the strides of the convolution kernel determines whether the kernel will skip over some of the pixels as it slides along the image. This affects the  size of the output because when strides are larger than one, the kernel will be centered on only some of the pixels.</p>"],"metadata":{"id":"rJvq7wntW4RS"}},{"cell_type":"markdown","source":["Instructions\r\n","<p>Construct a neural network with a <code>Conv2D</code> layer with strided convolutions that skips every other pixel.</p>"],"metadata":{"id":"y-VGBN-KW526"}},{"cell_type":"code","execution_count":7,"source":["# Initialize the model\r\n","model = Sequential()\r\n","\r\n","# Add the convolutional layer\r\n","model.add(Conv2D(10, kernel_size=3, activation='relu', \r\n","              input_shape=(img_rows, img_cols, 1), \r\n","              strides=2))\r\n","\r\n","# Feed into output layer\r\n","model.add(Flatten())\r\n","model.add(Dense(3, activation='softmax'))"],"outputs":[],"metadata":{"id":"-CJ2IqAzXHQK","executionInfo":{"status":"ok","timestamp":1614005069739,"user_tz":180,"elapsed":844,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["### Calculate the size of convolutional layer output"],"metadata":{"id":"ddZue0okXNKx"}},{"cell_type":"markdown","source":["<div class=\"\"><p>Zero padding and strides affect the size of the output of a convolution. </p>\r\n","<p>What is the size of the output for an input of size 256 by 256, with a kernel of size 4 by 4, padding of 1 and strides of 2?</p></div>"],"metadata":{"id":"AZfGGVo8XPqh"}},{"cell_type":"code","execution_count":null,"source":["(256-4+2*1)/2+1"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["128.0"]},"metadata":{"tags":[]},"execution_count":32}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eIaTYS9cXbS2","executionInfo":{"status":"ok","timestamp":1613924132280,"user_tz":180,"elapsed":493,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"790f8b1f-32c6-46df-b9a3-f14884f6c87a"}},{"cell_type":"markdown","source":["<pre>\r\n","Possible Answers\r\n","127\r\n","255\r\n","<b>128</b>\r\n","256\r\n","</pre>"],"metadata":{"id":"jjLoK0XiXSXL"}}]}