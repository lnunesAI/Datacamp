{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3-fine-tuning-your-model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMmp+GT1HwqtsIuIWVT2o2X"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"f5FTJNcbC9gb"},"source":["# Fine-tuning your model\r\n",">  Having trained your model, your next task is to evaluate its performance. In this chapter, you will learn about some of the other metrics available in scikit-learn that will allow you to assess your model's performance in a more nuanced manner. Next, learn to optimize your classification and regression models using hyperparameter tuning.\r\n","\r\n","- toc: true \r\n","- badges: true\r\n","- comments: true\r\n","- author: Lucas Nunes\r\n","- categories: [Datacamp]\r\n","- image: images/datacamp/01-supervised-learning-with-scikit-learn/3-fine-tuning-your-model.png"]},{"cell_type":"markdown","metadata":{"id":"M9teQ3m0OVYl"},"source":["> Note: This is a summary of the course's chapter 3 exercises \"Supervised Learning with scikit-learn\" at datacamp. <br>[Github repo](https://github.com/lnunesAI/Datacamp/) / [Course link](https://www.datacamp.com/courses/supervised-learning-with-scikit-learn)"]},{"cell_type":"code","metadata":{"id":"7SbXqsjxFOUG"},"source":["import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UvrKEMkeEF2g"},"source":["## How good is your model?"]},{"cell_type":"markdown","metadata":{"id":"XZ0g236e9vT8"},"source":["### Metrics for classification\r\n"]},{"cell_type":"markdown","metadata":{"id":"sqr-tufO9yni"},"source":["<div class=\"\"><p>In Chapter 1, you evaluated the performance of your k-NN classifier based on its accuracy. However, as Andy discussed, accuracy is not always an informative metric. In this exercise, you will dive more deeply into evaluating the performance of binary classifiers by computing a confusion matrix and generating a classification report. </p>\r\n","<p>You may have noticed in the video that the classification report consisted of three rows, and an additional <em>support</em> column. The <em>support</em> gives the number of samples of the true response that lie in that class - so in the video example, the support was the number of Republicans or Democrats in the test set on which the classification report was computed. The <em>precision</em>, <em>recall</em>, and <em>f1-score</em> columns, then, gave the respective metrics for that particular class.</p>\r\n","<p>Here, you'll work with the <a href=\"https://www.kaggle.com/uciml/pima-indians-diabetes-database\" target=\"_blank\" rel=\"noopener noreferrer\">PIMA Indians</a> dataset obtained from the UCI Machine Learning Repository. The goal is to predict whether or not a given female patient will contract diabetes based on features such as BMI, age, and number of pregnancies. Therefore, it is a binary classification problem. A target value of <code>0</code> indicates that the patient does <em>not</em> have diabetes, while a value of <code>1</code> indicates that the patient <em>does</em> have diabetes. As in Chapters 1 and 2, the dataset has been preprocessed to deal with missing values.</p>\r\n","<p>The dataset has been loaded into a DataFrame <code>df</code> and the feature and target variable arrays <code>X</code> and <code>y</code> have been created for you. In addition, <code>sklearn.model_selection.train_test_split</code> and <code>sklearn.neighbors.KNeighborsClassifier</code> have already been imported.</p>\r\n","<p>Your job is to train a k-NN classifier to the data and evaluate its performance by generating a confusion matrix and classification report.</p></div>"]},{"cell_type":"code","metadata":{"id":"wuwRGASPCiOK"},"source":["from sklearn.model_selection import train_test_split\r\n","from sklearn.neighbors import KNeighborsClassifier\r\n","\r\n","df = pd.read_csv('https://raw.githubusercontent.com/lnunesAI/Datacamp/main/2-machine-learning-scientist-with-python/1-supervised-learning-with-scikit-learn/datasets/diabetes.csv')\r\n","\r\n","X = df.iloc[:, :-1]\r\n","y = df.iloc[:, -1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FWLlVcv393p6"},"source":["Instructions\r\n","<ul>\r\n","<li>Import <code>classification_report</code> and <code>confusion_matrix</code> from <code>sklearn.metrics</code>.</li>\r\n","<li>Create training and testing sets with 40% of the data used for testing. Use a random state of <code>42</code>.</li>\r\n","<li>Instantiate a k-NN classifier with <code>6</code> neighbors, fit it to the training data, and predict the labels of the test set.</li>\r\n","<li>Compute and print the confusion matrix and classification report using the <code>confusion_matrix()</code> and <code>classification_report()</code> functions.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xyulfWtH-Fhx","executionInfo":{"status":"ok","timestamp":1611538797625,"user_tz":180,"elapsed":649,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"20248c1f-1913-406f-c229-94d079c9ccfa"},"source":["# Import necessary modules\r\n","from sklearn.metrics import confusion_matrix\r\n","from sklearn.metrics import classification_report\r\n","\r\n","# Create training and test set\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\r\n","\r\n","# Instantiate a k-NN classifier: knn\r\n","knn = knn = KNeighborsClassifier(n_neighbors=6)\r\n","\r\n","# Fit the classifier to the training data\r\n","knn.fit(X_train, y_train)\r\n","\r\n","# Predict the labels of the test data: y_pred\r\n","y_pred = knn.predict(X_test)\r\n","\r\n","# Generate the confusion matrix and classification report\r\n","print(confusion_matrix(y_test, y_pred))\r\n","print(classification_report(y_test, y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[176  30]\n"," [ 52  50]]\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.85      0.81       206\n","           1       0.62      0.49      0.55       102\n","\n","    accuracy                           0.73       308\n","   macro avg       0.70      0.67      0.68       308\n","weighted avg       0.72      0.73      0.72       308\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hmNmxVch-Nbw"},"source":["**By analyzing the confusion matrix and classification report, you can get a much better understanding of your classifier's performance.**"]},{"cell_type":"markdown","metadata":{"id":"w4PBmlg0DTwL"},"source":["## Logistic regression and the ROC curve"]},{"cell_type":"markdown","metadata":{"id":"az42MjvYDzYw"},"source":["### Building a logistic regression model"]},{"cell_type":"markdown","metadata":{"id":"uIyTLLP2D5NY"},"source":["<div class=\"\"><p>Time to build your first logistic regression model! As Hugo showed in the video, scikit-learn makes it very easy to try different models, since the Train-Test-Split/Instantiate/Fit/Predict paradigm applies to all classifiers and regressors - which are known in scikit-learn as 'estimators'. You'll see this now for yourself as you train a logistic regression model on exactly the same data as in the previous exercise. Will it outperform k-NN? There's only one way to find out! </p>\r\n","<p>The feature and target variable arrays <code>X</code> and <code>y</code> have been pre-loaded, and <code>train_test_split</code> has been imported for you from <code>sklearn.model_selection</code>.</p></div>"]},{"cell_type":"markdown","metadata":{"id":"ZO1mTBCSD7-v"},"source":["Instructions\r\n","<ul>\r\n","<li>Import:<ul>\r\n","<li><code>LogisticRegression</code> from <code>sklearn.linear_model</code>.</li>\r\n","<li><code>confusion_matrix</code> and <code>classification_report</code> from <code>sklearn.metrics</code>.</li></ul></li>\r\n","<li>Create training and test sets with 40% (or <code>0.4</code>) of the data used for testing. Use a random state of <code>42</code>. This has been done for you.</li>\r\n","<li>Instantiate a <code>LogisticRegression</code> classifier called <code>logreg</code>.</li>\r\n","<li>Fit the classifier to the training data and predict the labels of the test set.</li>\r\n","<li>Compute and print the confusion matrix and classification report. This has been done for you, so hit 'Submit Answer' to see how logistic regression compares to k-NN!</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"28Zikl3rD_Kv","executionInfo":{"status":"ok","timestamp":1611539112162,"user_tz":180,"elapsed":628,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"ce43f95f-f5a2-4edb-9dd1-21a5a78f4e71"},"source":["# Import the necessary modules\r\n","from sklearn.linear_model import LogisticRegression\r\n","from sklearn.metrics import confusion_matrix, classification_report\r\n","\r\n","# Create training and test sets\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\r\n","\r\n","# Create the classifier: logreg\r\n","logreg = LogisticRegression(solver='liblinear')\r\n","\r\n","# Fit the classifier to the training data\r\n","logreg.fit(X_train, y_train)\r\n","\r\n","# Predict the labels of the test set: y_pred\r\n","y_pred = logreg.predict(X_test)\r\n","\r\n","# Compute and print the confusion matrix and classification report\r\n","print(confusion_matrix(y_test, y_pred))\r\n","print(classification_report(y_test, y_pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[176  30]\n"," [ 35  67]]\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.85      0.84       206\n","           1       0.69      0.66      0.67       102\n","\n","    accuracy                           0.79       308\n","   macro avg       0.76      0.76      0.76       308\n","weighted avg       0.79      0.79      0.79       308\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ON6Ww7BNHq7W"},"source":["**You now know how to use logistic regression for binary classification - great work! Logistic regression is used in a variety of machine learning applications and will become a vital part of your data science toolbox.**"]},{"cell_type":"markdown","metadata":{"id":"hqh_QxYsHt-E"},"source":["## Plotting an ROC curve\r\n"]},{"cell_type":"markdown","metadata":{"id":"T6fiIpG8IHby"},"source":["<div class=\"\"><p>Great job in the previous exercise - you now have a new addition to your toolbox of classifiers! </p>\r\n","<p>Classification reports and confusion matrices are great methods to quantitatively evaluate model performance, while ROC curves provide a way to visually evaluate models. As Hugo demonstrated in the video, most classifiers in scikit-learn have a <code>.predict_proba()</code> method which returns the probability of a given sample being in a particular class. Having built a logistic regression model, you'll now evaluate its performance by plotting an ROC curve. In doing so, you'll make use of the <code>.predict_proba()</code> method and become familiar with its functionality. </p>\r\n","<p>Here, you'll continue working with the PIMA Indians diabetes dataset. The classifier has already been fit to the training data and is available as <code>logreg</code>.</p></div>"]},{"cell_type":"markdown","metadata":{"id":"3BrdWUbWIJwZ"},"source":["Instructions\r\n","<ul>\r\n","<li>Import <code>roc_curve</code> from <code>sklearn.metrics</code>.</li>\r\n","<li>Using the <code>logreg</code> classifier, which has been fit to the training data, compute the predicted probabilities of the labels of the test set <code>X_test</code>. Save the result as <code>y_pred_prob</code>.</li>\r\n","<li>Use the <code>roc_curve()</code> function with <code>y_test</code> and <code>y_pred_prob</code> and unpack the result into the variables <code>fpr</code>, <code>tpr</code>, and <code>thresholds</code>.</li>\r\n","<li>Plot the ROC curve with <code>fpr</code> on the x-axis and <code>tpr</code> on the y-axis.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"IdHO8xyGIMLJ","executionInfo":{"status":"ok","timestamp":1611538895344,"user_tz":180,"elapsed":660,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"ffc9c007-9e5b-4c44-c65e-888153c67b33"},"source":["# Import necessary modules\r\n","from sklearn.metrics import roc_curve\r\n","\r\n","# Compute predicted probabilities: y_pred_prob\r\n","y_pred_prob = logreg.predict_proba(X_test)[:,1]\r\n","\r\n","# Generate ROC curve values: fpr, tpr, thresholds\r\n","fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\r\n","\r\n","# Plot ROC curve\r\n","plt.plot([0, 1], [0, 1], 'k--')\r\n","plt.plot(fpr, tpr)\r\n","plt.xlabel('False Positive Rate')\r\n","plt.ylabel('True Positive Rate')\r\n","plt.title('ROC Curve')\r\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"FWO3OFhMISL5"},"source":["**This ROC curve provides a nice visual way to assess your classifier's performance.**"]},{"cell_type":"markdown","metadata":{"id":"ce29K6jCIWZo"},"source":["### Precision-recall Curve\r\n"]},{"cell_type":"markdown","metadata":{"id":"N7zVEsmtIZZo"},"source":["<p>When looking at your ROC curve, you may have noticed that the y-axis (True positive rate) is also known as recall. Indeed, in addition to the ROC curve, there are other ways to visually evaluate model performance. One such way is the precision-recall curve, which is generated by plotting the precision and recall for different thresholds. As a reminder, precision and recall are defined as:</p>\r\n","\r\n","$$ \\text{Precision} = \\dfrac{TP}{TP + FP} \\\\\r\n","   \\text{Recall} = \\dfrac{TP}{TP + FN}$$\r\n","\r\n","   <p>On the right, a precision-recall curve has been generated for the diabetes dataset. The classification report and confusion matrix are displayed in the IPython Shell.</p>\r\n","\r\n","   <p>Study the precision-recall curve and then consider the statements given below. Choose the one statement that is <strong>not</strong> true. Note that here, the class is positive (1) if the individual <em>has</em> diabetes.</p>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313},"id":"Zqxjsax8J1T2","executionInfo":{"status":"ok","timestamp":1611538900057,"user_tz":180,"elapsed":645,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"519c0f9b-1a06-411d-d377-a2a83de02d35"},"source":["#@title â € { display-mode: \"form\" }\r\n","from sklearn.metrics import precision_recall_curve\r\n","precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\r\n","plt.plot(recall, precision)\r\n","plt.xlabel('Recall')\r\n","plt.ylabel('Precision')\r\n","plt.title('Precision / Recall plot')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'Precision / Recall plot')"]},"metadata":{"tags":[]},"execution_count":14},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"A8-7yBHqJT8q"},"source":["<pre>\r\n","Possible Answers\r\n","\r\n","A recall of 1 corresponds to a classifier with a low threshold in which all females who contract diabetes were correctly classified as such, at the expense of many misclassifications of those who did not have diabetes.\r\n","\r\n","Precision is undefined for a classifier which makes no positive predictions, that is, classifies everyone as not having diabetes.\r\n","\r\n","When the threshold is very close to 1, precision is also 1, because the classifier is absolutely certain about its predictions.\r\n","\r\n","<b>Precision and recall take true negatives into consideration.</b>\r\n","</pre>"]},{"cell_type":"markdown","metadata":{"id":"4foIE0RVJbvp"},"source":["**True negatives do not appear at all in the definitions of precision and recall.**"]},{"cell_type":"markdown","metadata":{"id":"vrfdtbMTK6Dv"},"source":["## Area under the ROC curve\r\n"]},{"cell_type":"markdown","metadata":{"id":"URIf86xiK8xG"},"source":["### AUC computation\r\n"]},{"cell_type":"markdown","metadata":{"id":"VLbCaNb9LQWs"},"source":["<div class=\"\"><p>Say you have a binary classifier that in fact is just randomly making guesses. It would be correct approximately 50% of the time, and the resulting ROC curve would be a diagonal line in which the True Positive Rate and False Positive Rate are always equal. The Area under this ROC curve would be 0.5. This is one way in which the AUC, which Hugo discussed in the video, is an informative metric to evaluate a model. If the AUC is greater than 0.5, the model is better than random guessing. Always a good sign!  </p>\r\n","<p>In this exercise, you'll calculate AUC scores using the <code>roc_auc_score()</code> function from <code>sklearn.metrics</code> as well as by performing cross-validation on the diabetes dataset. </p>\r\n","<p><code>X</code> and <code>y</code>, along with training and test sets <code>X_train</code>, <code>X_test</code>, <code>y_train</code>, <code>y_test</code>, have been pre-loaded for you, and a logistic regression classifier <code>logreg</code> has been fit to the training data.</p></div>"]},{"cell_type":"markdown","metadata":{"id":"YBGY995kLSyE"},"source":["Instructions\r\n","<ul>\r\n","<li>Import <code>roc_auc_score</code> from <code>sklearn.metrics</code> and <code>cross_val_score</code> from <code>sklearn.model_selection</code>.</li>\r\n","<li>Using the <code>logreg</code> classifier, which has been fit to the training data, compute the predicted probabilities of the labels of the test set <code>X_test</code>. Save the result as <code>y_pred_prob</code>.</li>\r\n","<li>Compute the AUC score using the <code>roc_auc_score()</code> function, the test set labels <code>y_test</code>, and the predicted probabilities <code>y_pred_prob</code>.</li>\r\n","<li>Compute the AUC scores by performing 5-fold cross-validation. Use the <code>cross_val_score()</code> function and specify the <code>scoring</code> parameter to be <code>'roc_auc'</code>.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tiucwzoULVT0","executionInfo":{"status":"ok","timestamp":1611538906166,"user_tz":180,"elapsed":888,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"c4561b39-f3e1-4a75-8e12-6073c2fb0306"},"source":["# Import necessary modules\r\n","from sklearn.metrics import roc_auc_score\r\n","from sklearn.model_selection import cross_val_score \r\n","\r\n","# Compute predicted probabilities: y_pred_prob\r\n","y_pred_prob = logreg.predict_proba(X_test)[:,1]\r\n","\r\n","# Compute and print AUC score\r\n","print(\"AUC: {}\".format(roc_auc_score(y_test, y_pred_prob)))\r\n","\r\n","# Compute cross-validated AUC scores: cv_auc\r\n","cv_auc = cross_val_score(logreg, X, y, cv=5,\r\n","scoring='roc_auc')\r\n","\r\n","# Print list of AUC scores\r\n","print(\"AUC scores computed using 5-fold cross-validation: {}\".format(cv_auc))\r\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["AUC: 0.8260993717875499\n","AUC scores computed using 5-fold cross-validation: [0.81888889 0.80537037 0.825      0.87       0.84566038]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qgsksFKzLosh"},"source":["**You now have a number of different methods you can use to evaluate your model's performance.**"]},{"cell_type":"markdown","metadata":{"id":"Y9x040umLuwQ"},"source":["## Hyperparameter tuning\r\n"]},{"cell_type":"markdown","metadata":{"id":"C367Y7eHL4vv"},"source":["### Hyperparameter tuning with GridSearchCV\r\n"]},{"cell_type":"markdown","metadata":{"id":"lwRu-Qh1L8oH"},"source":["<div class=\"\"><p>Hugo demonstrated how to tune the <code>n_neighbors</code> parameter of the <code>KNeighborsClassifier()</code> using GridSearchCV on the voting dataset. You will now practice this yourself, but by using logistic regression on the diabetes dataset instead! </p>\r\n","<p>Like the alpha parameter of lasso and ridge regularization that you saw earlier, logistic regression also has a regularization parameter: <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"2\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D436 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></mjx-assistive-mml></mjx-container>. <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"3\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D436 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></mjx-assistive-mml></mjx-container> controls the <em>inverse</em> of the regularization strength, and this is what you will tune in this exercise. A large <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"4\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D436 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></mjx-assistive-mml></mjx-container> can lead to an <em>overfit</em> model, while a small <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"5\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D436 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></mjx-assistive-mml></mjx-container> can lead to an <em>underfit</em> model.</p>\r\n","<p>The hyperparameter space for <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"6\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D436 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></mjx-assistive-mml></mjx-container> has been setup for you. Your job is to use GridSearchCV and logistic regression to find the optimal <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"7\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D436 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></mjx-assistive-mml></mjx-container> in this hyperparameter space. The feature array is available as <code>X</code> and target variable array is available as <code>y</code>.</p>\r\n","<p>You may be wondering why you aren't asked to split the data into training and test sets. Good observation! Here, we want you to focus on the process of setting up the hyperparameter grid and performing grid-search cross-validation. In practice, you will indeed want to hold out a portion of your data for evaluation purposes, and you will learn all about this in the next video!</p></div>"]},{"cell_type":"markdown","metadata":{"id":"_EbU3bkFL_x-"},"source":["Instructions\r\n","<ul>\r\n","<li>Import <code>LogisticRegression</code> from <code>sklearn.linear_model</code> and <code>GridSearchCV</code> from <code>sklearn.model_selection</code>.</li>\r\n","<li>Setup the hyperparameter grid by using <code>c_space</code> as the grid of values to tune <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"8\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D436 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></mjx-assistive-mml></mjx-container> over.</li>\r\n","<li>Instantiate a logistic regression classifier called <code>logreg</code>.</li>\r\n","<li>Use <code>GridSearchCV</code> with 5-fold cross-validation to tune <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"9\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D436 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></mjx-assistive-mml></mjx-container>:<ul>\r\n","<li>Inside <code>GridSearchCV()</code>, specify the classifier, parameter grid, and number of folds to use.</li>\r\n","<li>Use the <code>.fit()</code> method on the <code>GridSearchCV</code> object to fit it to the data <code>X</code> and <code>y</code>.</li></ul></li>\r\n","<li>Print the best parameter and best score obtained from <code>GridSearchCV</code> by accessing the <code>best_params_</code> and <code>best_score_</code> attributes of <code>logreg_cv</code>.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7DKDVadCMa3C","executionInfo":{"status":"ok","timestamp":1611539092527,"user_tz":180,"elapsed":1111,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"84dc0338-70e0-4846-8ee1-7f9119d49889"},"source":["# Import necessary modules\r\n","from sklearn.linear_model import LogisticRegression\r\n","from sklearn.model_selection import GridSearchCV\r\n","\r\n","# Setup the hyperparameter grid\r\n","c_space = np.logspace(-5, 8, 15)\r\n","param_grid = {'C': c_space}\r\n","\r\n","# Instantiate a logistic regression classifier: logreg\r\n","logreg = LogisticRegression(solver='liblinear')\r\n","\r\n","# Instantiate the GridSearchCV object: logreg_cv\r\n","logreg_cv =  GridSearchCV(logreg, param_grid, cv=5)\r\n","\r\n","# Fit it to the data\r\n","logreg_cv.fit(X, y)\r\n","\r\n","# Print the tuned parameters and score\r\n","print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \r\n","print(\"Best score is {}\".format(logreg_cv.best_score_))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tuned Logistic Regression Parameters: {'C': 3.727593720314938}\n","Best score is 0.7708768355827178\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Dfk-exMIOjsX"},"source":["**It looks like a 'C' of 3.727 results in the best performance.**"]},{"cell_type":"markdown","metadata":{"id":"Vn5cOlphOztb"},"source":["## Hyperparameter tuning with RandomizedSearchCV\r\n"]},{"cell_type":"markdown","metadata":{"id":"NzvKzeV1PAcT"},"source":["<div class=\"\"><p>GridSearchCV can be computationally expensive, especially if you are searching over a large hyperparameter space and dealing with multiple hyperparameters. A solution to this is to use <code>RandomizedSearchCV</code>, in which not all hyperparameter values are tried out. Instead, a fixed number of hyperparameter settings is sampled from specified probability distributions. You'll practice using <code>RandomizedSearchCV</code> in this exercise and see how this works.</p>\r\n","<p>Here, you'll also be introduced to a new model: the Decision Tree. Don't worry about the specifics of how this model works. Just like k-NN, linear regression, and logistic regression, decision trees in scikit-learn have <code>.fit()</code> and <code>.predict()</code> methods that you can use in exactly the same way as before. Decision trees have many parameters that can be tuned, such as <code>max_features</code>, <code>max_depth</code>, and <code>min_samples_leaf</code>: This makes it an ideal use case for <code>RandomizedSearchCV</code>. </p>\r\n","<p>As before, the feature array <code>X</code> and target variable array <code>y</code> of the diabetes dataset have been pre-loaded. The hyperparameter settings have been specified for you. Your goal is to use <code>RandomizedSearchCV</code> to find the optimal hyperparameters. Go for it!</p></div>"]},{"cell_type":"markdown","metadata":{"id":"6_KpBKWnPDBy"},"source":["Instructions\r\n","<ul>\r\n","<li>Import <code>DecisionTreeClassifier</code> from <code>sklearn.tree</code> and <code>RandomizedSearchCV</code> from <code>sklearn.model_selection</code>.</li>\r\n","<li>Specify the parameters and distributions to sample from. This has been done for you.</li>\r\n","<li>Instantiate a <code>DecisionTreeClassifier</code>.</li>\r\n","<li>Use <code>RandomizedSearchCV</code> with 5-fold cross-validation to tune the hyperparameters:<ul>\r\n","<li>Inside <code>RandomizedSearchCV()</code>, specify the classifier, parameter distribution, and number of folds to use.</li>\r\n","<li>Use the <code>.fit()</code> method on the <code>RandomizedSearchCV</code> object to fit it to the data <code>X</code> and <code>y</code>.</li></ul></li>\r\n","<li>Print the best parameter and best score obtained from <code>RandomizedSearchCV</code> by accessing the <code>best_params_</code> and <code>best_score_</code> attributes of <code>tree_cv</code>.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-83z5MTbPGcK","executionInfo":{"status":"ok","timestamp":1611539485517,"user_tz":180,"elapsed":655,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"94bcfbb2-cc0d-42a4-80e0-4a619d6eaed3"},"source":["# Import necessary modules\r\n","from scipy.stats import randint\r\n","from sklearn.tree import DecisionTreeClassifier\r\n","from sklearn.model_selection import RandomizedSearchCV\r\n","\r\n","# Setup the parameters and distributions to sample from: param_dist\r\n","param_dist = {\"max_depth\": [3, None],\r\n","              \"max_features\": randint(1, 9),\r\n","              \"min_samples_leaf\": randint(1, 9),\r\n","              \"criterion\": [\"gini\", \"entropy\"]}\r\n","\r\n","# Instantiate a Decision Tree classifier: tree\r\n","tree = DecisionTreeClassifier()\r\n","\r\n","# Instantiate the RandomizedSearchCV object: tree_cv\r\n","tree_cv = RandomizedSearchCV(tree, param_dist, cv=5)\r\n","\r\n","# Fit it to the data\r\n","tree_cv.fit(X, y)\r\n","\r\n","# Print the tuned parameters and score\r\n","print(\"Tuned Decision Tree Parameters: {}\".format(tree_cv.best_params_))\r\n","print(\"Best score is {}\".format(tree_cv.best_score_))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tuned Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': 3, 'max_features': 3, 'min_samples_leaf': 7}\n","Best score is 0.7370681605975724\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LJey5xfbPMOj"},"source":["**You'll see a lot more of decision trees and RandomizedSearchCV as you continue your machine learning journey. Note that RandomizedSearchCV will never outperform GridSearchCV. Instead, it is valuable because it saves on computation time.**"]},{"cell_type":"markdown","metadata":{"id":"qo019rU-PheP"},"source":["## Hold-out set for final evaluation"]},{"cell_type":"markdown","metadata":{"id":"HMEDoyeMPou_"},"source":["### Hold-out set reasoning"]},{"cell_type":"markdown","metadata":{"id":"MbX4QZHcPrgg"},"source":["<p>For which of the following reasons would you want to use a hold-out set for the very end?</p>"]},{"cell_type":"markdown","metadata":{"id":"vAjAd9EqPt_O"},"source":["<pre>\r\n","Possible Answers\r\n","\r\n","You want to maximize the amount of training data used.\r\n","\r\n","<b>You want to be absolutely certain about your model's ability to generalize to unseen data.</b>\r\n","\r\n","You want to tune the hyperparameters of your model.\r\n","</pre>"]},{"cell_type":"markdown","metadata":{"id":"zQFeW60_P299"},"source":["**The idea is to tune the model's hyperparameters on the training set, and then evaluate its performance on the hold-out set which it has never seen before.**"]},{"cell_type":"markdown","metadata":{"id":"gD-U9k5JQIDb"},"source":["## Hold-out set in practice I: Classification\r\n"]},{"cell_type":"markdown","metadata":{"id":"ufSEKNI0QcfI"},"source":["<div class=\"\"><p>You will now practice evaluating a model with tuned hyperparameters on a hold-out set. The feature array and target variable array from the diabetes dataset have been pre-loaded as <code>X</code> and <code>y</code>. </p>\r\n","<p>In addition to <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"12\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D436 TEX-I\"></mjx-c></mjx-mi></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>C</mi></math></mjx-assistive-mml></mjx-container>, logistic regression has a <code>'penalty'</code> hyperparameter which specifies whether to use <code>'l1'</code> or <code>'l2'</code> regularization. Your job in this exercise is to create a hold-out set, tune the <code>'C'</code> and <code>'penalty'</code> hyperparameters of a logistic regression classifier using <code>GridSearchCV</code> on the training set.</p></div>"]},{"cell_type":"markdown","metadata":{"id":"mN6p1n5dQe2Q"},"source":["<ul>\r\n","<li>Create the hyperparameter grid:<ul>\r\n","<li>Use the array <code>c_space</code> as the grid of values for <code>'C'</code>.</li>\r\n","<li>For <code>'penalty'</code>, specify a list consisting of <code>'l1'</code> and <code>'l2'</code>.</li></ul></li>\r\n","<li>Instantiate a logistic regression classifier.</li>\r\n","<li>Create training and test sets. Use a <code>test_size</code> of <code>0.4</code> and <code>random_state</code> of <code>42</code>. In practice, the test set here will function as the hold-out set.</li>\r\n","<li>Tune the hyperparameters on the training set using <code>GridSearchCV</code> with 5-folds. This involves first instantiating the <code>GridSearchCV</code> object with the correct parameters and then fitting it to the training data.</li>\r\n","<li>Print the best parameter and best score obtained from <code>GridSearchCV</code> by accessing the <code>best_params_</code> and <code>best_score_</code> attributes of <code>logreg_cv</code>.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nuug1RIJQgXQ","executionInfo":{"status":"ok","timestamp":1611539833129,"user_tz":180,"elapsed":1604,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"01914c7d-7fad-4316-b669-777a27679792"},"source":["# Import necessary modules\r\n","from sklearn.model_selection import train_test_split\r\n","from sklearn.linear_model import LogisticRegression\r\n","from sklearn.model_selection import GridSearchCV\r\n","\r\n","# Create the hyperparameter grid\r\n","c_space = np.logspace(-5, 8, 15)\r\n","param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\r\n","\r\n","# Instantiate the logistic regression classifier: logreg\r\n","logreg = LogisticRegression(solver='liblinear')\r\n","\r\n","# Create train and test sets\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\r\n","\r\n","# Instantiate the GridSearchCV object: logreg_cv\r\n","logreg_cv = GridSearchCV(logreg, param_grid, cv=5)\r\n","\r\n","# Fit it to the training data\r\n","logreg_cv.fit(X_train, y_train)\r\n","\r\n","# Print the optimal parameters and best score\r\n","print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\r\n","print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tuned Logistic Regression Parameter: {'C': 0.4393970560760795, 'penalty': 'l1'}\n","Tuned Logistic Regression Accuracy: 0.7673913043478262\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mXG0p8B4Qqn5"},"source":["**You're really mastering the fundamentals of classification!**"]},{"cell_type":"markdown","metadata":{"id":"WtBwa0_0QuOH"},"source":["## Hold-out set in practice II: Regression\r\n"]},{"cell_type":"markdown","metadata":{"id":"PqQRJF5cQy2o"},"source":["<div class=\"\"><p>Remember lasso and ridge regression from the previous chapter? Lasso used the <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"13\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D43F TEX-I\"></mjx-c></mjx-mi><mjx-mn class=\"mjx-n\"><mjx-c class=\"mjx-c31\"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi><mn>1</mn></math></mjx-assistive-mml></mjx-container> penalty to regularize, while ridge used the <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"14\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D43F TEX-I\"></mjx-c></mjx-mi><mjx-mn class=\"mjx-n\"><mjx-c class=\"mjx-c32\"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi><mn>2</mn></math></mjx-assistive-mml></mjx-container> penalty. There is another type of regularized regression known as the elastic net. In elastic net regularization, the penalty term is a linear combination of the <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"15\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D43F TEX-I\"></mjx-c></mjx-mi><mjx-mn class=\"mjx-n\"><mjx-c class=\"mjx-c31\"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi><mn>1</mn></math></mjx-assistive-mml></mjx-container> and <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"16\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D43F TEX-I\"></mjx-c></mjx-mi><mjx-mn class=\"mjx-n\"><mjx-c class=\"mjx-c32\"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi><mn>2</mn></math></mjx-assistive-mml></mjx-container> penalties:</p>\r\n","<p><mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" display=\"true\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"17\" style=\"font-size: 116.7%; position: relative;\"><mjx-math display=\"true\" class=\"MJX-TEX\" aria-hidden=\"true\" style=\"margin-left: 0px; margin-right: 0px;\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D44E TEX-I\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\" space=\"3\"><mjx-c class=\"mjx-c2217\"></mjx-c></mjx-mo><mjx-mi class=\"mjx-i\" space=\"3\"><mjx-c class=\"mjx-c1D43F TEX-I\"></mjx-c></mjx-mi><mjx-mn class=\"mjx-n\"><mjx-c class=\"mjx-c31\"></mjx-c></mjx-mn><mjx-mo class=\"mjx-n\" space=\"3\"><mjx-c class=\"mjx-c2B\"></mjx-c></mjx-mo><mjx-mi class=\"mjx-i\" space=\"3\"><mjx-c class=\"mjx-c1D44F TEX-I\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\" space=\"3\"><mjx-c class=\"mjx-c2217\"></mjx-c></mjx-mo><mjx-mi class=\"mjx-i\" space=\"3\"><mjx-c class=\"mjx-c1D43F TEX-I\"></mjx-c></mjx-mi><mjx-mn class=\"mjx-n\"><mjx-c class=\"mjx-c32\"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"block\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><mi>a</mi><mo>âˆ—</mo><mi>L</mi><mn>1</mn><mo>+</mo><mi>b</mi><mo>âˆ—</mo><mi>L</mi><mn>2</mn></math></mjx-assistive-mml></mjx-container></p>\r\n","<p>In scikit-learn, this term is represented by the <code>'l1_ratio'</code> parameter: An <code>'l1_ratio'</code> of <code>1</code> corresponds to an <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"18\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D43F TEX-I\"></mjx-c></mjx-mi><mjx-mn class=\"mjx-n\"><mjx-c class=\"mjx-c31\"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi><mn>1</mn></math></mjx-assistive-mml></mjx-container> penalty, and anything lower is a combination of <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"19\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D43F TEX-I\"></mjx-c></mjx-mi><mjx-mn class=\"mjx-n\"><mjx-c class=\"mjx-c31\"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi><mn>1</mn></math></mjx-assistive-mml></mjx-container> and <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"20\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D43F TEX-I\"></mjx-c></mjx-mi><mjx-mn class=\"mjx-n\"><mjx-c class=\"mjx-c32\"></mjx-c></mjx-mn></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>L</mi><mn>2</mn></math></mjx-assistive-mml></mjx-container>.</p>\r\n","<p>In this exercise, you will <code>GridSearchCV</code> to tune the <code>'l1_ratio'</code> of an elastic net model trained on the Gapminder data. As in the previous exercise, use a hold-out set to evaluate your model's performance.</p></div>"]},{"cell_type":"code","metadata":{"id":"Qp5nwGX7SgTk"},"source":["df = pd.read_csv('https://raw.githubusercontent.com/lnunesAI/Datacamp/main/2-machine-learning-scientist-with-python/1-supervised-learning-with-scikit-learn/datasets/gapminder_preprocessed.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eZvmrc2KTPcJ"},"source":["X = df.drop('life', axis='columns').values\r\n","y = df['life'].values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R46oiW4rQ3_3"},"source":["Instructions\r\n","<ul>\r\n","<li>Import the following modules:<ul>\r\n","<li><code>ElasticNet</code> from <code>sklearn.linear_model</code>.</li>\r\n","<li><code>mean_squared_error</code> from <code>sklearn.metrics</code>.</li>\r\n","<li><code>GridSearchCV</code> and <code>train_test_split</code> from <code>sklearn.model_selection</code>.</li></ul></li>\r\n","<li>Create training and test sets, with 40% of the data used for the test set. Use a random state of <code>42</code>.</li>\r\n","<li>Specify the hyperparameter grid for <code>'l1_ratio'</code> using <code>l1_space</code> as the grid of values to search over.</li>\r\n","<li>Instantiate the <code>ElasticNet</code> regressor. </li>\r\n","<li>Use <code>GridSearchCV</code> with 5-fold cross-validation to tune <code>'l1_ratio'</code> on the training data <code>X_train</code> and <code>y_train</code>. This involves first instantiating the <code>GridSearchCV</code> object with the correct parameters and then fitting it to the training data.</li>\r\n","<li>Predict on the test set and compute the <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"21\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-msup><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D445 TEX-I\"></mjx-c></mjx-mi><mjx-script style=\"vertical-align: 0.363em;\"><mjx-mn class=\"mjx-n\" size=\"s\"><mjx-c class=\"mjx-c32\"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><msup><mi>R</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container> and mean squared error.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GR7cWjeISowr","executionInfo":{"status":"ok","timestamp":1611540371811,"user_tz":180,"elapsed":629,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"c7b04d67-7767-4808-8b0f-0e112c61f0b9"},"source":["df.drop(labels=['Region'], axis='columns', inplace=True)\r\n","df.head()\r\n","X = df.drop('life', axis='columns').values\r\n","y = df['life'].values"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(139, 9)"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KoIyobwqRTXM","executionInfo":{"status":"ok","timestamp":1611541363382,"user_tz":180,"elapsed":627,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"42673c68-11ed-47ed-cdf6-9bb1fd6a167b"},"source":["# Import necessary modules\r\n","from sklearn.linear_model import ElasticNet\r\n","from sklearn.metrics import mean_squared_error\r\n","from sklearn.model_selection import GridSearchCV, train_test_split\r\n","\r\n","# Create train and test sets\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state=42)\r\n","\r\n","# Create the hyperparameter grid\r\n","l1_space = np.linspace(0, 1, 30)\r\n","param_grid = {'l1_ratio': l1_space}\r\n","\r\n","# Instantiate the ElasticNet regressor: elastic_net\r\n","elastic_net = ElasticNet(max_iter=100)\r\n","\r\n","# Setup the GridSearchCV object: gm_cv\r\n","gm_cv = GridSearchCV(elastic_net, param_grid, cv=5)\r\n","\r\n","# Fit it to the training data\r\n","gm_cv.fit(X_train, y_train)\r\n","\r\n","# Predict on the test set and compute metrics\r\n","y_pred = gm_cv.predict(X_test)\r\n","r2 = gm_cv.score(X_test, y_test)\r\n","mse = mean_squared_error(y_test, y_pred)\r\n","print(\"Tuned ElasticNet l1 ratio: {}\".format(gm_cv.best_params_))\r\n","print(\"Tuned ElasticNet R squared: {}\".format(r2))\r\n","print(\"Tuned ElasticNet MSE: {}\".format(mse))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 282.4862175850652, tolerance: 0.558941590909091\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 309.8466391486278, tolerance: 0.5893071666666668\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 255.50344008061305, tolerance: 0.5890250303030303\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 287.6728412633783, tolerance: 0.5814186865671642\n","  positive)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 311.18271147681963, tolerance: 0.5801944179104478\n","  positive)\n"],"name":"stderr"},{"output_type":"stream","text":["Tuned ElasticNet l1 ratio: {'l1_ratio': 0.20689655172413793}\n","Tuned ElasticNet R squared: 0.8668305372460283\n","Tuned ElasticNet MSE: 10.057914133398446\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qXRF9x0DVY15"},"source":["**Now that you understand how to fine-tune your models, it's time to learn about preprocessing techniques and how to piece together all the different stages of the machine learning process into a pipeline!**"]}]}