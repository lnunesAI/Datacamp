{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"3-feature-engineering.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNVNcBGupAROCJbofs/HoWH"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["# Classification\r\n","\r\n","> In this section you'll learn about feature engineering. You'll explore different ways to create new, more useful, features from the ones already in your dataset. You'll see how to encode, aggregate, and extract information from both numerical and textual features.\r\n","> \r\n","- toc: true \r\n","- badges: true\r\n","- comments: true\r\n","- author: Lucas Nunes\r\n","- categories: [Python, Datacamp, Machine Learning]\r\n","- image: images/datacamp/1_supervised_learning_with_scikit_learn/2_regression.png"],"metadata":{"id":"f5FTJNcbC9gb"}},{"cell_type":"markdown","source":["> Note: This is a summary of the course's chapter 3 exercises \"Preprocessing for Machine Learning in Python\" at datacamp. <br>[Github repo](https://github.com/lnunesAI/Datacamp/) / [Course link](https://www.datacamp.com/tracks/machine-learning-scientist-with-python)"],"metadata":{}},{"cell_type":"code","execution_count":1,"source":["import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns"],"outputs":[],"metadata":{"id":"7SbXqsjxFOUG","executionInfo":{"status":"ok","timestamp":1611584563038,"user_tz":180,"elapsed":2000,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["## Feature engineering\r\n"],"metadata":{"id":"UvrKEMkeEF2g"}},{"cell_type":"markdown","source":["### Feature engineering knowledge test\r\n"],"metadata":{"id":"cenXvqenycGh"}},{"cell_type":"markdown","source":["<p>Now that you've learned about feature engineering, which of the following examples are good candidates for creating new features?</p>"],"metadata":{"id":"8tOc-z_7ygT4"}},{"cell_type":"markdown","source":["<pre>\r\n","Possible Answers\r\n","\r\n","A column of timestamps\r\n","\r\n","A column of newspaper headlines\r\n","\r\n","A column of weight measurements\r\n","\r\n","<b>1 and 2</b>\r\n","\r\n","None of the above\r\n","\r\n","</pre>"],"metadata":{"id":"8jSeFTcSy5MN"}},{"cell_type":"markdown","source":["**Timestamps can be broken into days or months, and headlines can be used for natural language processing.**"],"metadata":{"id":"-pPrcGtsysf3"}},{"cell_type":"markdown","source":["### Identifying areas for feature engineering\r\n"],"metadata":{"id":"c-kvcANGy9Oc"}},{"cell_type":"markdown","source":["<p>Take an exploratory look at the <code>volunteer</code> dataset, using the variable of that name. Which of the following columns would you want to perform a feature engineering task on?</p>"],"metadata":{"id":"P36yXTsHy_s8"}},{"cell_type":"code","execution_count":5,"source":["volunteer = pd.read_csv('https://raw.githubusercontent.com/lnunesAI/Datacamp/main/2-machine-learning-scientist-with-python/8-preprocessing-for-machine-learning-in-python/datasets/volunteer.csv')"],"outputs":[],"metadata":{"id":"3AxSzF8TC0ZC","executionInfo":{"status":"ok","timestamp":1611584637642,"user_tz":180,"elapsed":1485,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["<pre>\r\n","Possible Answers\r\n","\r\n","vol_requests\r\n","\r\n","title\r\n","\r\n","created_date\r\n","\r\n","category_desc\r\n","\r\n","<b>2, 3, and 4</b>\r\n","</pre>"],"metadata":{"id":"L1zu5HbT0PNr"}},{"cell_type":"code","execution_count":6,"source":["volunteer[['vol_requests', 'title', 'created_date', 'category_desc']]"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>vol_requests</th>\n","      <th>title</th>\n","      <th>created_date</th>\n","      <th>category_desc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50</td>\n","      <td>Volunteers Needed For Rise Up &amp; Stay Put! Home...</td>\n","      <td>January 13 2011</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Web designer</td>\n","      <td>January 14 2011</td>\n","      <td>Strengthening Communities</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>20</td>\n","      <td>Urban Adventures - Ice Skating at Lasker Rink</td>\n","      <td>January 19 2011</td>\n","      <td>Strengthening Communities</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>500</td>\n","      <td>Fight global hunger and support women farmers ...</td>\n","      <td>January 21 2011</td>\n","      <td>Strengthening Communities</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>15</td>\n","      <td>Stop 'N' Swap</td>\n","      <td>January 28 2011</td>\n","      <td>Environment</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>660</th>\n","      <td>3</td>\n","      <td>Volunteer for NYLAG's Food Stamps Project</td>\n","      <td>August 16 2011</td>\n","      <td>Helping Neighbors in Need</td>\n","    </tr>\n","    <tr>\n","      <th>661</th>\n","      <td>10</td>\n","      <td>Iridescent Science Studio Open House Volunteers</td>\n","      <td>March 21 2011</td>\n","      <td>Strengthening Communities</td>\n","    </tr>\n","    <tr>\n","      <th>662</th>\n","      <td>1</td>\n","      <td>French Translator</td>\n","      <td>July 20 2011</td>\n","      <td>Helping Neighbors in Need</td>\n","    </tr>\n","    <tr>\n","      <th>663</th>\n","      <td>2</td>\n","      <td>Marketing &amp; Advertising Volunteer</td>\n","      <td>June 01 2011</td>\n","      <td>Strengthening Communities</td>\n","    </tr>\n","    <tr>\n","      <th>664</th>\n","      <td>5</td>\n","      <td>Volunteer filmmakers to help Mayor's Office wi...</td>\n","      <td>July 07 2011</td>\n","      <td>Strengthening Communities</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>665 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["     vol_requests  ...              category_desc\n","0              50  ...                        NaN\n","1               2  ...  Strengthening Communities\n","2              20  ...  Strengthening Communities\n","3             500  ...  Strengthening Communities\n","4              15  ...                Environment\n","..            ...  ...                        ...\n","660             3  ...  Helping Neighbors in Need\n","661            10  ...  Strengthening Communities\n","662             1  ...  Helping Neighbors in Need\n","663             2  ...  Strengthening Communities\n","664             5  ...  Strengthening Communities\n","\n","[665 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":6}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"loxWtbynzXRa","executionInfo":{"status":"ok","timestamp":1611582618119,"user_tz":180,"elapsed":621,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"ccee829d-6920-4a25-b7a7-09a458ce2042"}},{"cell_type":"markdown","source":["**All three of these columns will require some feature engineering before modeling.**"],"metadata":{"id":"-3d6QHky0MbL"}},{"cell_type":"markdown","source":["## Encoding categorical variables\r\n"],"metadata":{"id":"jGmEeAHF0kNY"}},{"cell_type":"markdown","source":["### Encoding categorical variables - binary\r\n"],"metadata":{"id":"m1jEyfdg1OND"}},{"cell_type":"markdown","source":["<p>Take a look at the <code>hiking</code> dataset. There are several columns here that need encoding, one of which is the <code>Accessible</code> column, which needs to be encoded in order to be modeled. <code>Accessible</code> is a binary feature, so it has two values - either <code>Y</code> or <code>N</code> - so it needs to be encoded into 1s and 0s. Use scikit-learn's <code>LabelEncoder</code> method to do that transformation.</p>"],"metadata":{"id":"QmNj44_D1TqI"}},{"cell_type":"code","execution_count":19,"source":["from sklearn.preprocessing import LabelEncoder\r\n","hiking = pd.read_csv('https://raw.githubusercontent.com/lnunesAI/Datacamp/main/2-machine-learning-scientist-with-python/8-preprocessing-for-machine-learning-in-python/datasets/hiking.csv')"],"outputs":[],"metadata":{"id":"A94WPST-2gYh","executionInfo":{"status":"ok","timestamp":1611585592518,"user_tz":180,"elapsed":1012,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Store <code>LabelEncoder()</code> in a variable named <code>enc</code></li>\r\n","<li>Using the encoder's <code>fit_transform()</code> function, encode the <code>hiking</code> dataset's <code>\"Accessible\"</code> column. Call the new column <code>Accessible_enc</code>.</li>\r\n","<li>Compare the two columns side-by-side to see the encoding.</li>\r\n","</ul>"],"metadata":{"id":"9rDIpJHa1VnP"}},{"cell_type":"code","execution_count":15,"source":["# Set up the LabelEncoder object\r\n","enc = LabelEncoder()\r\n","\r\n","# Apply the encoding to the \"Accessible\" column\r\n","hiking['Accessible_enc'] = enc.fit_transform(hiking['Accessible'])\r\n","\r\n","# Compare the two columns\r\n","print(hiking[['Accessible', 'Accessible_enc']].head())"],"outputs":[{"output_type":"stream","name":"stdout","text":["  Accessible  Accessible_enc\n","0          Y               1\n","1          N               0\n","2          N               0\n","3          N               0\n","4          N               0\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wiKnkjQv12C-","executionInfo":{"status":"ok","timestamp":1611585553237,"user_tz":180,"elapsed":867,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"5819de72-a587-45a3-e203-ab14cb499121"}},{"cell_type":"markdown","source":["**.fit_transform() is a good way to both fit an encoding and transform the data in a single step.**"],"metadata":{"id":"hv5OYDmp17Nt"}},{"cell_type":"markdown","source":["## Encoding categorical variables - one-hot\r\n"],"metadata":{"id":"Ujez4fy12xQ3"}},{"cell_type":"markdown","source":["<p>One of the columns in the <code>volunteer</code> dataset, <code>category_desc</code>, gives category descriptions for the volunteer opportunities listed. Because it is a categorical variable with more than two categories, we need to use one-hot encoding to transform this column numerically. Use Pandas' <code>get_dummies()</code> function to do so.</p>"],"metadata":{"id":"rm0ejcut20J-"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Call <code>get_dummies()</code> on the <code>volunteer[\"category_desc\"]</code> column to create the encoded columns and assign it to <code>category_enc</code>.</li>\r\n","<li>Print out the <code>head()</code> of the <code>category_enc</code> variable to take a look at the encoded columns.</li>\r\n","</ul>"],"metadata":{"id":"tcZUEiXX2181"}},{"cell_type":"code","execution_count":16,"source":["# Transform the category_desc column\r\n","category_enc = pd.get_dummies(volunteer['category_desc'])\r\n","\r\n","# Take a look at the encoded columns\r\n","category_enc.head()"],"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Education</th>\n","      <th>Emergency Preparedness</th>\n","      <th>Environment</th>\n","      <th>Health</th>\n","      <th>Helping Neighbors in Need</th>\n","      <th>Strengthening Communities</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Education  ...  Strengthening Communities\n","0          0  ...                          0\n","1          0  ...                          1\n","2          0  ...                          1\n","3          0  ...                          1\n","4          0  ...                          0\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":16}],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"C3EU66ah3JD8","executionInfo":{"status":"ok","timestamp":1611585561964,"user_tz":180,"elapsed":762,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"7d9b116e-32c0-43d9-b812-b326f6ed0c29"}},{"cell_type":"markdown","source":["**get_dummies() is a simple and quick way to encode categorical variables.**"],"metadata":{"id":"C4AG49il3LYE"}},{"cell_type":"markdown","source":["## Engineering numerical features"],"metadata":{"id":"Z7ep5zt13fHB"}},{"cell_type":"markdown","source":["### Engineering numerical features - taking an average"],"metadata":{"id":"lNzMykci39UV"}},{"cell_type":"markdown","source":["<p>A good use case for taking an aggregate statistic to create a new feature is to take the mean of columns. Here, you have a DataFrame of running times named <code>running_times_5k</code>. For each <code>name</code> in the dataset, take the mean of their 5 run times.</p>"],"metadata":{"id":"aReF3Z-O4E8E"}},{"cell_type":"code","execution_count":2,"source":["running_times_5k = pd.read_csv('https://raw.githubusercontent.com/lnunesAI/Datacamp/main/2-machine-learning-scientist-with-python/8-preprocessing-for-machine-learning-in-python/datasets/running_times_5k.csv')"],"outputs":[],"metadata":{"id":"e02gnsrf5_km","executionInfo":{"status":"ok","timestamp":1611584569697,"user_tz":180,"elapsed":778,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Create a list of the columns you want to take the average of and store it in a variable named <code>run_columns</code>.</li>\r\n","<li>Use <code>apply</code> to take the <code>mean()</code> of the list of columns and remember to set <code>axis=1</code>. Use <code>lambda row:</code> in the apply.</li>\r\n","<li>Print out the DataFrame to see the <code>mean</code> column.</li>\r\n","</ul>"],"metadata":{"id":"cwDyi8Az4Its"}},{"cell_type":"code","execution_count":4,"source":["# Create a list of the columns to average\r\n","run_columns = running_times_5k.columns[-5:]\r\n","\r\n","# Use apply to create a mean column\r\n","running_times_5k[\"mean\"] = running_times_5k.apply(lambda row: row[run_columns].mean(), axis=1)\r\n","\r\n","# Take a look at the results\r\n","print(running_times_5k)"],"outputs":[{"output_type":"stream","name":"stdout","text":["      name  run1  run2  run3  run4  run5   mean\n","0      Sue  20.1  18.5  19.6  20.3  18.3  19.36\n","1     Mark  16.5  17.1  16.9  17.6  17.3  17.08\n","2     Sean  23.5  25.1  25.2  24.6  23.9  24.46\n","3     Erin  21.7  21.1  20.9  22.1  22.2  21.60\n","4    Jenny  25.8  27.1  26.1  26.7  26.9  26.52\n","5  Russell  30.9  29.6  31.4  30.4  29.9  30.44\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A8VRK4CL5oWJ","executionInfo":{"status":"ok","timestamp":1611584578139,"user_tz":180,"elapsed":769,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"6c7461af-09c6-4c8d-e05f-75bd821e02df"}},{"cell_type":"markdown","source":["**Lambdas are especially helpful for operating across columns.**"],"metadata":{"id":"Fx6dFFEb5rUi"}},{"cell_type":"markdown","source":["### Engineering numerical features - datetime\r\n"],"metadata":{"id":"dqDGjp3H7Wiy"}},{"cell_type":"markdown","source":["<p>There are several columns in the <code>volunteer</code> dataset comprised of datetimes. Let's take a look at the <code>start_date_date</code> column and extract just the month to use as a feature for modeling.</p>"],"metadata":{"id":"IvV92i7Q7YxK"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Use Pandas <code>to_datetime()</code> function on the <code>volunteer[\"start_date_date\"]</code> column and store it in a new column called <code>start_date_converted</code>.</li>\r\n","<li>To retrieve just the month, apply a lambda function to <code>volunteer[\"start_date_converted\"]</code> that grabs the <code>.month</code> attribute from the <code>row</code>. Store this in a new column called <code>start_date_month</code>.</li>\r\n","<li>Print the <code>head()</code> of just the <code>start_date_converted</code> and <code>start_date_month</code> columns.</li>\r\n","</ul>"],"metadata":{"id":"yNPQZcpJ7awJ"}},{"cell_type":"code","execution_count":7,"source":["# First, convert string column to date column\r\n","volunteer[\"start_date_converted\"] = pd.to_datetime(volunteer[\"start_date_date\"])\r\n","\r\n","# Extract just the month from the converted column\r\n","volunteer[\"start_date_month\"] = volunteer[\"start_date_converted\"].apply(lambda row: row.month)\r\n","\r\n","# Take a look at the converted and new month columns\r\n","print(volunteer[['start_date_converted', 'start_date_month']].head())"],"outputs":[{"output_type":"stream","name":"stdout","text":["  start_date_converted  start_date_month\n","0           2011-07-30                 7\n","1           2011-02-01                 2\n","2           2011-01-29                 1\n","3           2011-02-14                 2\n","4           2011-02-05                 2\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MrP_yx4x7m94","executionInfo":{"status":"ok","timestamp":1611584848925,"user_tz":180,"elapsed":998,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"1404090e-49ee-4ce9-d2ea-705bfa5bcb65"}},{"cell_type":"markdown","source":["**You can also use attributes like .day to get the day and .year to get the year from datetime columns.**"],"metadata":{"id":"eey3ZkQQ8d95"}},{"cell_type":"markdown","source":["## Text classification\r\n"],"metadata":{"id":"p4jacgyn8huR"}},{"cell_type":"markdown","source":["### Engineering features from strings - extraction\r\n"],"metadata":{"id":"RihCShyR9pMJ"}},{"cell_type":"markdown","source":["<p>The <code>Length</code> column in the <code>hiking</code> dataset is a column of strings, but contained in the column is the mileage for the hike. We're going to extract this mileage using regular expressions, and then use a lambda in Pandas to apply the extraction to the DataFrame.</p>"],"metadata":{"id":"NQHnuclD9tF_"}},{"cell_type":"code","execution_count":22,"source":["import re\r\n","hiking = pd.read_csv('https://raw.githubusercontent.com/lnunesAI/Datacamp/main/2-machine-learning-scientist-with-python/8-preprocessing-for-machine-learning-in-python/datasets/hiking_29x11.csv')"],"outputs":[],"metadata":{"id":"kLw_E4v_-qww","executionInfo":{"status":"ok","timestamp":1611585764654,"user_tz":180,"elapsed":738,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Create a pattern that will extract numbers and decimals from text, using <code>\\d+</code> to get numbers and <code>\\.</code> to get decimals, and pass it into <code>re</code>'s <code>compile</code> function.</li>\r\n","<li>Use <code>re</code>'s <code>match</code> function to search the text, passing in the <code>pattern</code> and the <code>length</code> text.</li>\r\n","<li>Use the matched <code>mile</code>'s <code>group()</code> attribute to extract the matched pattern, making sure to match group <code>0</code>, and pass it into <code>float</code>.</li>\r\n","<li>Apply the <code>return_mileage()</code> function to the <code>hiking[\"Length\"]</code> column.</li>\r\n","</ul>"],"metadata":{"id":"OtG6hoJg9yTu"}},{"cell_type":"code","execution_count":23,"source":["# Write a pattern to extract numbers and decimals\r\n","def return_mileage(length):\r\n","    pattern = re.compile(r\"\\d+\\.\\d+\")\r\n","    \r\n","    # Search the text for matches\r\n","    mile = re.match(pattern, length)\r\n","    \r\n","    # If a value is returned, use group(0) to return the found value\r\n","    if mile is not None:\r\n","        return float(mile.group(0))\r\n","        \r\n","# Apply the function to the Length column and take a look at both columns\r\n","hiking[\"Length_num\"] = hiking[\"Length\"].apply(lambda row: return_mileage(row))\r\n","print(hiking[[\"Length\", \"Length_num\"]].head())"],"outputs":[{"output_type":"stream","name":"stdout","text":["       Length  Length_num\n","0   0.8 miles        0.80\n","1    1.0 mile        1.00\n","2  0.75 miles        0.75\n","3   0.5 miles        0.50\n","4   0.5 miles        0.50\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q13y_Hgz-lvT","executionInfo":{"status":"ok","timestamp":1611585769319,"user_tz":180,"elapsed":763,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"ec9f04f9-d3ed-437d-debf-b31d64b39064"}},{"cell_type":"markdown","source":["**Regular expressions are a useful way to perform text extraction.**"],"metadata":{"id":"6MuqHgyY-68H"}},{"cell_type":"markdown","source":["### Engineering features from strings - tf/idf\r\n"],"metadata":{"id":"9yMTnZ7VAGYf"}},{"cell_type":"markdown","source":["<p>Let's transform the <code>volunteer</code> dataset's <code>title</code> column into a text vector, to use in a prediction task in the next exercise.</p>"],"metadata":{"id":"Ku7qSz02AJel"}},{"cell_type":"code","execution_count":31,"source":["from sklearn.feature_extraction.text import TfidfVectorizer\r\n","volunteer = volunteer.dropna(subset=['category_desc'], axis=0)"],"outputs":[],"metadata":{"id":"VcxfwlpsAYfH","executionInfo":{"status":"ok","timestamp":1611586333552,"user_tz":180,"elapsed":1206,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Store the <code>volunteer[\"title\"]</code> column in a variable named <code>title_text</code>.</li>\r\n","<li>Use the <code>tfidf_vec</code> vectorizer's <code>fit_transform()</code> function on <code>title_text</code> to transform the text into a tf-idf vector.</li>\r\n","</ul>"],"metadata":{"id":"JyrzVS5gALOU"}},{"cell_type":"code","execution_count":32,"source":["# Take the title text\r\n","title_text = volunteer['title']\r\n","\r\n","# Create the vectorizer method\r\n","tfidf_vec = TfidfVectorizer()\r\n","\r\n","# Transform the text into tf-idf vectors\r\n","text_tfidf = tfidf_vec.fit_transform(title_text)"],"outputs":[],"metadata":{"id":"X2yW1IvEAWKt","executionInfo":{"status":"ok","timestamp":1611586336786,"user_tz":180,"elapsed":824,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["**Scikit-learn provides several methods for text vectorization.**"],"metadata":{"id":"Z-8nAKaDAcji"}},{"cell_type":"markdown","source":["## Text classification using tf/idf vectors\r\n"],"metadata":{"id":"XP_N-HxuAeYD"}},{"cell_type":"markdown","source":["<p>Now that we've encoded the <code>volunteer</code> dataset's <code>title</code> column into tf/idf vectors, let's use those vectors to try to predict the <code>category_desc</code> column.</p>"],"metadata":{"id":"cxWXejcRAjth"}},{"cell_type":"code","execution_count":33,"source":["from sklearn.model_selection import train_test_split\r\n","from sklearn.naive_bayes import GaussianNB\r\n","nb = GaussianNB()"],"outputs":[],"metadata":{"id":"K9VfXxGgBdz0","executionInfo":{"status":"ok","timestamp":1611586345299,"user_tz":180,"elapsed":1280,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Using <code>train_test_split</code>, split the <code>text_tfidf</code> vector, along with your <code>y</code> variable, into training and test sets. Set the <code>stratify</code> parameter equal to <code>y</code>, since the class distribution is uneven. Notice that we have to run the <code>toarray()</code> method on the tf/idf vector, in order to get in it the proper format for scikit-learn.</li>\r\n","<li>Use Naive Bayes' <code>fit()</code> method on the <code>X_train</code> and <code>y_train</code> variables.</li>\r\n","<li>Print out the <code>score()</code> of the <code>X_test</code> and <code>y_test</code> variables.</li>\r\n","</ul>"],"metadata":{"id":"S0TekhQPAl3R"}},{"cell_type":"code","execution_count":36,"source":["# Split the dataset according to the class distribution of category_desc\r\n","y = volunteer[\"category_desc\"]\r\n","X_train, X_test, y_train, y_test = train_test_split(text_tfidf.toarray(), y, stratify=y)\r\n","\r\n","# Fit the model to the training data\r\n","nb.fit(X_train, y_train)\r\n","\r\n","# Print out the model's accuracy\r\n","print(nb.score(X_test, y_test))"],"outputs":[{"output_type":"stream","name":"stdout","text":["0.5548387096774193\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HRflETxMBVGm","executionInfo":{"status":"ok","timestamp":1611586362653,"user_tz":180,"elapsed":777,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"28b61480-0d1f-4a2d-cbc6-f8825733e6d3"}},{"cell_type":"markdown","source":["**Notice that the model doesn't score very well. We'll work on selecting the best features for modeling in the next chapter.**"],"metadata":{"id":"5ziZZndNBipw"}}]}