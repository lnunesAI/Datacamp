{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"1-introduction-to-data-preprocessing.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP+NOD4g/iAD2cCZkRoG2ns"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["# Introduction to Data Preprocessing\r\n","> In this chapter you'll learn exactly what it means to preprocess data. You'll take the first steps in any preprocessing journey, including exploring data types and dealing with missing data.\r\n","\r\n","- toc: true \r\n","- badges: true\r\n","- comments: true\r\n","- author: Lucas Nunes\r\n","- categories: [Python, Datacamp, Machine Learning]\r\n","- image: images/batman.jpg"],"metadata":{"id":"f5FTJNcbC9gb"}},{"cell_type":"markdown","source":["> Note: This is a summary of the course's chapter 1 exercises \"Preprocessing for Machine Learning in Python\" at datacamp. <br>[Github repo](https://github.com/lnunesAI/Datacamp/) / [Course link](https://www.datacamp.com/tracks/machine-learning-scientist-with-python)"],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns"],"outputs":[],"metadata":{"id":"7SbXqsjxFOUG","executionInfo":{"status":"ok","timestamp":1611495138688,"user_tz":180,"elapsed":528,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["## What is data preprocessing?\r\n"],"metadata":{"id":"UvrKEMkeEF2g"}},{"cell_type":"markdown","source":["### Missing data - columns"],"metadata":{"id":"_hODN_MfjvAA"}},{"cell_type":"markdown","source":["<div class=\"\"><p>We have a dataset comprised of volunteer information from New York City. The dataset has a number of features, but we want to get rid of features that have at least 3 missing values. </p>\r\n","<p>How many features are in the original dataset, and how many features are in the set after columns with at least 3 missing values are removed?</p>\r\n","<ul>\r\n","<li>The dataset <code>volunteer</code> has been provided.</li>\r\n","<li>Use the <code>dropna()</code> function to remove columns.</li>\r\n","<li>You'll have to set both the <code>axis=</code> and <code>thresh=</code> parameters.</li>\r\n","</ul></div>"],"metadata":{"id":"OPPQCjhRj5ed"}},{"cell_type":"code","execution_count":26,"source":["volunteer = pd.read_csv('https://raw.githubusercontent.com/lnunesAI/Datacamp/main/2-machine-learning-scientist-with-python/8-preprocessing-for-machine-learning-in-python/datasets/volunteer.csv')"],"outputs":[],"metadata":{"id":"3AxSzF8TC0ZC","executionInfo":{"status":"ok","timestamp":1611497765464,"user_tz":180,"elapsed":746,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["<pre>\r\n","Possible Answers\r\n","\r\n","<b>35, 24</b>\r\n","\r\n","35, 35\r\n","\r\n","35, 19\r\n","</pre>"],"metadata":{"id":"B_963i_GkRNb"}},{"cell_type":"code","execution_count":14,"source":["volunteer.shape"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(665, 35)"]},"metadata":{"tags":[]},"execution_count":14}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJYNPK1LoF6-","executionInfo":{"status":"ok","timestamp":1611495666011,"user_tz":180,"elapsed":580,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"51ab84c5-1cec-4e3a-c1c7-50d79935521f"}},{"cell_type":"code","execution_count":15,"source":["volunteer.dropna(axis=1, thresh=3).shape"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(665, 24)"]},"metadata":{"tags":[]},"execution_count":15}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FXFOGmoImHM0","executionInfo":{"status":"ok","timestamp":1611495672241,"user_tz":180,"elapsed":561,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"8f5c48f4-d655-4e0b-d61d-b76e1dda6ff7"}},{"cell_type":"markdown","source":["**A lot of operations are done on a column basis, so it's useful to remember axis=1 when working with Pandas.**"],"metadata":{"id":"NDB_xL3noRIJ"}},{"cell_type":"markdown","source":["### Missing data - rows"],"metadata":{"id":"Tlbb5KZlolrh"}},{"cell_type":"markdown","source":["<p>Taking a look at the <code>volunteer</code> dataset again, we want to drop rows where the <code>category_desc</code> column values are missing. We're going to do this using boolean indexing, by checking to see if we have any null values, and then filtering the dataset so that we only have rows with those values.</p>"],"metadata":{"id":"Q6coMuf1opjJ"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Check how many values are missing in the <code>category_desc</code> column using <code>isnull()</code> and <code>sum()</code>.</li>\r\n","<li>Subset the <code>volunteer</code> dataset by indexing by where <code>category_desc</code> is <code>notnull()</code>, and store in a new variable called <code>volunteer_subset</code>.</li>\r\n","<li>Take a look at the <code>.shape</code> attribute of the new dataset, to verify it worked correctly.</li>\r\n","</ul>"],"metadata":{"id":"A-AGG378osDQ"}},{"cell_type":"code","execution_count":28,"source":["# Check how many values are missing in the category_desc column\r\n","print(volunteer['category_desc'].isnull().sum())\r\n","\r\n","# Subset the volunteer dataset\r\n","volunteer_subset = volunteer[volunteer['category_desc'].notnull()]\r\n","\r\n","# Print out the shape of the subset\r\n","print(volunteer_subset.shape)"],"outputs":[{"output_type":"stream","name":"stdout","text":["48\n","(617, 35)\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9aaVVjnwpIFF","executionInfo":{"status":"ok","timestamp":1611497793407,"user_tz":180,"elapsed":532,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"b7fec930-9703-490d-8cde-0157febed4c3"}},{"cell_type":"markdown","source":["**Remember that you can use boolean indexing to effectively subset DataFrames.**"],"metadata":{"id":"BvkDZOz9pMRM"}},{"cell_type":"markdown","source":["## Working with data types\r\n"],"metadata":{"id":"tx3CeuQIqEdF"}},{"cell_type":"markdown","source":["### Exploring data types\r\n"],"metadata":{"id":"ru5ArrLHqHEF"}},{"cell_type":"markdown","source":["<div class=\"\"><p>Taking another look at the dataset comprised of volunteer information from New York City, we want to know what types we'll be working with as we start to do more preprocessing.</p>\r\n","<p>Which data types are present in the <code>volunteer</code> dataset?</p>\r\n","<ul>\r\n","<li>The dataset <code>volunteer</code> has been provided.</li>\r\n","<li>Use the <code>.dtypes</code> attribute to check the datatypes.</li>\r\n","</ul></div>"],"metadata":{"id":"KVY3-Om9qKMV"}},{"cell_type":"markdown","source":["<pre>\r\n","Possible Answers\r\n","\r\n","Float and int only\r\n","\r\n","Int only\r\n","\r\n","<b>Float, int, and object</b>\r\n","\r\n","Float only\r\n","</pre>"],"metadata":{"id":"c2OKxw4sqVgr"}},{"cell_type":"code","execution_count":17,"source":["volunteer.dtypes"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["opportunity_id          int64\n","content_id              int64\n","vol_requests            int64\n","event_time              int64\n","title                  object\n","hits                    int64\n","summary                object\n","is_priority            object\n","category_id           float64\n","category_desc          object\n","amsl                  float64\n","amsl_unit             float64\n","org_title              object\n","org_content_id          int64\n","addresses_count         int64\n","locality               object\n","region                 object\n","postalcode            float64\n","primary_loc           float64\n","display_url            object\n","recurrence_type        object\n","hours                   int64\n","created_date           object\n","last_modified_date     object\n","start_date_date        object\n","end_date_date          object\n","status                 object\n","Latitude              float64\n","Longitude             float64\n","Community Board       float64\n","Community Council     float64\n","Census Tract          float64\n","BIN                   float64\n","BBL                   float64\n","NTA                   float64\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":17}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33PLcN-6qSe8","executionInfo":{"status":"ok","timestamp":1611496325784,"user_tz":180,"elapsed":548,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"4b921678-9ead-4ad1-b01a-0e77f924d374"}},{"cell_type":"markdown","source":["**All three of these types are present in the DataFrame.**"],"metadata":{"id":"k-ZahriCqonw"}},{"cell_type":"markdown","source":["### Converting a column type\r\n"],"metadata":{"id":"_HYxLUUEqvpQ"}},{"cell_type":"markdown","source":["<p>If you take a look at the <code>volunteer</code> dataset types, you'll see that the column <code>hits</code> is type <code>object</code>. But, if you actually look at the column, you'll see that it consists of integers. Let's convert that column to type <code>int</code>.</p>"],"metadata":{"id":"nl_cpXd1qyDI"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Take a look at the <code>.head()</code> of the <code>hits</code> column.</li>\r\n","<li>Use the <code>.astype</code> function to convert the column to type <code>int</code>.</li>\r\n","<li>Take a look at the <code>dtypes</code> of the dataset again, and notice that the column type has changed.</li>\r\n","</ul>"],"metadata":{"id":"XvaXdKgdq0BY"}},{"cell_type":"code","execution_count":29,"source":["# Print the head of the hits column\r\n","print(volunteer[\"hits\"].head())\r\n","\r\n","# Convert the hits column to type int\r\n","volunteer[\"hits\"] = volunteer[\"hits\"].astype(int)\r\n","\r\n","# Look at the dtypes of the dataset\r\n","print(volunteer.dtypes)"],"outputs":[{"output_type":"stream","name":"stdout","text":["0    737\n","1     22\n","2     62\n","3     14\n","4     31\n","Name: hits, dtype: int64\n","opportunity_id          int64\n","content_id              int64\n","vol_requests            int64\n","event_time              int64\n","title                  object\n","hits                    int64\n","summary                object\n","is_priority            object\n","category_id           float64\n","category_desc          object\n","amsl                  float64\n","amsl_unit             float64\n","org_title              object\n","org_content_id          int64\n","addresses_count         int64\n","locality               object\n","region                 object\n","postalcode            float64\n","primary_loc           float64\n","display_url            object\n","recurrence_type        object\n","hours                   int64\n","created_date           object\n","last_modified_date     object\n","start_date_date        object\n","end_date_date          object\n","status                 object\n","Latitude              float64\n","Longitude             float64\n","Community Board       float64\n","Community Council     float64\n","Census Tract          float64\n","BIN                   float64\n","BBL                   float64\n","NTA                   float64\n","dtype: object\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1MJ5-d6rrYb7","executionInfo":{"status":"ok","timestamp":1611497800195,"user_tz":180,"elapsed":545,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"b7726339-f122-432d-b256-ae6d652d4ba0"}},{"cell_type":"markdown","source":["**You can use astype to convert between a variety of types.**"],"metadata":{"id":"D-_Eueycrcwr"}},{"cell_type":"markdown","source":["## Class distribution\r\n"],"metadata":{"id":"yFpwlUJwrhAq"}},{"cell_type":"markdown","source":["###Class imbalance\r\n","<div class=\"\"><p>In the <code>volunteer</code> dataset, we're thinking about trying to predict the <code>category_desc</code> variable using the other features in the dataset. First, though, we need to know what the class distribution (and imbalance) is for that label.</p>\r\n","<p>Which descriptions occur less than 50 times in the <code>volunteer</code> dataset?</p>\r\n","<ul>\r\n","<li>The dataset <code>volunteer</code> has been provided.</li>\r\n","<li>The colum you want to check is <code>category_desc</code>.</li>\r\n","<li>Use the <code>value_counts()</code> method to check variable counts.</li>\r\n","</ul></div>"],"metadata":{"id":"rt-KVR-lsuhB"}},{"cell_type":"markdown","source":["<pre>\r\n","Possible Answers\r\n","\r\n","Emergency Preparedness\r\n","\r\n","Health\r\n","\r\n","Environment\r\n","\r\n","<b>1 and 3</b>\r\n","\r\n","All of the above\r\n","\r\n","</pre>"],"metadata":{"id":"XaVuQYR1s4Iw"}},{"cell_type":"code","execution_count":21,"source":["volunteer['category_desc'].value_counts()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["Strengthening Communities    307\n","Helping Neighbors in Need    119\n","Education                     92\n","Health                        52\n","Environment                   32\n","Emergency Preparedness        15\n","Name: category_desc, dtype: int64"]},"metadata":{"tags":[]},"execution_count":21}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pYoyDF_GtEd9","executionInfo":{"status":"ok","timestamp":1611496995919,"user_tz":180,"elapsed":533,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"4336b821-9020-4f4c-f493-1ab843efc417"}},{"cell_type":"markdown","source":["**Both Emergency Prepardness and Environment occur less than 50 times.**"],"metadata":{"id":"DQiUvoJqtjfz"}},{"cell_type":"markdown","source":["### Stratified sampling\r\n"],"metadata":{"id":"-1VeIAEety9y"}},{"cell_type":"markdown","source":["<p>We know that the distribution of variables in the <code>category_desc</code> column in the <code>volunteer</code> dataset is uneven. If we wanted to train a model to try to predict <code>category_desc</code>, we would want to train the model on a sample of data that is representative of the entire dataset. Stratified sampling is a way to achieve this.</p>"],"metadata":{"id":"0PhahHO2t1-C"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Create a <code>volunteer_X</code> dataset with all of the columns except <code>category_desc</code>.</li>\r\n","<li>Create a <code>volunteer_y</code> training labels dataset.</li>\r\n","<li>Split up the <code>volunteer_X</code> dataset using scikit-learn's <code>train_test_split</code> function and passing <code>volunteer_y</code> into the <code>stratify=</code> parameter.</li>\r\n","<li>Take a look at the <code>category_desc</code> value counts on the training labels.</li>\r\n","</ul>"],"metadata":{"id":"k5BnUWist4ho"}},{"cell_type":"code","execution_count":32,"source":["from sklearn.model_selection import train_test_split\r\n","volunteer = volunteer.dropna(subset=['category_desc'], axis=0)"],"outputs":[],"metadata":{"id":"0d_Dtt_NwyWs","executionInfo":{"status":"ok","timestamp":1611497944389,"user_tz":180,"elapsed":522,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"code","execution_count":33,"source":["# Create a data with all columns except category_desc\r\n","volunteer_X = volunteer.drop('category_desc', axis=1)\r\n","\r\n","# Create a category_desc labels dataset\r\n","volunteer_y = volunteer[['category_desc']]\r\n","\r\n","# Use stratified sampling to split up the dataset according to the volunteer_y dataset\r\n","X_train, X_test, y_train, y_test = train_test_split(volunteer_X, volunteer_y, stratify=volunteer_y)\r\n","\r\n","# Print out the category_desc counts on the training y labels\r\n","print(y_train['category_desc'].value_counts())"],"outputs":[{"output_type":"stream","name":"stdout","text":["Strengthening Communities    230\n","Helping Neighbors in Need     89\n","Education                     69\n","Health                        39\n","Environment                   24\n","Emergency Preparedness        11\n","Name: category_desc, dtype: int64\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9aXgfZvfv5SB","executionInfo":{"status":"ok","timestamp":1611497945761,"user_tz":180,"elapsed":763,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"6f3701bb-5f7e-4b0f-e4a8-a45f66f01c2d"}},{"cell_type":"markdown","source":["**You'll use train_test_split frequently while building models, so it's useful to be familiar with the function.**"],"metadata":{"id":"H-NQu44uvcSV"}}]}