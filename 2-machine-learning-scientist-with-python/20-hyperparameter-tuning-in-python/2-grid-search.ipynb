{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"2-grid-search.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN/tHLPEFJo0rrD5gWpt8qV"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["# Grid search\r\n",">  This chapter introduces you to a popular automated hyperparameter tuning methodology called Grid Search. You will learn what it is, how it works and practice undertaking a Grid Search using Scikit Learn. You will then learn how to analyze the output of a Grid Search & gain practical experience doing this.\r\n","\r\n","- toc: true \r\n","- badges: true\r\n","- comments: true\r\n","- author: Lucas Nunes\r\n","- categories: [Datacamp]\r\n","- image: images/datacamp/___"],"metadata":{"id":"f5FTJNcbC9gb"}},{"cell_type":"markdown","source":["> Note: This is a summary of the course's chapter 2 exercises \"Hyperparameter Tuning in Python\" at datacamp. <br>[Github repo](https://github.com/lnunesAI/Datacamp/) / [Course link](https://www.datacamp.com/tracks/machine-learning-scientist-with-python)"],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","plt.rcParams['figure.figsize'] = (8, 8)"],"outputs":[],"metadata":{"id":"7SbXqsjxFOUG","executionInfo":{"status":"ok","timestamp":1614139854270,"user_tz":180,"elapsed":636,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["## Introducing Grid Search"],"metadata":{"id":"UvrKEMkeEF2g"}},{"cell_type":"markdown","source":["### Build Grid Search functions"],"metadata":{"id":"Ho1eZTss8AvH"}},{"cell_type":"markdown","source":["<div class=\"\"><p>In data science it is a great idea to try building algorithms, models and processes 'from scratch' so you can really understand what is happening at a deeper level. Of course there are great packages and libraries for this work (and we will get to that very soon!) but building from scratch will give you a great edge in your data science work.</p>\r\n","<p>In this exercise, you will create a function to take in 2 hyperparameters, build models and return results. You will use this function in a future exercise.</p>\r\n","<p>You will have available the <code>X_train</code>, <code>X_test</code>, <code>y_train</code> and <code>y_test</code> datasets available.</p></div>"],"metadata":{"id":"eHNv9JJKYVgR"}},{"cell_type":"code","execution_count":3,"source":["from sklearn.model_selection import train_test_split\r\n","df = pd.read_csv('https://github.com/lnunesAI/Datacamp/raw/main/2-machine-learning-scientist-with-python/20-hyperparameter-tuning-in-python/datasets/credit-card-full.csv')\r\n","df = pd.get_dummies(df, columns=['SEX', 'EDUCATION', 'MARRIAGE'], drop_first=True)\r\n","X = df.drop(['ID', 'default payment next month'], axis=1)\r\n","y = df['default payment next month']\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)"],"outputs":[],"metadata":{"id":"93egt-klHM0x","executionInfo":{"status":"ok","timestamp":1614139856825,"user_tz":180,"elapsed":1767,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Build a function that takes two parameters called <code>learn_rate</code> and <code>max_depth</code> for the learning rate and maximum depth.</li>\r\n","<li>Add capability in the function to build a GBM model and fit it to the data with the input hyperparameters.</li>\r\n","<li>Have the function return the results of that model and the chosen hyperparameters (<code>learn_rate</code> and <code>max_depth</code>).</li>\r\n","</ul>"],"metadata":{"id":"_Hr8twW4YXD6"}},{"cell_type":"code","execution_count":null,"source":["# Create the function\r\n","def gbm_grid_search(learn_rate, max_depth):\r\n","\r\n","\t# Create the model\r\n","    model = GradientBoostingClassifier(learning_rate=learn_rate, max_depth=max_depth)\r\n","    \r\n","    # Use the model to make predictions\r\n","    predictions = model.fit(X_train, y_train).predict(X_test)\r\n","    \r\n","    # Return the hyperparameters and score\r\n","    return([learn_rate, max_depth, accuracy_score(y_test, predictions)])"],"outputs":[],"metadata":{"id":"3Yi6fhDNYTbB"}},{"cell_type":"markdown","source":["**You now have a function you can call to test different combinations of two hyperparameters for the GBM algorithm. In the next exercise we will use it to test some values and analyze the results.**"],"metadata":{"id":"jHxgi-aZZX21"}},{"cell_type":"markdown","source":["### Iteratively tune multiple hyperparameters"],"metadata":{"id":"hR934PS1ZZ61"}},{"cell_type":"markdown","source":["<div class=\"\"><p>In this exercise, you will build on the function you previously created to take in 2 hyperparameters, build a model and return the results. You will now use that to loop through some values and then extend this function and loop with another hyperparameter.</p>\r\n","<p>The function <code>gbm_grid_search(learn_rate, max_depth)</code> is available in this exercise.</p>\r\n","<p>If you need to remind yourself of the function you can run the function <code>print_func()</code> that has been created for you</p></div>"],"metadata":{"id":"zesKy1_VZe9x"}},{"cell_type":"code","execution_count":null,"source":["from sklearn.ensemble import GradientBoostingClassifier\r\n","from sklearn.metrics import accuracy_score"],"outputs":[],"metadata":{"id":"vheGZRplHtZL"}},{"cell_type":"markdown","source":["Instructions 1/3\r\n","<li>Write a for-loop to test the values (0.01, 0.1, 0.5) for the <code>learning_rate</code> and (2, 4, 6) for the <code>max_depth</code> using the function you created <code>gbm_grid_search</code> and print the results.</li>"],"metadata":{"id":"iQZhYe73ZiNO"}},{"cell_type":"code","execution_count":null,"source":["# Create the relevant lists\r\n","results_list = []\r\n","learn_rate_list = [0.01, 0.1, 0.5]\r\n","max_depth_list = [2, 4, 6]\r\n","\r\n","# Create the for loop\r\n","for learn_rate in learn_rate_list:\r\n","    for max_depth in max_depth_list:\r\n","        results_list.append(gbm_grid_search(learn_rate,max_depth))\r\n","\r\n","# Print the results\r\n","results_list"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0.01, 2, 0.8176666666666667],\n"," [0.01, 4, 0.817],\n"," [0.01, 6, 0.8146666666666667],\n"," [0.1, 2, 0.8183333333333334],\n"," [0.1, 4, 0.8182222222222222],\n"," [0.1, 6, 0.8145555555555556],\n"," [0.5, 2, 0.8171111111111111],\n"," [0.5, 4, 0.801],\n"," [0.5, 6, 0.7867777777777778]]"]},"metadata":{"tags":[]},"execution_count":26}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FLHInGz-IOyl","executionInfo":{"status":"ok","timestamp":1614106086900,"user_tz":180,"elapsed":148353,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"2f1e0f04-0eb2-469d-9ffd-e34fc4afd55b"}},{"cell_type":"markdown","source":["Instructions 2/3\r\n","<li>Extend the <code>gbm_grid_search</code> function to include the hyperparameter <code>subsample</code>. Name this new function <code>gbm_grid_search_extended</code>.</li>"],"metadata":{"id":"Nst1jQeNZiNU"}},{"cell_type":"code","execution_count":null,"source":["results_list = []\r\n","\r\n","# Extend the function input\r\n","def gbm_grid_search_extended(learn_rate, max_depth, subsample):\r\n","\r\n","\t# Extend the model creation section\r\n","    model = GradientBoostingClassifier(learning_rate=learn_rate, max_depth=max_depth, subsample=subsample)\r\n","    \r\n","    predictions = model.fit(X_train, y_train).predict(X_test)\r\n","    \r\n","    # Extend the return part\r\n","    return([learn_rate, max_depth, subsample, accuracy_score(y_test, predictions)])       "],"outputs":[],"metadata":{"id":"yfc4xY5cacha"}},{"cell_type":"markdown","source":["Instructions 3/3\r\n","<li>Extend your loop to call <code>gbm_grid_search</code> (available in your console), then test the values [0.4 , 0.6] for the <code>subsample</code> hyperparameter and print the results. <code>max_depth_list</code> &amp; <code>learn_rate_list</code> are available in your environment.</li>"],"metadata":{"id":"xdhGqNQ9ZiNV"}},{"cell_type":"code","execution_count":null,"source":["results_list = []\r\n","\r\n","# Create the new list to test\r\n","subsample_list = [0.4 , 0.6]\r\n","\r\n","for learn_rate in learn_rate_list:\r\n","    for max_depth in max_depth_list:\r\n","    \r\n","    \t# Extend the for loop\r\n","        for subsample in subsample_list:\r\n","        \t\r\n","            # Extend the results to include the new hyperparameter\r\n","            results_list.append(gbm_grid_search_extended(learn_rate, max_depth, subsample))\r\n","            \r\n","# Print results\r\n","results_list    "],"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0.01, 2, 0.4, 0.816],\n"," [0.01, 2, 0.6, 0.8173333333333334],\n"," [0.01, 4, 0.4, 0.8156666666666667],\n"," [0.01, 4, 0.6, 0.8168888888888889],\n"," [0.01, 6, 0.4, 0.8143333333333334],\n"," [0.01, 6, 0.6, 0.8152222222222222],\n"," [0.1, 2, 0.4, 0.8181111111111111],\n"," [0.1, 2, 0.6, 0.8191111111111111],\n"," [0.1, 4, 0.4, 0.8186666666666667],\n"," [0.1, 4, 0.6, 0.8178888888888889],\n"," [0.1, 6, 0.4, 0.8118888888888889],\n"," [0.1, 6, 0.6, 0.8132222222222222],\n"," [0.5, 2, 0.4, 0.8127777777777778],\n"," [0.5, 2, 0.6, 0.8134444444444444],\n"," [0.5, 4, 0.4, 0.7926666666666666],\n"," [0.5, 4, 0.6, 0.7917777777777778],\n"," [0.5, 6, 0.4, 0.7808888888888889],\n"," [0.5, 6, 0.6, 0.7721111111111111]]"]},"metadata":{"tags":[]},"execution_count":28}],"metadata":{"id":"rHY9n3S_avN-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614106244955,"user_tz":180,"elapsed":158042,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"e40688d7-5bd0-476d-a2c1-8f9abe9d8598"}},{"cell_type":"markdown","source":["**You have effectively built your own grid search! You went from 2 to 3 hyperparameters and can see how you could extend that to even more values and hyperparameters. That was a lot of effort though. Be warned - we are now entering a world that can get very computationally expensive very fast!**"],"metadata":{"id":"1buQ-OA4azCO"}},{"cell_type":"markdown","source":["### How Many Models?"],"metadata":{"id":"YzCF44H1bMr_"}},{"cell_type":"markdown","source":["<div class=\"\"><p>Adding more hyperparameters or values, you increase the amount of models created but the increases is not linear it is proportional to how many values and hyperparameters you already have.</p>\r\n","<p>How many models would be created when running a grid search over the following hyperparameters and values for a GBM algorithm?</p>\r\n","<ul>\r\n","<li>learning_rate = [0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 1, 2]</li>\r\n","<li>max_depth = [4,6,8,10,12,14,16,18, 20]</li>\r\n","<li>subsample = [0.4, 0.6, 0.7, 0.8, 0.9]</li>\r\n","<li>max_features = ['auto', 'sqrt', 'log2']</li>\r\n","</ul>\r\n","<p>These lists are in your console so you can utilize properties of them to help you!</p></div>"],"metadata":{"id":"0146okiPbPRH"}},{"cell_type":"code","execution_count":null,"source":["9*9*5*3"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["1215"]},"metadata":{"tags":[]},"execution_count":29}],"metadata":{"id":"41GjjTXebqUg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614106244956,"user_tz":180,"elapsed":58979,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"823501fe-d4ea-48db-f689-7c5f4275981f"}},{"cell_type":"markdown","source":["<pre>\r\n","Possible Answers\r\n","26\r\n","9 of one model, 9 of another\r\n","1 large model\r\n","<b>1215</b>\r\n","</pre>"],"metadata":{"id":"VL2r2Dxhb0l8"}},{"cell_type":"markdown","source":["**For every value of one hyperparameter, we test EVERY value of EVERY other hyperparameter. So you correctly multiplied the number of values (the lengths of the lists).**"],"metadata":{"id":"Pc6lOA9PbwSS"}},{"cell_type":"markdown","source":["## Grid Search with Scikit Learn"],"metadata":{"id":"WBatgzA0QyWN"}},{"cell_type":"markdown","source":["### GridSearchCV inputs"],"metadata":{"id":"gsD6Asg1d3E2"}},{"cell_type":"markdown","source":["<div class=\"\"><p>Let's test your knowledge of <code>GridSeachCV</code> inputs by answering the question below.</p>\r\n","<p>Three <code>GridSearchCV</code> objects are available in the console, named <code>model_1</code>, <code>model_2</code>, <code>model_3</code>. Note that there is no data available to fit these models. Instead, you must answer by looking at their construct.</p>\r\n","<p>Which of these <code>GridSearchCV</code> objects would not work when we try to fit it?</p></div>"],"metadata":{"id":"9BWunD7Kd5rh"}},{"cell_type":"markdown","source":["Model 1:\r\n"," GridSearchCV(\r\n","    estimator = RandomForestClassifier(),\r\n","    param_grid = {'max_depth': [2, 4, 8, 15], 'max_features': ['auto', 'sqrt']},\r\n","    scoring='roc_auc',\r\n","    n_jobs=4,\r\n","    cv=5,\r\n","    refit=True, return_train_score=True) \r\n","\r\n","\r\n","Model 2:\r\n"," GridSearchCV(\r\n","    estimator = KNeighborsClassifier(),\r\n","    param_grid = {'n_neighbors': [5, 10, 20], 'algorithm': ['ball_tree', 'brute']},\r\n","    scoring='accuracy',\r\n","    n_jobs=8,\r\n","    cv=10,\r\n","    refit=False) \r\n","\r\n","\r\n","Model 3:\r\n"," GridSearchCV(\r\n","    estimator = GradientBoostingClassifier(),\r\n","    param_grid = {'number_attempts': [2, 4, 6], 'max_depth': [3, 6, 9, 12]},\r\n","    scoring='accuracy',\r\n","    n_jobs=2,\r\n","    cv=7,\r\n","    refit=True) "],"metadata":{"id":"ir1DdocSeIam"}},{"cell_type":"markdown","source":["<pre>\r\n","Possible Answers\r\n","model_1 would not work when we try to fit it.\r\n","model_2 would not work when we try to fit it.\r\n","<b>model_3 would not work when we try to fit it.</b>\r\n","None - they will all work when we try to fit them.\r\n","</pre>"],"metadata":{"id":"BHzMqJMufATv"}},{"cell_type":"markdown","source":["**By looking at the Scikit Learn documentation (or your excellent memory!) you know that number_attempts is not a valid hyperparameter. This GridSearchCV will not fit to our data.**"],"metadata":{"id":"kGFwEjV8e7yN"}},{"cell_type":"markdown","source":["### GridSearchCV with Scikit Learn"],"metadata":{"id":"lVcvfRc5fNEL"}},{"cell_type":"markdown","source":["<div class=\"\"><p>The <code>GridSearchCV</code> module from Scikit Learn provides many useful features to assist with efficiently undertaking a grid search. You will now put your learning into practice by creating a <code>GridSearchCV</code> object with certain parameters.</p>\r\n","<p>The desired options are:</p>\r\n","<ul>\r\n","<li>A Random Forest Estimator, with the split criterion as 'entropy'</li>\r\n","<li>5-fold cross validation</li>\r\n","<li>The hyperparameters <code>max_depth</code> (2, 4, 8, 15) and <code>max_features</code> ('auto' vs 'sqrt')</li>\r\n","<li>Use <code>roc_auc</code> to score the models</li>\r\n","<li>Use 4 cores for processing in parallel</li>\r\n","<li>Ensure you refit the best model and return training scores</li>\r\n","</ul>\r\n","<p>You will have available <code>X_train</code>, <code>X_test</code>, <code>y_train</code> &amp; <code>y_test</code> datasets.</p></div>"],"metadata":{"id":"P_IKMh5MfY42"}},{"cell_type":"code","execution_count":null,"source":["from sklearn.model_selection import GridSearchCV\r\n","from sklearn.ensemble import RandomForestClassifier"],"outputs":[],"metadata":{"id":"H5zRvMqt5hsA"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Create a Random Forest estimator as specified in the context above.</li>\r\n","<li>Create a parameter grid as specified in the context above.</li>\r\n","<li>Create a <code>GridSearchCV</code> object as outlined in the context above, using the two elements created in the previous two instructions.</li>\r\n","</ul>"],"metadata":{"id":"uOiEGPIgfanX"}},{"cell_type":"code","execution_count":null,"source":["# Create a Random Forest Classifier with specified criterion\r\n","rf_class = RandomForestClassifier(criterion='entropy')\r\n","\r\n","# Create the parameter grid\r\n","param_grid = {'max_depth': [2, 4, 8, 15], 'max_features': ['auto', 'sqrt']} \r\n","\r\n","# Create a GridSearchCV object\r\n","grid_rf_class = GridSearchCV(\r\n","    estimator=rf_class,\r\n","    param_grid=param_grid,\r\n","    scoring='roc_auc',\r\n","    n_jobs=4,\r\n","    cv=5,\r\n","    refit=True, return_train_score=True)\r\n","print(grid_rf_class)"],"outputs":[{"output_type":"stream","name":"stdout","text":["GridSearchCV(cv=5, error_score=nan,\n","             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n","                                              class_weight=None,\n","                                              criterion='entropy',\n","                                              max_depth=None,\n","                                              max_features='auto',\n","                                              max_leaf_nodes=None,\n","                                              max_samples=None,\n","                                              min_impurity_decrease=0.0,\n","                                              min_impurity_split=None,\n","                                              min_samples_leaf=1,\n","                                              min_samples_split=2,\n","                                              min_weight_fraction_leaf=0.0,\n","                                              n_estimators=100, n_jobs=None,\n","                                              oob_score=False,\n","                                              random_state=None, verbose=0,\n","                                              warm_start=False),\n","             iid='deprecated', n_jobs=4,\n","             param_grid={'max_depth': [2, 4, 8, 15],\n","                         'max_features': ['auto', 'sqrt']},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n","             scoring='roc_auc', verbose=0)\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iz8cK_EygV9W","executionInfo":{"status":"ok","timestamp":1614117482351,"user_tz":180,"elapsed":1821,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"71519983-e024-41d1-dd31-99c66d264ecb"}},{"cell_type":"markdown","source":["**You now understand all the inputs to a GridSearchCV object and can tune many different hyperparameters and many different values for each on a chosen algorithm!**"],"metadata":{"id":"HpqSDRmsgZ3p"}},{"cell_type":"markdown","source":["## Understanding a grid search output"],"metadata":{"id":"12a2h4EJgdyK"}},{"cell_type":"markdown","source":["### Using the best outputs"],"metadata":{"id":"90pPYzsVyj6Q"}},{"cell_type":"markdown","source":["<p>Which of the following parameters must be set in order to be able to directly use the <code>best_estimator_</code> property for predictions?</p>"],"metadata":{"id":"SXIm2mY1yntv"}},{"cell_type":"markdown","source":["<pre>\r\n","Possible Answers\r\n","return_train_score = True\r\n","<b>refit = True</b>\r\n","refit = False\r\n","verbose = 1\r\n","</pre>"],"metadata":{"id":"BSAkUhuHyuix"}},{"cell_type":"markdown","source":["**When we set this to true, the creation of the grid search object automatically refits the best parameters on the whole training set and creates the best_estimator_ property.**"],"metadata":{"id":"B33A3g-PysAp"}},{"cell_type":"markdown","source":["### Exploring the grid search results"],"metadata":{"id":"2PwGIujC1tT5"}},{"cell_type":"markdown","source":["<div class=\"\"><p>You will now explore the <code>cv_results_</code> property of the GridSearchCV object defined in the video. This is a dictionary that we can read into a pandas DataFrame and contains a lot of useful information about the grid search we just undertook. </p>\r\n","<p>A reminder of the different column types in this property:</p>\r\n","<ul>\r\n","<li><code>time_</code> columns</li>\r\n","<li><code>param_</code> columns (one for each hyperparameter) and <strong>the</strong> singular <code>params</code> column (with all hyperparameter settings)</li>\r\n","<li>a <code>train_score</code> column for each cv fold including the <code>mean_train_score</code> and <code>std_train_score</code> columns</li>\r\n","<li>a <code>test_score</code> column for each cv fold including the <code>mean_test_score</code> and <code>std_test_score</code> columns</li>\r\n","<li>a <code>rank_test_score</code> column with a number from 1 to n (number of iterations) ranking the rows based on their <code>mean_test_score</code></li>\r\n","</ul></div>"],"metadata":{"id":"kbozPuwh1vpr"}},{"cell_type":"code","execution_count":null,"source":["grid_rf_class.fit(X_train, y_train)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5, error_score=nan,\n","             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n","                                              class_weight=None,\n","                                              criterion='entropy',\n","                                              max_depth=None,\n","                                              max_features='auto',\n","                                              max_leaf_nodes=None,\n","                                              max_samples=None,\n","                                              min_impurity_decrease=0.0,\n","                                              min_impurity_split=None,\n","                                              min_samples_leaf=1,\n","                                              min_samples_split=2,\n","                                              min_weight_fraction_leaf=0.0,\n","                                              n_estimators=100, n_jobs=None,\n","                                              oob_score=False,\n","                                              random_state=None, verbose=0,\n","                                              warm_start=False),\n","             iid='deprecated', n_jobs=4,\n","             param_grid={'max_depth': [2, 4, 8, 15],\n","                         'max_features': ['auto', 'sqrt']},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n","             scoring='roc_auc', verbose=0)"]},"metadata":{"tags":[]},"execution_count":8}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d4zKL1GV5zDm","executionInfo":{"status":"ok","timestamp":1614117660486,"user_tz":180,"elapsed":111538,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"eae84c4a-4b11-446c-a44c-02ed3e860c99"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Read the <code>cv_results_</code> property of the <code>grid_rf_class</code> GridSearchCV object into a data frame &amp; print the whole thing out to inspect.</li>\r\n","<li>Extract &amp; print the <strong>singular</strong> column containing a dictionary of all hyperparameters used in each iteration of the grid search.</li>\r\n","<li>Extract &amp; print the row that had the best mean test score by indexing using the <code>rank_test_score</code> column.</li>\r\n","</ul>"],"metadata":{"id":"KgPqiv4J1x1S"}},{"cell_type":"code","execution_count":null,"source":["# Read the cv_results property into a dataframe & print it out\r\n","cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\r\n","print(cv_results_df)\r\n","\r\n","# Extract and print the column with a dictionary of hyperparameters used\r\n","column = cv_results_df.loc[:, ['params']]\r\n","print(column)\r\n","\r\n","# Extract and print the row that had the best mean test score\r\n","best_row = cv_results_df[cv_results_df['rank_test_score'] == 1 ]\r\n","print(best_row)"],"outputs":[{"output_type":"stream","name":"stdout","text":["   mean_fit_time  std_fit_time  ...  mean_train_score  std_train_score\n","0       3.458513      0.285226  ...          0.769632         0.001048\n","1       3.697389      0.172889  ...          0.769441         0.001575\n","2       6.008191      0.111924  ...          0.780005         0.001331\n","3       6.044000      0.153031  ...          0.780220         0.001659\n","4      11.024294      0.151925  ...          0.830187         0.001384\n","5      11.009805      0.118585  ...          0.830242         0.001592\n","6      18.288561      0.181061  ...          0.975750         0.001260\n","7      16.278501      2.493098  ...          0.974560         0.001332\n","\n","[8 rows x 22 columns]\n","                                      params\n","0   {'max_depth': 2, 'max_features': 'auto'}\n","1   {'max_depth': 2, 'max_features': 'sqrt'}\n","2   {'max_depth': 4, 'max_features': 'auto'}\n","3   {'max_depth': 4, 'max_features': 'sqrt'}\n","4   {'max_depth': 8, 'max_features': 'auto'}\n","5   {'max_depth': 8, 'max_features': 'sqrt'}\n","6  {'max_depth': 15, 'max_features': 'auto'}\n","7  {'max_depth': 15, 'max_features': 'sqrt'}\n","   mean_fit_time  std_fit_time  ...  mean_train_score  std_train_score\n","4      11.024294      0.151925  ...          0.830187         0.001384\n","\n","[1 rows x 22 columns]\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hh3ZhXhi2Vyq","executionInfo":{"status":"ok","timestamp":1614117666217,"user_tz":180,"elapsed":661,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"8a7b3c68-9cea-45dc-aa5c-4fdfb2f7859a"}},{"cell_type":"markdown","source":["**You have built invaluable skills in looking 'under the hood' at what your grid search is doing by extracting and analysing the cv_results_ property.**"],"metadata":{"id":"SidCtxvK2Yg1"}},{"cell_type":"markdown","source":["### Analyzing the best results"],"metadata":{"id":"WT8O1Q-t2dWe"}},{"cell_type":"markdown","source":["<div class=\"\"><p>At the end of the day, we primarily care about the best performing 'square' in a grid search. Luckily Scikit Learn's <code>gridSearchCv</code> objects have a number of parameters that provide key information on just the best square (or row in <code>cv_results_</code>).</p>\r\n","<p>Three properties you will explore are:</p>\r\n","<ul>\r\n","<li><code>best_score_</code> – The score (here ROC_AUC) from the best-performing square.</li>\r\n","<li><code>best_index_</code> – The index of the row in <code>cv_results_</code> containing information on the best-performing square.</li>\r\n","<li><code>best_params_</code> – A dictionary of the parameters that gave the best score, for example <code>'max_depth': 10</code></li>\r\n","</ul>\r\n","<p>The grid search object <code>grid_rf_class</code> is available. </p>\r\n","<p>A dataframe (<code>cv_results_df</code>) has been created from the <code>cv_results_</code> for you on line 6. This will help you index into the results.</p></div>"],"metadata":{"id":"Hl1StYWU2fyY"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Extract and print out the ROC_AUC <strong>score</strong> from the <strong>best</strong> performing square in <code>grid_rf_class</code>.</li>\r\n","<li>Create a variable from the best-performing row by <strong>index</strong>ing into <code>cv_results_df</code>.</li>\r\n","<li>Create a variable, <code>best_n_estimators</code> by extracting the <code>n_estimators</code> parameter from the best-performing square in <code>grid_rf_class</code> and print it out.</li>\r\n","</ul>"],"metadata":{"id":"ioMZ98dG2hP2"}},{"cell_type":"code","execution_count":null,"source":["# Print out the ROC_AUC score from the best-performing square\r\n","best_score = grid_rf_class.best_score_\r\n","print(best_score)\r\n","\r\n","# Create a variable from the row related to the best-performing square\r\n","cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\r\n","best_row = cv_results_df.loc[[grid_rf_class.best_index_]]\r\n","print(best_row)\r\n","\r\n","# Get the n_estimators parameter from the best-performing square and print\r\n","best_n_estimators = grid_rf_class.best_params_[\"max_depth\"] #n_estimators\r\n","print(best_n_estimators)"],"outputs":[{"output_type":"stream","name":"stdout","text":["0.780853884604309\n","   mean_fit_time  std_fit_time  ...  mean_train_score  std_train_score\n","4      11.024294      0.151925  ...          0.830187         0.001384\n","\n","[1 rows x 22 columns]\n","8\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Rf7k2p24gi-","executionInfo":{"status":"ok","timestamp":1614117767717,"user_tz":180,"elapsed":640,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"f6551da3-c454-4188-dd5e-c5ce21d4e2d9"}},{"cell_type":"markdown","source":["**Being able to quickly find and prioritize the huge volume of information given back from machine learning modeling output is a great skill. Here you had great practice doing that with cv_results_ by quickly isolating the key information on the best performing square. This will be very important when your grids grow from 12 squares to many more!**"],"metadata":{"id":"9e3Ot-zW4h0N"}},{"cell_type":"markdown","source":["### Using the best results"],"metadata":{"id":"dLfIdjlr4mzX"}},{"cell_type":"markdown","source":["<div class=\"\"><p>While it is interesting to analyze the results of our grid search, our final goal is practical in nature; we want to make predictions on our test set using our estimator object.</p>\r\n","<p>We can access this object through the <code>best_estimator_</code> property of our grid search object.</p>\r\n","<p>Let's take a look inside the <code>best_estimator_</code> property, make predictions, and generate evaluation scores. We will firstly use the default <code>predict</code> (giving class predictions), but then we will need to use <code>predict_proba</code> rather than <code>predict</code> to generate the roc-auc score as roc-auc needs probability scores for its calculation. We use a slice <code>[:,1]</code> to get probabilities of the positive class.</p>\r\n","<p>You have available the <code>X_test</code> and <code>y_test</code> datasets to use and the <code>grid_rf_class</code> object from previous exercises.</p></div>"],"metadata":{"id":"sSf55pnR4pFH"}},{"cell_type":"code","execution_count":null,"source":["from sklearn.metrics import confusion_matrix, roc_auc_score"],"outputs":[],"metadata":{"id":"YeX1bwZx6lhO"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Check the type of the <code>best_estimator_</code> property.</li>\r\n","<li>Use the <code>best_estimator_</code> property to make predictions on our test set.</li>\r\n","<li>Generate a confusion matrix and ROC_AUC score from our predictions.</li>\r\n","</ul>"],"metadata":{"id":"at3ueZu74qb_"}},{"cell_type":"code","execution_count":null,"source":["# See what type of object the best_estimator_ property is\r\n","print(type(grid_rf_class.best_estimator_))\r\n","\r\n","# Create an array of predictions directly using the best_estimator_ property\r\n","predictions = grid_rf_class.best_estimator_.predict(X_test)\r\n","\r\n","# Take a look to confirm it worked, this should be an array of 1's and 0's\r\n","print(predictions[0:5])\r\n","\r\n","# Now create a confusion matrix \r\n","print(\"Confusion Matrix \\n\", confusion_matrix(y_test, predictions))\r\n","\r\n","# Get the ROC-AUC score\r\n","predictions_proba = grid_rf_class.best_estimator_.predict_proba(X_test)[:,1]\r\n","print(\"ROC-AUC Score \\n\", roc_auc_score(y_test, predictions_proba))"],"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n","[0 0 0 0 0]\n","Confusion Matrix \n"," [[6664  315]\n"," [1343  678]]\n","ROC-AUC Score \n"," 0.7763614587311805\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rjtiY0og5L5C","executionInfo":{"status":"ok","timestamp":1614117759276,"user_tz":180,"elapsed":622,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"0ab70cd8-6ae4-4d43-b57b-0a60d651ad6e"}},{"cell_type":"markdown","source":["**The .best_estimator_ property is a really powerful property to understand for streamlining your machine learning model building process. You now can run a grid search and seamlessly use the best model from that search to make predictions.**"],"metadata":{"id":"v3ne2zCF5P7r"}}]}