{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"1-introduction-to-tensorflow.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPNUAC+Y/pCJJVvQWFzXbQZ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["# Introduction to TensorFlow\r\n",">  Before you can build advanced models in TensorFlow 2, you will first need to understand the basics. In this chapter, you’ll learn how to define constants and variables, perform tensor addition and multiplication, and compute derivatives. Knowledge of linear algebra will be helpful, but not necessary.\r\n","\r\n","- toc: true \r\n","- badges: true\r\n","- comments: true\r\n","- author: Lucas Nunes\r\n","- categories: [Datacamp]\r\n","- image: images/datacamp/___"],"metadata":{"id":"f5FTJNcbC9gb"}},{"cell_type":"markdown","source":["> Note: This is a summary of the course's chapter 1 exercises \"Introduction to TensorFlow in Python\" at datacamp. <br>[Github repo](https://github.com/lnunesAI/Datacamp/) / [Course link](https://www.datacamp.com/tracks/machine-learning-scientist-with-python)"],"metadata":{}},{"cell_type":"code","execution_count":11,"source":["import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import seaborn as sns\r\n","plt.rcParams['figure.figsize'] = (8, 8)\r\n","import tensorflow as tf"],"outputs":[],"metadata":{"id":"7SbXqsjxFOUG","executionInfo":{"status":"ok","timestamp":1612965649705,"user_tz":180,"elapsed":806,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["## Constants and variables"],"metadata":{"id":"UvrKEMkeEF2g"}},{"cell_type":"markdown","source":["### Defining data as constants"],"metadata":{"id":"FPsw9_7kMuyV"}},{"cell_type":"markdown","source":["<div class=\"\"><p>Throughout this course, we will use <code>tensorflow</code> version 2.4 and will exclusively import the submodules needed to complete each exercise. This will usually be done for you, but you will do it in this exercise by importing <code>constant</code> from <code>tensorflow</code>.</p>\r\n","<p>After you have imported <code>constant</code>, you will use it to transform a <code>numpy</code> array, <code>credit_numpy</code>, into a <code>tensorflow</code> constant, <code>credit_constant</code>. This array contains feature columns from a dataset on credit card holders and is previewed in the image below. We will return to this dataset in later chapters.</p>\r\n","<p>Note that <code>tensorflow</code> 2 allows you to use data as either a <code>numpy</code> array or a <code>tensorflow</code> <code>constant</code> object. Using a <code>constant</code> will ensure that any operations performed with that object are done in <code>tensorflow</code>.  </p>\r\n","<p><img src=\"https://assets.datacamp.com/production/repositories/3953/datasets/10c0da730973582584bc227f4bca4b5510d42c9f/default_features.jpg\" alt=\"This image shows four feature columns from a dataset on credit card default: education, marriage, age, and bill amount.\"></p></div>"],"metadata":{"id":"gBLZzhyyMy4d"}},{"cell_type":"code","execution_count":2,"source":["df = pd.read_csv('https://github.com/lnunesAI/Datacamp/raw/main/2-machine-learning-scientist-with-python/14-introduction-to-tensorflow-in-python/datasets/uci_credit_card.csv')"],"outputs":[],"metadata":{"id":"IViK3IzmOrIp","executionInfo":{"status":"ok","timestamp":1612965406685,"user_tz":180,"elapsed":4885,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"code","execution_count":8,"source":["credit_numpy = df[['EDUCATION', 'MARRIAGE', 'AGE', 'BILL_AMT1']].values"],"outputs":[],"metadata":{"id":"0jAKHFG0Ov9y","executionInfo":{"status":"ok","timestamp":1612965483414,"user_tz":180,"elapsed":879,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Import the <code>constant</code> submodule from the <code>tensorflow</code> module.</li>\r\n","<li>Convert the <code>credit_numpy</code> array into a <code>constant</code> object in <code>tensorflow</code>. Do not set the data type.</li>\r\n","</ul>"],"metadata":{"id":"6HJktKyvM1Q9"}},{"cell_type":"code","execution_count":15,"source":["# Import constant from TensorFlow\r\n","from tensorflow import constant\r\n","\r\n","# Convert the credit_numpy array into a tensorflow constant\r\n","credit_constant = constant(credit_numpy)\r\n","\r\n","# Print constant datatype\r\n","print('\\n The datatype is:', credit_constant.dtype)\r\n","\r\n","# Print constant shape\r\n","print('\\n The shape is:', credit_constant.shape)"],"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," The datatype is: <dtype: 'float64'>\n","\n"," The shape is: (30000, 4)\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cXjVluUNKli","executionInfo":{"status":"ok","timestamp":1612966445171,"user_tz":180,"elapsed":884,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"c84e3984-232a-4a0e-bc31-45ad6b02ec81"}},{"cell_type":"markdown","source":["**You now understand how constants are used in tensorflow. In the following exercise, you'll practice defining variables.**"],"metadata":{"id":"Ve5t2TdrNNxs"}},{"cell_type":"markdown","source":["### Defining variables"],"metadata":{"id":"PwQedx9QPLG5"}},{"cell_type":"markdown","source":["<div class=\"\"><p>Unlike a constant, a variable's value can be modified. This will be useful when we want to train a model by updating its parameters.</p>\r\n","<p>Let's try defining and printing a variable. We'll then convert the variable to a <code>numpy</code> array, print again, and check for differences. Note that <code>Variable()</code>, which is used to create a variable tensor, has been imported from <code>tensorflow</code> and is available to use in the exercise.</p></div>"],"metadata":{"id":"bX7r8hL3PNo6"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Define a variable, <code>A1</code>, as the 1-dimensional tensor: [1, 2, 3, 4].</li>\r\n","<li>Apply <code>.numpy()</code> to <code>A1</code> and assign it to <code>B1</code>.</li>\r\n","</ul>"],"metadata":{"id":"ZAmmWL_wPPwL"}},{"cell_type":"code","execution_count":14,"source":["# Define the 1-dimensional variable A1\r\n","A1 = tf.Variable([1, 2, 3, 4])\r\n","\r\n","# Print the variable A1\r\n","print('\\n A1: ', A1)\r\n","\r\n","# Convert A1 to a numpy array and assign it to B1\r\n","B1 = A1.numpy()\r\n","\r\n","# Print B1\r\n","print('\\n B1: ', B1)"],"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," A1:  <tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>\n","\n"," B1:  [1 2 3 4]\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Eg-eMftPiQ_","executionInfo":{"status":"ok","timestamp":1612965679023,"user_tz":180,"elapsed":860,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"423c5e2d-63ea-4fb3-c00f-af1031593ae9"}},{"cell_type":"markdown","source":["**Did you notice any differences between the print statements for A1 and B1? In our next exercise, we'll review how to check the properties of a tensor after it is already defined.**"],"metadata":{"id":"c1QBh1s7PzOW"}},{"cell_type":"markdown","source":["## Basic operations"],"metadata":{"id":"KfwOoWVtQ_7l"}},{"cell_type":"markdown","source":["<p>Element-wise multiplication in TensorFlow is performed using two tensors with identical shapes. This is because the operation multiplies elements in corresponding positions in the two tensors. An example of an element-wise multiplication, denoted by the <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"2\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mo class=\"mjx-n\"><mjx-c class=\"mjx-c2299\"></mjx-c></mjx-mo></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mo>⊙</mo></math></mjx-assistive-mml></mjx-container> symbol, is shown below:</p>\r\n","\r\n","$$ \\begin{bmatrix} 1 & 2 \\\\ 2 & 1 \\end{bmatrix} \\odot \\begin{bmatrix} 3 & 1 \\\\ 2 & 5 \\end{bmatrix} = \\begin{bmatrix} 3 & 2 \\\\ 4 & 5 \\end{bmatrix} $$\r\n","\r\n","<p>In this exercise, you will perform element-wise multiplication, paying careful attention to the shape of the tensors you multiply. Note that <code>multiply()</code>, <code>constant()</code>, and <code>ones_like()</code> have been imported for you.</p>"],"metadata":{"id":"yh4hV2ypReel"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Define the tensors <code>A1</code> and <code>A23</code> as constants.</li>\r\n","<li>Set <code>B1</code> to be a tensor of ones with the same shape as <code>A1</code>.</li>\r\n","<li>Set <code>B23</code> to be a tensor of ones with the same shape as <code>A23</code>.</li>\r\n","<li>Set <code>C1</code> and <code>C23</code> equal to the element-wise products of <code>A1</code> and <code>B1</code>, and <code>A23</code> and <code>B23</code>, respectively.</li>\r\n","</ul>"],"metadata":{"id":"N2uBtS5gRnGg"}},{"cell_type":"code","execution_count":17,"source":["# Define tensors A1 and A23 as constants\r\n","A1 = constant([1, 2, 3, 4])\r\n","A23 = constant([[1, 2, 3], [1, 6, 4]])\r\n","\r\n","# Define B1 and B23 to have the correct shape\r\n","B1 = tf.ones_like(A1)\r\n","B23 = tf.ones_like(A23)\r\n","\r\n","# Perform element-wise multiplication\r\n","C1 = tf.multiply(A1, B1)\r\n","C23 = tf.multiply(A23, B23)\r\n","\r\n","# Print the tensors C1 and C23\r\n","print('\\n C1: {}'.format(C1.numpy()))\r\n","print('\\n C23: {}'.format(C23.numpy()))"],"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," C1: [1 2 3 4]\n","\n"," C23: [[1 2 3]\n"," [1 6 4]]\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q09yn7wdSouZ","executionInfo":{"status":"ok","timestamp":1612966457852,"user_tz":180,"elapsed":878,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"825196d0-1807-4166-a19a-4f740b0e5b42"}},{"cell_type":"markdown","source":["**Notice how performing element-wise multiplication with tensors of ones leaves the original tensors unchanged.**"],"metadata":{"id":"-8qiE_MhTF57"}},{"cell_type":"markdown","source":["### Making predictions with matrix multiplication"],"metadata":{"id":"tz83tjy7TJJ8"}},{"cell_type":"markdown","source":["<p>In later chapters, you will learn to train linear regression models. This process will yield a vector of parameters that can be multiplied by the input data to generate predictions. In this exercise, you will use input data, <code>features</code>, and a target vector, <code>bill</code>, which are taken from a credit card dataset we will use later in the course.</p>\r\n","\r\n","$$ \\text{features} = \\begin{bmatrix} 2 & 24 \\\\ 2 & 26 \\\\ 2 & 57 \\\\ 1 & 37 \\end{bmatrix}, \r\n","\\text{bill} = \\begin{bmatrix} 3913 \\\\ 2682 \\\\ 8617 \\\\ 64400 \\end{bmatrix}, \\text{params} = \\begin{bmatrix} 1000 \\\\ 150 \\end{bmatrix} $$\r\n","\r\n","<p>The matrix of input data, <code>features</code>, contains two columns: education level and age. The target vector, <code>bill</code>, is the size of the credit card borrower's bill. </p>\r\n","\r\n","<p>Since we have not trained the model, you will enter a guess for the values of the parameter vector, <code>params</code>. You will then use <code>matmul()</code> to perform matrix multiplication of <code>features</code> by <code>params</code> to generate predictions, <code>billpred</code>, which you will compare with <code>bill</code>. Note that we have imported <code>matmul()</code> and <code>constant()</code>.</p>"],"metadata":{"id":"EK_yzG1MTMRF"}},{"cell_type":"code","execution_count":22,"source":["# Define features, params, and bill as constants\r\n","features = constant([[2, 24], [2, 26], [2, 57], [1, 37]])\r\n","params = constant([[1000], [150]])\r\n","bill = constant([[3913], [2682], [8617], [64400]])\r\n","\r\n","# Compute billpred using features and params\r\n","billpred = tf.matmul(features, params)\r\n","\r\n","# Compute and print the error\r\n","error = bill - billpred\r\n","print(error.numpy())"],"outputs":[{"output_type":"stream","name":"stdout","text":["[[-1687]\n"," [-3218]\n"," [-1933]\n"," [57850]]\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I4pG3j-EUecn","executionInfo":{"status":"ok","timestamp":1612966926921,"user_tz":180,"elapsed":1111,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"b69664fd-b5f7-4c8f-8fe7-722ff8004e9a"}},{"cell_type":"markdown","source":["**Understanding matrix multiplication will make things simpler when we start making predictions with linear models.**"],"metadata":{"id":"9GM4XxGBUlXg"}},{"cell_type":"markdown","source":["### Summing over tensor dimensions"],"metadata":{"id":"-mKdkkGSUpPZ"}},{"cell_type":"markdown","source":["<p>You've been given a matrix, <code>wealth</code>. This contains the value of bond and stock wealth for five individuals in thousands of dollars.</p>\r\n","\r\n","$$\\text{wealth} = \\begin{bmatrix} 11 & 50 \\\\ 7 & 2 \\\\ 4 & 60 \\\\ 3 & 0 \\\\ 25 & 10 \\end{bmatrix} $$\r\n","\r\n","<p>The first column corresponds to bonds and the second corresponds to stocks. Each row gives the bond and stock wealth for a single individual. Use <code>wealth</code>, <code>reduce_sum()</code>, and <code>.numpy()</code> to determine which statements are correct about <code>wealth</code>.</p>"],"metadata":{"id":"HnFuzRvsUtwT"}},{"cell_type":"markdown","source":["Instructions\r\n","<pre>\r\n","Possible Answers\r\n","\r\n","The individual in the first row has the highest total wealth (i.e. stocks + bonds).\r\n","\r\n","Combined, the 5 individuals hold $50,000 in stocks.\r\n","\r\n","<b>Combined, the 5 individuals hold \\$50,000 in bonds.</b>\r\n","\r\n","The individual in the second row has the lowest total wealth (i.e. stocks + bonds).\r\n","\r\n","</pre>"],"metadata":{"id":"dFR4WQdIU1lF"}},{"cell_type":"code","execution_count":23,"source":["wealth = tf.constant([[11, 50], [7, 2], [4, 60], [3, 0], [25, 10]])"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(5,), dtype=int32, numpy=array([61,  9, 64,  3, 35], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":23}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jQW1tzTNVUqs","executionInfo":{"status":"ok","timestamp":1612967150571,"user_tz":180,"elapsed":820,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"f6d612f7-b371-4b8a-841f-10a194135b98"}},{"cell_type":"code","execution_count":34,"source":["tf.reduce_sum(wealth, 1)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(5,), dtype=int32, numpy=array([61,  9, 64,  3, 35], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":34}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eNtWWo3iXdE3","executionInfo":{"status":"ok","timestamp":1612967696605,"user_tz":180,"elapsed":856,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"dd6b9797-1f2f-4845-fe62-7d4ee1bd5fe2"}},{"cell_type":"code","execution_count":33,"source":["tf.reduce_sum(wealth, 0)"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 50, 122], dtype=int32)>"]},"metadata":{"tags":[]},"execution_count":33}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RD7URaJYW-oW","executionInfo":{"status":"ok","timestamp":1612967574430,"user_tz":180,"elapsed":978,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"e80a9b07-1267-44dd-e75f-e181910548b7"}},{"cell_type":"markdown","source":["**Understanding how to sum over tensor dimensions will be helpful when preparing datasets and training models.**"],"metadata":{"id":"kzNLKHCGZlcB"}},{"cell_type":"markdown","source":["## Advanced operations"],"metadata":{"id":"qhK4WBA5ZnpQ"}},{"cell_type":"markdown","source":["### Reshaping tensors"],"metadata":{"id":"022AoGGXdSBo"}},{"cell_type":"markdown","source":["<div class=\"\"><p>Later in the course, you will classify images of sign language letters using a neural network. In some cases, the network will take 1-dimensional tensors as inputs, but your data will come in the form of images, which will either be either 2- or 3-dimensional tensors, depending on whether they are grayscale or color images.</p>\r\n","<p>The figure below shows grayscale and color images of the sign language letter A. The two images have been imported for you and converted to the numpy arrays <code>gray_tensor</code> and <code>color_tensor</code>. Reshape these arrays into 1-dimensional vectors using the <code>reshape</code> operation, which has been imported for you from <code>tensorflow</code>. Note that the shape of <code>gray_tensor</code> is 28x28 and the shape of <code>color_tensor</code> is 28x28x3.</p>\r\n","<p><img src=\"https://assets.datacamp.com/production/repositories/3953/datasets/f5cd02c63926113b407c33b3f2f7f05c57d4f8b8/sign_1_10.jpg\" alt=\"This figure shows grayscale and color images of the sign language letter &quot;A&quot;.\"></p></div>"],"metadata":{"id":"v2ZKSU5QdWr-"}},{"cell_type":"code","execution_count":52,"source":["!wget https://github.com/lnunesAI/Datacamp/raw/main/2-machine-learning-scientist-with-python/14-introduction-to-tensorflow-in-python/datasets/color_tensor.npz\r\n","!wget https://github.com/lnunesAI/Datacamp/raw/main/2-machine-learning-scientist-with-python/14-introduction-to-tensorflow-in-python/datasets/gray_tensor.npz\r\n","\r\n","color_tensor = np.load('/content/color_tensor.npz')\r\n","gray_tensor = np.load('/content/gray_tensor.npz')\r\n","color_tensor = color_tensor.f.arr_0\r\n","gray_tensor = gray_tensor.f.arr_0"],"outputs":[{"output_type":"stream","name":"stdout","text":["--2021-02-10 15:18:19--  https://github.com/lnunesAI/Datacamp/raw/main/2-machine-learning-scientist-with-python/14-introduction-to-tensorflow-in-python/datasets/color_tensor.npz\n","Resolving github.com (github.com)... 13.114.40.48\n","Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/lnunesAI/Datacamp/main/2-machine-learning-scientist-with-python/14-introduction-to-tensorflow-in-python/datasets/color_tensor.npz [following]\n","--2021-02-10 15:18:19--  https://raw.githubusercontent.com/lnunesAI/Datacamp/main/2-machine-learning-scientist-with-python/14-introduction-to-tensorflow-in-python/datasets/color_tensor.npz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19080 (19K) [application/octet-stream]\n","Saving to: ‘color_tensor.npz.1’\n","\n","color_tensor.npz.1  100%[===================>]  18.63K  --.-KB/s    in 0.001s  \n","\n","2021-02-10 15:18:21 (15.8 MB/s) - ‘color_tensor.npz.1’ saved [19080/19080]\n","\n","--2021-02-10 15:18:21--  https://github.com/lnunesAI/Datacamp/raw/main/2-machine-learning-scientist-with-python/14-introduction-to-tensorflow-in-python/datasets/gray_tensor.npz\n","Resolving github.com (github.com)... 13.114.40.48\n","Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/lnunesAI/Datacamp/main/2-machine-learning-scientist-with-python/14-introduction-to-tensorflow-in-python/datasets/gray_tensor.npz [following]\n","--2021-02-10 15:18:21--  https://raw.githubusercontent.com/lnunesAI/Datacamp/main/2-machine-learning-scientist-with-python/14-introduction-to-tensorflow-in-python/datasets/gray_tensor.npz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6536 (6.4K) [application/octet-stream]\n","Saving to: ‘gray_tensor.npz.1’\n","\n","gray_tensor.npz.1   100%[===================>]   6.38K  --.-KB/s    in 0s      \n","\n","2021-02-10 15:18:21 (71.2 MB/s) - ‘gray_tensor.npz.1’ saved [6536/6536]\n","\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GQkQRxiaftK0","executionInfo":{"status":"ok","timestamp":1612970303629,"user_tz":180,"elapsed":2983,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"9bbab358-5592-495c-9b34-4e814ecdd47f"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Reshape <code>gray_tensor</code> from a 28x28 matrix into a 784x1 vector named <code>gray_vector</code>.</li>\r\n","<li>Reshape <code>color_tensor</code> from a 28x28x3 tensor into a 2352x1 vector named <code>color_vector</code>.</li>\r\n","</ul>"],"metadata":{"id":"LZbThWV8deeo"}},{"cell_type":"code","execution_count":54,"source":["# Reshape the grayscale image tensor into a vector\r\n","gray_vector = tf.reshape(gray_tensor, (28*28, 1))\r\n","\r\n","# Reshape the color image tensor into a vector\r\n","color_vector = tf.reshape(color_tensor, (28*28*3, 1))"],"outputs":[],"metadata":{"id":"plLdEjbDeOk4","executionInfo":{"status":"ok","timestamp":1612970319076,"user_tz":180,"elapsed":1030,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"code","execution_count":58,"source":["gray_vector.shape, color_vector.shape"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([784, 1]), TensorShape([2352, 1]))"]},"metadata":{"tags":[]},"execution_count":58}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5gz-zaehetN","executionInfo":{"status":"ok","timestamp":1612970337493,"user_tz":180,"elapsed":939,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"54c904f9-465c-48a9-e401-b50958ee1d46"}},{"cell_type":"markdown","source":["**Notice that there are 3 times as many elements in color_vector as there are in gray_vector, since color_tensor has 3 color channels.**"],"metadata":{"id":"p8Hvz1PWeSgp"}},{"cell_type":"markdown","source":["### Optimizing with gradients"],"metadata":{"id":"K2anMp4Chnn2"}},{"cell_type":"markdown","source":["<div class=\"\"><p>You are given a loss function, <mjx-container class=\"MathJax CtxtMenu_Attached_0\" jax=\"CHTML\" role=\"presentation\" tabindex=\"0\" ctxtmenu_counter=\"8\" style=\"font-size: 116.7%; position: relative;\"><mjx-math class=\"MJX-TEX\" aria-hidden=\"true\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D466 TEX-I\"></mjx-c></mjx-mi><mjx-mo class=\"mjx-n\" space=\"4\"><mjx-c class=\"mjx-c3D\"></mjx-c></mjx-mo><mjx-msup space=\"4\"><mjx-mi class=\"mjx-i\"><mjx-c class=\"mjx-c1D465 TEX-I\"></mjx-c></mjx-mi><mjx-script style=\"vertical-align: 0.363em;\"><mjx-texatom size=\"s\" texclass=\"ORD\"><mjx-mn class=\"mjx-n\"><mjx-c class=\"mjx-c32\"></mjx-c></mjx-mn></mjx-texatom></mjx-script></mjx-msup></mjx-math><mjx-assistive-mml role=\"presentation\" unselectable=\"on\" display=\"inline\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mi>y</mi><mo>=</mo><msup><mi>x</mi><mrow><mn>2</mn></mrow></msup></math></mjx-assistive-mml></mjx-container>, which you want to minimize. You can do this by computing the slope using the <code>GradientTape()</code> operation at different values of <code>x</code>. If the slope is positive, you can decrease the loss by lowering <code>x</code>. If it is negative, you can decrease it by increasing <code>x</code>. This is how gradient descent works.</p>\r\n","<p><img src=\"https://assets.datacamp.com/production/repositories/3953/datasets/4a3d06616c28aed697d57914a26da3d831bac83c/gradient_plot.png\" alt=\"The image shows a plot of y equals x squared. It also shows the gradient at x equals -1, x equals 0, and x equals 1.\"></p>\r\n","<p>In practice, you will use a high level <code>tensorflow</code> operation to perform gradient descent automatically. In this exercise, however, you will compute the slope at <code>x</code> values of -1, 1, and 0. The following operations are available: <code>GradientTape()</code>, <code>multiply()</code>, and <code>Variable()</code>.</p></div>"],"metadata":{"id":"VRvlUXyNhp2P"}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>Define <code>x</code> as a variable with the initial value <code>x0</code>.</li>\r\n","<li>Set the loss function, <code>y</code>, equal to <code>x</code> multiplied by <code>x</code>. Do not make use of operator overloading.</li>\r\n","<li>Set the function to return the gradient of <code>y</code> with respect to <code>x</code>.</li>\r\n","</ul>"],"metadata":{"id":"ClzejLmwhrxw"}},{"cell_type":"code","execution_count":62,"source":["def compute_gradient(x0):\r\n","  \t# Define x as a variable with an initial value of x0\r\n","\tx = tf.Variable(x0)\r\n","\twith tf.GradientTape() as tape:\r\n","\t\ttape.watch(x)\r\n","        # Define y using the multiply operation\r\n","\t\ty = tf.multiply(x, x)\r\n","    # Return the gradient of y with respect to x\r\n","\treturn tape.gradient(y, x).numpy()\r\n","\r\n","# Compute and print gradients at x = -1, 1, and 0\r\n","print(compute_gradient(-1.0))\r\n","print(compute_gradient(1.0))\r\n","print(compute_gradient(0.0))"],"outputs":[{"output_type":"stream","name":"stdout","text":["-2.0\n","2.0\n","0.0\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HzXdLca8iIPw","executionInfo":{"status":"ok","timestamp":1612970556263,"user_tz":180,"elapsed":994,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"74dc4c74-8e66-4819-842a-cd0f057f50e8"}},{"cell_type":"markdown","source":["**Notice that the slope is positive at x = 1, which means that we can lower the loss by reducing x. The slope is negative at x = -1, which means that we can lower the loss by increasing x. The slope at x = 0 is 0, which means that we cannot lower the loss by either increasing or decreasing x. This is because the loss is minimized at x = 0.**"],"metadata":{"id":"WgX9Rl5eiLhR"}},{"cell_type":"markdown","source":["### Working with image data"],"metadata":{"id":"GhrqFAXkiunU"}},{"cell_type":"markdown","source":["<div class=\"\"><p>You are given a black-and-white image of a letter, which has been encoded as a tensor, <code>letter</code>. You want to determine whether the letter is an X or a K. You don't have a trained neural network, but you do have a simple model, <code>model</code>, which can be used to classify <code>letter</code>.</p>\r\n","<p>The 3x3 tensor, <code>letter</code>, and the 1x3 tensor, <code>model</code>, are available in the Python shell. You can determine whether <code>letter</code> is a K by multiplying <code>letter</code> by <code>model</code>, summing over the result, and then checking if it is equal to 1. As with more complicated models, such as neural networks, <code>model</code> is a collection of weights, arranged in a tensor.</p>\r\n","<p>Note that the functions <code>reshape()</code>, <code>matmul()</code>, and <code>reduce_sum()</code> have been imported from <code>tensorflow</code> and are available for use.</p></div>"],"metadata":{"id":"VWkIxYjKixIF"}},{"cell_type":"code","execution_count":64,"source":["letter = np.array([[1.0, 0, 1.0], [1., 1., 0], [1., 0, 1.] ])\r\n","model = np.array([[1., 0., -1.]])"],"outputs":[],"metadata":{"id":"PMuSBvTKjrNG","executionInfo":{"status":"ok","timestamp":1612970900216,"user_tz":180,"elapsed":842,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}}},{"cell_type":"markdown","source":["Instructions\r\n","<ul>\r\n","<li>The model, <code>model</code>, is 1x3 tensor, but should be a 3x1. Reshape <code>model</code>.</li>\r\n","<li>Perform a matrix multiplication of the 3x3 tensor, <code>letter</code>, by the 3x1 tensor, <code>model</code>.</li>\r\n","<li>Sum over the resulting tensor, <code>output</code>, and assign this value to <code>prediction</code>.</li>\r\n","<li>Print <code>prediction</code> using the <code>.numpy()</code> method to determine whether <code>letter</code> is K.</li>\r\n","</ul>"],"metadata":{"id":"xRSrVCxfiypV"}},{"cell_type":"code","execution_count":68,"source":["# Reshape model from a 1x3 to a 3x1 tensor\r\n","model = tf.reshape(model, (3, 1))\r\n","\r\n","# Multiply letter by model\r\n","output = tf.matmul(letter, model)\r\n","\r\n","# Sum over output and print prediction using the numpy method\r\n","prediction =  tf.reduce_sum(output)\r\n","print(prediction.numpy())"],"outputs":[{"output_type":"stream","name":"stdout","text":["1.0\n"]}],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fvIDulL_jkoU","executionInfo":{"status":"ok","timestamp":1612970921512,"user_tz":180,"elapsed":993,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"0536e247-abc3-4931-9fa6-8bd7ad4c9186"}},{"cell_type":"markdown","source":["**Your model found that prediction=1.0 and correctly classified the letter as a K. In the coming chapters, you will use data to train a model, model, and then combine this with matrix multiplication, matmul(letter, model), as we have done here, to make predictions about the classes of objects.**"],"metadata":{"id":"iDOPqy8Ljygw"}}]}