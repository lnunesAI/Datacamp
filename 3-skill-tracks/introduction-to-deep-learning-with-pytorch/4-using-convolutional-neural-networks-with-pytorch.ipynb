{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4-using-convolutional-neural-networks-with-pytorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMjCVlMxd39DOjsHAWNbQg8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6f1707e681fc4930a3af56a8c3761cd5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5b2441b6b2994c82b85cc2e27bbb779c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8354eb793117405e8332ee1f5f3b9d42","IPY_MODEL_22b8b7327872456c837d703c557b6598"]}},"5b2441b6b2994c82b85cc2e27bbb779c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8354eb793117405e8332ee1f5f3b9d42":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_26af4509d5244395980616eab94b434d","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":9912422,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9912422,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6c0ad4f0454d4cb296787b088085477a"}},"22b8b7327872456c837d703c557b6598":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_00d2ea4c515d4723bb1134ede3f3b390","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9913344/? [00:00&lt;00:00, 12232550.98it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d802a2ed172495abfc1eba7774106ae"}},"26af4509d5244395980616eab94b434d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6c0ad4f0454d4cb296787b088085477a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"00d2ea4c515d4723bb1134ede3f3b390":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5d802a2ed172495abfc1eba7774106ae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a59d582c5a3c42b2be1a25f7da3e9a6f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d107bdffaa9b49cf821f3beb1316358f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_69563498dfa0401aa4076652381dd377","IPY_MODEL_f2fd75c491dc41f1bc1379ec1a2c3b3d"]}},"d107bdffaa9b49cf821f3beb1316358f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69563498dfa0401aa4076652381dd377":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c890ac6a628244bdbf82a89f326b3771","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1e0da554618b427bbbf30f9898b2688c"}},"f2fd75c491dc41f1bc1379ec1a2c3b3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_694e41b9ca2b44568137401db6fbbafe","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29696/? [00:02&lt;00:00, 14312.38it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_286fb10adbfc46998b484c57561c907d"}},"c890ac6a628244bdbf82a89f326b3771":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1e0da554618b427bbbf30f9898b2688c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"694e41b9ca2b44568137401db6fbbafe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"286fb10adbfc46998b484c57561c907d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"44dad7e3921e4812b146b2681d56f3d0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f14602bae53642acb19dace64ed54825","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c05578e4e8ec4f2bbffda7ce8229e28f","IPY_MODEL_e666d6a0700448b4a0e5cb5da4ce827a"]}},"f14602bae53642acb19dace64ed54825":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c05578e4e8ec4f2bbffda7ce8229e28f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a9aef6f0fe594859b275ca71b8cfd2df","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1648877,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1648877,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9c928c4b6db547fc9bdf7db249dd9811"}},"e666d6a0700448b4a0e5cb5da4ce827a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_19f3bda71b1d48e0b035e33e389d7287","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1649664/? [00:01&lt;00:00, 1473677.06it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fa59178fffcb439d83634389e9c66e22"}},"a9aef6f0fe594859b275ca71b8cfd2df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9c928c4b6db547fc9bdf7db249dd9811":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19f3bda71b1d48e0b035e33e389d7287":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fa59178fffcb439d83634389e9c66e22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6062262acc9047a182a9c952f004f82d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_69e1e5e0e64e48a79725fbb3b8ca4b20","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e10aa2e8f7c5435b8733598045d29013","IPY_MODEL_0edce708aae748e0b26b8c5c3b5dbe64"]}},"69e1e5e0e64e48a79725fbb3b8ca4b20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e10aa2e8f7c5435b8733598045d29013":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7688fef62362423899374cf7b2166911","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4542,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4542,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_73782fc7332e44f6b24c2da0ac456edd"}},"0edce708aae748e0b26b8c5c3b5dbe64":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4842df90bfca4122aeda156a98410738","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5120/? [00:00&lt;00:00, 20307.92it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c63f093ee5da48ce970fefdc2b65afb4"}},"7688fef62362423899374cf7b2166911":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"73782fc7332e44f6b24c2da0ac456edd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4842df90bfca4122aeda156a98410738":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c63f093ee5da48ce970fefdc2b65afb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5800d6817b044fe0ac735873b9a099a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3c160c412cad412e93b0e5901f450c73","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b3fcfc2ad8144ebd9ffa904083081163","IPY_MODEL_ef81e4007959444cb1073c77a1dd588c"]}},"3c160c412cad412e93b0e5901f450c73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b3fcfc2ad8144ebd9ffa904083081163":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_fc807460618d4aa7ad1ac40058a2fa71","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":46827520,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":46827520,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0606e5ce265545828a83ed43b804c289"}},"ef81e4007959444cb1073c77a1dd588c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0c1b22a29a0b49c6839540093ca3be8b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 44.7M/44.7M [07:15&lt;00:00, 108kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3e1cf9d6c6464117b7221570316d99dc"}},"fc807460618d4aa7ad1ac40058a2fa71":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0606e5ce265545828a83ed43b804c289":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0c1b22a29a0b49c6839540093ca3be8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3e1cf9d6c6464117b7221570316d99dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"f5FTJNcbC9gb"},"source":["# Using Convolutional Neural Networks\r\n",">  In this last chapter, we learn how to make neural networks work well in practice, using concepts like regularization, batch-normalization and transfer learning.\r\n","\r\n","- toc: true \r\n","- badges: true\r\n","- comments: true\r\n","- author: Lucas Nunes\r\n","- categories: [Datacamp]\r\n","- image: images/datacamp/___"]},{"cell_type":"markdown","metadata":{"id":"f9J9naPqLbDt"},"source":["> Note: This is a summary of the course's chapter 4 exercises \"Introduction to Deep Learning with PyTorch\" at datacamp. <br>[Github repo](https://github.com/lnunesAI/Datacamp/) / [Course link](https://www.datacamp.com/tracks/machine-learning-scientist-with-python)"]},{"cell_type":"code","metadata":{"id":"7SbXqsjxFOUG"},"source":["import torch\r\n","import torch.nn as nn\r\n","import torch.optim as optim\r\n","import torch.nn.functional as F\r\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UvrKEMkeEF2g"},"source":["## The sequential module\r\n"]},{"cell_type":"markdown","metadata":{"id":"Ho1eZTss8AvH"},"source":["### Sequential module - init method"]},{"cell_type":"markdown","metadata":{"id":"1RJVQo7_IBJZ"},"source":["<div class=\"\"><p>Having learned about the sequential module, now is the time to see how you can convert a neural network that doesn't use sequential modules to one that uses them. We are giving the code to build the network in the usual way, and you are going to write the code for the same network using sequential modules.</p>\r\n","<pre><code>class Net(nn.Module):\r\n","    def __init__(self, num_classes):\r\n","        super(Net, self).__init__()\r\n","\r\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\r\n","        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\r\n","        self.conv3 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1)\r\n","        self.conv4 = nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1)\r\n","\r\n","        self.relu = nn.ReLU()\r\n","\r\n","        self.pool = nn.MaxPool2d(2, 2)\r\n","\r\n","        self.fc1 = nn.Linear(7 * 7 * 40, 1024)\r\n","        self.fc2 = nn.Linear(1024, 2048)\r\n","        self.fc3 = nn.Linear(2048, 10) \r\n","</code></pre>\r\n","<p>We want the pooling layer to be used after the second and fourth convolutional layers, while the relu nonlinearity needs to be used after each layer except the last (fully-connected) layer. For the number of filters (kernels), stride, passing, number of channels and number of units, use the same numbers as above.</p></div>"]},{"cell_type":"markdown","metadata":{"id":"w_OQ61aFH6MP"},"source":["Instructions 1/2\r\n","<li>Declare all the layers needed for feature extraction in the <code>self.features</code>.</li>"]},{"cell_type":"markdown","metadata":{"id":"DRdeLcK2H6MW"},"source":["Instructions 2/2\r\n","<li>Declare the three linear layers in <code>self.classifier</code>.</li>"]},{"cell_type":"code","metadata":{"id":"wgtx-5XYJNy_"},"source":["class Net(nn.Module):\r\n","    def __init__(self):\r\n","        super(Net, self).__init__()\r\n","        \r\n","        # Declare all the layers for feature extraction\r\n","        self.features = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1), \r\n","                                      nn.ReLU(inplace=True),\r\n","                                      nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1), \r\n","                                      nn.MaxPool2d(2, 2), nn.ReLU(inplace=True),\r\n","                                      nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1),\r\n","                                      nn.ReLU(inplace=True),\r\n","                                      nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1),\r\n","                                      nn.MaxPool2d(2, 2), nn.ReLU(inplace=True))\r\n","        \r\n","        # Declare all the layers for classification\r\n","        self.classifier = nn.Sequential(nn.Linear(7 * 7 * 40, 1024), nn.ReLU(inplace=True),\r\n","                                       \tnn.Linear(1024, 2048), nn.ReLU(inplace=True),\r\n","                                        nn.Linear(2048, 10))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n11f1wL0JUYB"},"source":["### Sequential module - forward() method"]},{"cell_type":"markdown","metadata":{"id":"6hisQy8KJZLK"},"source":["<div class=\"\"><p>Now, that you have defined all the modules that the network needs, it is time to apply them in the <code>forward()</code> method. For context, we are giving the code for the <code>forward()</code> method, if the net was written in the usual way.</p>\r\n","<pre><code>class Net(nn.Module):\r\n","    def __init__(self, num_classes):\r\n","        super(Net, self).__init__()\r\n","\r\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\r\n","        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\r\n","        self.conv3 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1)\r\n","        self.conv4 = nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1)\r\n","\r\n","        self.relu = nn.ReLU()\r\n","\r\n","        self.pool = nn.MaxPool2d(2, 2)\r\n","\r\n","        self.fc1 = nn.Linear(7 * 7 * 40, 1024)\r\n","        self.fc2 = nn.Linear(1024, 2048)\r\n","        self.fc3 = nn.Linear(2048, 10) \r\n","\r\n","    def forward():\r\n","        x = self.relu(self.conv1(x))\r\n","        x = self.relu(self.pool(self.conv2(x)))\r\n","        x = self.relu(self.conv3(x))\r\n","        x = self.relu(self.pool(self.conv4(x)))\r\n","        x = x.view(-1, 7 * 7 * 40)\r\n","        x = self.relu(self.fc1(x))\r\n","        x = self.relu(self.fc2(x))\r\n","        x = self.fc3(x)\r\n","        return x\r\n","</code></pre>\r\n","<p>Note: for evaluation purposes, the entire code of the class needs to be in the script. We are using the <code>__init__</code> method as you have coded it on the previous exercise, while you are going to code the <code>forward()</code> method here.</p></div>"]},{"cell_type":"markdown","metadata":{"id":"0lRdCbpFJhXE"},"source":["Instructions\r\n","<ul>\r\n","<li>Extract the features from the images.</li>\r\n","<li>Squeeze the three spatial dimensions of the feature maps into one using the <code>view()</code> method.</li>\r\n","<li>Classify images based on the extracted features.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"id":"JudJHQIIJ9VT"},"source":["class Net(nn.Module):\r\n","    def __init__(self):\r\n","        super(Net, self).__init__()\r\n","        \r\n","        # Declare all the layers for feature extraction\r\n","        self.features = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1), \r\n","                                      nn.ReLU(inplace=True),\r\n","                                      nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1), \r\n","                                      nn.MaxPool2d(2, 2), nn.ReLU(inplace=True),\r\n","                                      nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1),\r\n","                                      nn.ReLU(inplace=True),\r\n","                                      nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1),\r\n","                                      nn.MaxPool2d(2, 2), nn.ReLU(inplace=True))\r\n","        \r\n","        # Declare all the layers for classification\r\n","        self.classifier = nn.Sequential(nn.Linear(7 * 7 * 40, 1024), nn.ReLU(inplace=True),\r\n","                                       \tnn.Linear(1024, 2048), nn.ReLU(inplace=True),\r\n","                                        nn.Linear(2048, 10))\r\n","        \r\n","    def forward(self, x):\r\n","      \r\n","        # Apply the feature extractor in the input\r\n","        x = self.features(x)\r\n","        \r\n","        # Squeeze the three spatial dimensions in one\r\n","        x = x.view(-1, 7 * 7 * 40)\r\n","        \r\n","        # Classify the images\r\n","        x = self.classifier(x)\r\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SLAfaXioKDC_"},"source":["## The problem of overfitting"]},{"cell_type":"markdown","metadata":{"id":"hWoXSx9FOaPe"},"source":["### Validation set"]},{"cell_type":"markdown","metadata":{"id":"6nmmlcAgOc0w"},"source":["<p>You saw the need for validation set in the previous video. Problem is that the datasets typically are not separated into training, validation and testing. It is your job as a data scientist to split the dataset into training, testing and validation. The easiest (and most used) way of doing so is to do a random splitting of the dataset. In PyTorch, that can be done using <code>SubsetRandomSampler</code> object. You are going to split the training part of <code>MNIST</code> dataset into training and validation. After randomly shuffling the dataset, use the first <code>55000</code> points for training, and the remaining <code>5000</code> points for validation.</p>"]},{"cell_type":"markdown","metadata":{"id":"hPB3D-IQOeQB"},"source":["Instructions\r\n","<ul>\r\n","<li>Use <code>numpy.arange()</code> to create an array containing numbers [0, 59999] and then randomly shuffle the array.</li>\r\n","<li>In the <code>train_loader</code> using <code>SubsetRandomSampler()</code> use the first <code>55k</code> points for training.</li>\r\n","<li>In the <code>val_loader</code> use the remaining <code>5k</code> points for validation.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":453,"referenced_widgets":["6f1707e681fc4930a3af56a8c3761cd5","5b2441b6b2994c82b85cc2e27bbb779c","8354eb793117405e8332ee1f5f3b9d42","22b8b7327872456c837d703c557b6598","26af4509d5244395980616eab94b434d","6c0ad4f0454d4cb296787b088085477a","00d2ea4c515d4723bb1134ede3f3b390","5d802a2ed172495abfc1eba7774106ae","a59d582c5a3c42b2be1a25f7da3e9a6f","d107bdffaa9b49cf821f3beb1316358f","69563498dfa0401aa4076652381dd377","f2fd75c491dc41f1bc1379ec1a2c3b3d","c890ac6a628244bdbf82a89f326b3771","1e0da554618b427bbbf30f9898b2688c","694e41b9ca2b44568137401db6fbbafe","286fb10adbfc46998b484c57561c907d","44dad7e3921e4812b146b2681d56f3d0","f14602bae53642acb19dace64ed54825","c05578e4e8ec4f2bbffda7ce8229e28f","e666d6a0700448b4a0e5cb5da4ce827a","a9aef6f0fe594859b275ca71b8cfd2df","9c928c4b6db547fc9bdf7db249dd9811","19f3bda71b1d48e0b035e33e389d7287","fa59178fffcb439d83634389e9c66e22","6062262acc9047a182a9c952f004f82d","69e1e5e0e64e48a79725fbb3b8ca4b20","e10aa2e8f7c5435b8733598045d29013","0edce708aae748e0b26b8c5c3b5dbe64","7688fef62362423899374cf7b2166911","73782fc7332e44f6b24c2da0ac456edd","4842df90bfca4122aeda156a98410738","c63f093ee5da48ce970fefdc2b65afb4"]},"id":"dxu7PRrAP9V-","executionInfo":{"status":"ok","timestamp":1615243414231,"user_tz":180,"elapsed":5804,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"534b7f83-ce78-416f-a361-d2abba3a66fd"},"source":["import torchvision.datasets as datasets\r\n","import torchvision.transforms as transforms\r\n","\r\n","# Shuffle the indices\r\n","indices = np.arange(60000)\r\n","np.random.shuffle(indices)\r\n","\r\n","transform = transforms.Compose([\r\n","    transforms.ToTensor(),\r\n","    transforms.Normalize((0.1307, ), (0.3081, ))\r\n","])\r\n","\r\n","# Build the train loader\r\n","train_loader = torch.utils.data.DataLoader(\r\n","    datasets.MNIST('mnist', download=True, train=True, transform=transform),\r\n","    batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[:55000])\r\n",")\r\n","\r\n","# Build the validation loader\r\n","val_loader = torch.utils.data.DataLoader(\r\n","    datasets.MNIST('mnist', download=True, train=True, transform=transform),\r\n","    batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[55000:])\r\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f1707e681fc4930a3af56a8c3761cd5","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting mnist/MNIST/raw/train-images-idx3-ubyte.gz to mnist/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a59d582c5a3c42b2be1a25f7da3e9a6f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting mnist/MNIST/raw/train-labels-idx1-ubyte.gz to mnist/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"44dad7e3921e4812b146b2681d56f3d0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6062262acc9047a182a9c952f004f82d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:479: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"oAawSWUxQKzX"},"source":["### Detecting overfitting"]},{"cell_type":"markdown","metadata":{"id":"Vtk_NRa7QNZ5"},"source":["<div class=\"\"><p>Overfitting is arguably the biggest problem in machine learning and data science, and being able to detect it will make you a much better data scientist. While reaching a high (or even perfect) accuracy on training sets is quite easy when you use neural networks, reaching a high accuracy on validation and testing sets is a very different thing.</p>\r\n","<hr>\r\n","<p>Let's see if you can now detect overfitting. Amongst the accuracy scores below, which network presents the biggest overfitting problem.\r\n","?</p></div>"]},{"cell_type":"markdown","metadata":{"id":"FZTfvhNSQ7Cn"},"source":["<pre>\r\n","Possible Answers\r\n","The accuracy in the training set is 90%, the accuracy in the validation set is 88%.\r\n","The accuracy in the training set is 90%, the accuracy in the testing set is 70%.\r\n","<b>The accuracy in the training set is 90%, the accuracy in the validation set is 70%.</b>\r\n","The accuracy in the validation set is 85%, the accuracy in the testing set is 82%.\r\n","\r\n","</pre>"]},{"cell_type":"markdown","metadata":{"id":"RaPg2tjuQ1pl"},"source":["**The accuracy in the training set is much higher than in the validation set, this is a typical example of overfitting.**"]},{"cell_type":"markdown","metadata":{"id":"5VkgTIR9Rsod"},"source":["## Regularization techniques"]},{"cell_type":"markdown","metadata":{"id":"oumllJz1UU0u"},"source":["### L2-regularization"]},{"cell_type":"markdown","metadata":{"id":"aAa8pSpVUXTO"},"source":["<p>You are going to implement each of the regularization techniques explained in the previous video. Doing so, you will also remember important concepts studied throughout the course. You will start with l2-regularization, the most important regularization technique in machine learning. As you saw in the video, l2-regularization simply penalizes large weights, and thus enforces the network to use only small weights.</p>"]},{"cell_type":"markdown","metadata":{"id":"nBQKHerCUZT8"},"source":["Instructions\r\n","<ul>\r\n","<li>Instantiate an object called <code>model</code> from class <code>Net()</code>, which is available in your workspace (consider it as a blackbox).</li>\r\n","<li>Instantiate the cross-entropy loss.</li>\r\n","<li>Instantiate <code>Adam</code> optimizer with <code>learning_rate</code> equals to <code>3e-4</code>, and <code>l2</code> regularization parameter equals to <code>0.001</code>.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"id":"7Ku8y4AnVGP0"},"source":["# Instantiate the network\r\n","model = Net()\r\n","\r\n","# Instantiate the cross-entropy loss\r\n","criterion = nn.CrossEntropyLoss()\r\n","\r\n","# Instantiate the Adam optimizer\r\n","optimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.001)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VpAQPjmHVIht"},"source":["**When you will start using bigger networks, this might well make the difference between your network overfitting or not.**"]},{"cell_type":"markdown","metadata":{"id":"YOB7GTMmVOo_"},"source":["### Dropout"]},{"cell_type":"markdown","metadata":{"id":"QTkXFKcyVRyw"},"source":["<div class=\"\"><p>You saw that dropout is an effective technique to avoid overfitting. Typically, dropout is applied in fully-connected neural networks, or in the fully-connected layers of a convolutional neural network. You are now going to implement dropout and use it on a small fully-connected neural network. </p>\r\n","<p>For the first hidden layer use <code>200</code> units, for the second hidden layer use <code>500</code> units, and for the output layer use <code>10</code> units (one for each class). For the activation function, use ReLU. Use <code>.Dropout()</code> with strength <code>0.5</code>, between the first and second hidden layer. Use the sequential module, with the order being: <code>fully-connected</code>, <code>activation</code>, <code>dropout</code>, <code>fully-connected</code>, <code>activation</code>, <code>fully-connected</code>.</p></div>"]},{"cell_type":"markdown","metadata":{"id":"yrM0pAasVTpU"},"source":["Instructions 1/2\r\n","<li>Implement the <code>__init__</code> method, based on the description of the network in the context.</li>"]},{"cell_type":"markdown","metadata":{"id":"bA0O08K5VTpZ"},"source":["Instructions 2/2\r\n","<li>Apply the forward pass in the <code>forward()</code> method.</li>"]},{"cell_type":"code","metadata":{"id":"WTapKmF3V_at"},"source":["class Net(nn.Module):\r\n","    def __init__(self):\r\n","        \r\n","        # Define all the parameters of the net\r\n","        self.classifier = nn.Sequential(\r\n","            nn.Linear(28*28, 200),\r\n","            nn.ReLU(inplace=True),\r\n","            nn.Dropout(p=0.5),\r\n","            nn.Linear(200, 500),\r\n","            nn.ReLU(inplace=True),\r\n","            nn.Linear(500, 10))\r\n","        \r\n","    def forward(self, x):\r\n","    \r\n","    \t# Do the forward pass\r\n","        return self.classifier(x)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GCBBIt3-WDTW"},"source":["### Batch-normalization"]},{"cell_type":"markdown","metadata":{"id":"nFEM8sZhWG13"},"source":["<div class=\"\"><p>Dropout is used to regularize fully-connected layers. Batch-normalization is used to make the training of convolutional neural networks more efficient, while at the same time having regularization effects. You are going to implement the <code>__init__</code> method of a small convolutional neural network, with batch-normalization. The feature extraction part of the CNN will contain the following modules (in order): <code>convolution</code>, <code>max-pool</code>, <code>activation</code>, <code>batch-norm</code>, <code>convolution</code>, <code>max-pool</code>, <code>relu</code>, <code>batch-norm</code>.</p>\r\n","<p>The first convolutional layer will contain 10 output channels, while the second will contain 20 output channels. As always, we are going to use MNIST dataset, with images having shape (28, 28) in grayscale format (1 channel). In all cases, the size of the <code>filter</code> should be 3, the <code>stride</code> should be 1 and the <code>padding</code> should be <code>1</code>.</p></div>"]},{"cell_type":"markdown","metadata":{"id":"ZKrcYXtCWIiX"},"source":["Instructions\r\n","<ul>\r\n","<li>Implement the feature extraction part of the network, using the description in the context.</li>\r\n","<li>Implement the fully-connected (classifier) part of the network.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"id":"RAYvCYt4XVIO"},"source":["class Net(nn.Module):\r\n","    def __init__(self):\r\n","        super(Net, self).__init__()\r\n","        \r\n","        # Implement the sequential module for feature extraction\r\n","        self.features = nn.Sequential(\r\n","            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, stride=1, padding=1),\r\n","            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True), nn.BatchNorm2d(10),\r\n","            nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, stride=1, padding=1),\r\n","            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True), nn.BatchNorm2d(20))\r\n","        \r\n","        # Implement the fully connected layer for classification\r\n","        self.fc = nn.Linear(in_features=20 * 7 * 7, out_features=10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kDK2fKbvXbnI"},"source":["## Transfer learning"]},{"cell_type":"markdown","metadata":{"id":"RUrMvmu20fri"},"source":["### Finetuning a CNN"]},{"cell_type":"markdown","metadata":{"id":"Perkkw9n0flW"},"source":["<div class=\"\"><p>Previously, you trained a model to classify handwritten digits and saved the model parameters to <code>my_net.pth</code>. Now you're going to classify handwritten letters, but you have a smaller training set.</p>\r\n","<p>In the first step, you'll create a new model using this training set, but the accuracy will be poor. Next, you'll perform the same training, but you'll start with the parameters from your digit classifying model. Even though digits and letters are two different classification problems, you'll see that using information from your previous model will dramatically improve this one.</p></div>"]},{"cell_type":"code","metadata":{"id":"OgsIYzutBOAs"},"source":["class Net(nn.Module):\r\n","    def __init__(self):\r\n","      super(Net, self).__init__()\r\n","\r\n","      # instantiate all 3 linear layers\r\n","      self.conv1 = nn.Conv2d(1, 128, 3, padding=1)\r\n","      self.pool = nn.MaxPool2d(2, 2)\r\n","      self.conv2 = nn.Conv2d(128, 256, 3, padding=1)\r\n","      self.conv3 = nn.Conv2d(256, 512, 3, padding=1)\r\n","      self.fc = nn.Linear(7 * 7 * 512, 10)\r\n","\r\n","      # Set dummy parameters\r\n","      self.train_mode = False\r\n","      self.is_trained = False\r\n","      self.previous_state_loaded = False\r\n","    def model_load(self, path):\r\n","      try:\r\n","        model.load_state_dict(torch.load(path))\r\n","        self.previous_state_loaded = True\r\n","      except ValueError:\r\n","        raise TypeError('Please input a path to an existing model.')\r\n","    def forward(self, x):\r\n","      x = self.pool(F.relu(self.conv1(x)))\r\n","      x = self.pool(F.relu(self.conv2(x)))\r\n","      x = F.relu(self.conv3(x))\r\n","      x = x.view(-1, 7 * 7 * 512)\r\n","      return self.fc(x)\r\n","    def train(self):\r\n","      self.train_mode = True\r\n","    def eval(self):\r\n","      # :D\r\n","      # Was fc entered correctly?\r\n","      if type(self.fc) == type(nn.Linear(7 * 7 * 512, 26)):\r\n","        # Were the number of out channel changes?\r\n","        if self.fc.out_features == 26:\r\n","          # Was the model set to train mode?\r\n","          if self.train_mode:\r\n","            # Was the model actually trained?\r\n","            if self.is_trained:\r\n","              # Is this the previously trained model?\r\n","              if self.previous_state_loaded:\r\n","                return 0.84\r\n","              # This is the naieve model\r\n","              else:\r\n","                return 0.57\r\n","            else:\r\n","              raise ValueError('Did you remember to train your model?')\r\n","          else:\r\n","            raise ValueError('Did you remember to set your model to train mode?')\r\n","        else:\r\n","          raise ValueError('There should be 26 out channels for the 26 letters of the alphabet.')\r\n","      else:\r\n","        raise ValueError('Did you remember to defined model.fc?')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_oSX5LcLCSBi"},"source":["def train_net(model, optimizer, criterion):\r\n","  # Check that model is a Net\r\n","  if type(model) == type(Net()):\r\n","    # Check that optimizer is an Adam\r\n","    if type(optimizer) == type(optim.Adam(model.parameters(), lr=3e-4)):\r\n","      # Check that criterion is CrossEntropyLoss\r\n","      if type(criterion) == type(nn.CrossEntropyLoss()):\r\n","        model.is_trained = True\r\n","      else:\r\n","        raise TypeError('criterion should be of type CrossEntropyLoss.')\r\n","    else:\r\n","      raise TypeError('optimizer should be of type  Adam Optimizer.')\r\n","  else:\r\n","    raise TypeError('model should be of type Net().')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dl4Jf4nd0lPm"},"source":["Instructions 1/2\r\n","<ul>\r\n","<li>Create a new model using the <code>Net()</code> module.</li>\r\n","<li>Change the number of output units, to the number of classifications for letters.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p6clLpuF1TqY","executionInfo":{"status":"ok","timestamp":1615247841353,"user_tz":180,"elapsed":633,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"f27336d7-ce80-4310-e0a4-689f0e01618b"},"source":["# Create a new model\r\n","model = Net()\r\n","\r\n","# Change the number of out channels\r\n","model.fc = nn.Linear(7 * 7 * 512, 26)\r\n","\r\n","# Train and evaluate the model\r\n","model.train()\r\n","train_net(model, optimizer, criterion)\r\n","print(\"Accuracy of the net is: \" + str(model.eval()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of the net is: 0.57\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0jzfyH6e0lPn"},"source":["Instructions 2/2\r\n","<li>Repeat the training process, but first load the digit classifier parameters from <code>my_net.pth</code>.</li>"]},{"cell_type":"code","metadata":{"id":"r03sJTdYH3Dz"},"source":["torch.save(model.state_dict(), 'my_net.pth') #only for test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-TARKk1d1s5_","executionInfo":{"status":"ok","timestamp":1615248239365,"user_tz":180,"elapsed":616,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"1ffb4b0e-4ccc-4732-c3f2-e1a881064fe8"},"source":["# Create a model using\r\n","model = Net()\r\n","\r\n","# Load the parameters from the old model\r\n","model.model_load('my_net.pth')\r\n","\r\n","# Change the number of out channels\r\n","model.fc = nn.Linear(7 * 7 * 512, 26)\r\n","\r\n","# Train and evaluate the model\r\n","model.train()\r\n","train_net(model, optimizer, criterion)\r\n","print(\"Accuracy of the net is: \" + str(model.eval()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of the net is: 0.84\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F0iFBztr17ez"},"source":["**By incorporating information from the previously trained model, we are able to get a good model for handwritten digits, even with a small training set!**"]},{"cell_type":"markdown","metadata":{"id":"dORfNV7-2Hyu"},"source":["### Torchvision module"]},{"cell_type":"markdown","metadata":{"id":"9JROShkH2Lpf"},"source":["<div class=\"\"><p>You already finetuned a net you had pretrained. In practice though, it is very common to finetune CNNs that someone else (typically the library's developers) have pretrained in ImageNet. Big networks still take a lot of time to be trained on large datasets, and maybe you cannot afford to train a large network on a dataset of 1.2 million images on your laptop.</p>\r\n","<p>Instead, you can simply download the network and finetune it on your dataset. That's what you will do right now. You are going to assume that you have a personal dataset, containing the images from all your last <code>7</code> holidays. You want to build a neural network that can classify each image depending on the holiday it comes from. However, since the dataset is so small, you need to use the finetuning technique.</p></div>"]},{"cell_type":"markdown","metadata":{"id":"6F5Jvtdl2PVI"},"source":["Instructions\r\n","<ul>\r\n","<li>Import the module that lets you download state-of-the-art CNNs.</li>\r\n","<li>Download and load a pretrained ResNet18 network.</li>\r\n","<li>Freeze all the layers bar the final one.</li>\r\n","<li>Change the last layer to correspond to the number of classes (<code>7</code>) in your dataset.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85,"referenced_widgets":["5800d6817b044fe0ac735873b9a099a1","3c160c412cad412e93b0e5901f450c73","b3fcfc2ad8144ebd9ffa904083081163","ef81e4007959444cb1073c77a1dd588c","fc807460618d4aa7ad1ac40058a2fa71","0606e5ce265545828a83ed43b804c289","0c1b22a29a0b49c6839540093ca3be8b","3e1cf9d6c6464117b7221570316d99dc"]},"id":"LOlIN4r32zZa","executionInfo":{"status":"ok","timestamp":1615244039598,"user_tz":180,"elapsed":1575,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"9617f41f-631b-42b0-c8b9-1c4d2d99b16e"},"source":["# Import the module\r\n","import torchvision\r\n","\r\n","# Download resnet18\r\n","model = torchvision.models.resnet18(pretrained=True)\r\n","\r\n","# Freeze all the layers bar the last one\r\n","for param in model.parameters():\r\n","    param.requires_grad = False\r\n","\r\n","# Change the number of output units\r\n","model.fc = nn.Linear(512, 7)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5800d6817b044fe0ac735873b9a099a1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]}]}