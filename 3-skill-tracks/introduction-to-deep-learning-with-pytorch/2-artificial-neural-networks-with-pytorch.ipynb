{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2-artificial-neural-networks-with-pytorch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOArk1ck9Q7PW8iY6tN77+Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0c9a04e1b1c74d6dbe9144f1d08b138a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e092ab0ee24c4ffd8be849b53ddaac3e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f400e47f99f441a6890dea2dff2acb3a","IPY_MODEL_02f79e1021bb4551b96ccc0c6f018361"]}},"e092ab0ee24c4ffd8be849b53ddaac3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f400e47f99f441a6890dea2dff2acb3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d4befbc4b160403b8dee5373ccc79550","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c60f64b5ace34e7583056417d6afa69b"}},"02f79e1021bb4551b96ccc0c6f018361":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0045136b55474462b7906873043030c0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9920512/? [00:01&lt;00:00, 8507948.11it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4c6f39047a88436a817b14626807bee5"}},"d4befbc4b160403b8dee5373ccc79550":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c60f64b5ace34e7583056417d6afa69b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0045136b55474462b7906873043030c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4c6f39047a88436a817b14626807bee5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"537aff8af34b49b484291e3e75f76d02":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6ca9be9e60144163b2c9d869e29e5e77","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6f309262c460410494b01ac6e48169df","IPY_MODEL_8255e5a77f38479987e5dac4334d5bd4"]}},"6ca9be9e60144163b2c9d869e29e5e77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6f309262c460410494b01ac6e48169df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2acb8663b82b403f96651626f391c907","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6c25b2732f3748709c4e70c2d531b6c7"}},"8255e5a77f38479987e5dac4334d5bd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c38e8225c8f84fbcbfd17bd42b2a8d0b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 32768/? [00:00&lt;00:00, 76506.20it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_db9b3d73ac7841f0b329886cea7305f8"}},"2acb8663b82b403f96651626f391c907":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6c25b2732f3748709c4e70c2d531b6c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c38e8225c8f84fbcbfd17bd42b2a8d0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"db9b3d73ac7841f0b329886cea7305f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dfdf4fdbc0e546659845e9517626a948":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a4375609a6774a0c9ba90061ae77c024","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4ccbb2e6486d4d4381d1ad15e6bbea5a","IPY_MODEL_494d23bbe7294b80a8ab06172f464ec6"]}},"a4375609a6774a0c9ba90061ae77c024":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4ccbb2e6486d4d4381d1ad15e6bbea5a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9ee88712a6594a308a6015f24bc10ca1","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0c5602d993354b21aacbcb03f64a06f6"}},"494d23bbe7294b80a8ab06172f464ec6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e26153c5565f4bbd8828159bd1e96531","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1654784/? [00:00&lt;00:00, 5177573.82it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d7813e0e571a4f439ba2751d92703b6a"}},"9ee88712a6594a308a6015f24bc10ca1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0c5602d993354b21aacbcb03f64a06f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e26153c5565f4bbd8828159bd1e96531":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d7813e0e571a4f439ba2751d92703b6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c4ea63db2ab743828b07bc8ecbcc82a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5b1fcdc4faec4084ab830832dc7e9deb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_84aa38b29e2549a4a771161d87880983","IPY_MODEL_21c4f8bb017047bda86fad5aa7e25ffd"]}},"5b1fcdc4faec4084ab830832dc7e9deb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"84aa38b29e2549a4a771161d87880983":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ca93f07a5a864aafbb8bba4c05d7834d","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_11747556de8c48359f0dfe61606110cc"}},"21c4f8bb017047bda86fad5aa7e25ffd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_cfb7383649c1422ab550c4640d742049","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/4542 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8bf45d2d3fcd4f0195fa77a88879e0ed"}},"ca93f07a5a864aafbb8bba4c05d7834d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"11747556de8c48359f0dfe61606110cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cfb7383649c1422ab550c4640d742049":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8bf45d2d3fcd4f0195fa77a88879e0ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"f5FTJNcbC9gb"},"source":["# Artificial Neural Networks With PyTorch\r\n",">  In this second chapter, we delve deeper into Artificial Neural Networks, learning how to train them with real datasets.\r\n","\r\n","- toc: true \r\n","- badges: true\r\n","- comments: true\r\n","- author: Lucas Nunes\r\n","- categories: [Datacamp]\r\n","- image: images/datacamp/___"]},{"cell_type":"markdown","metadata":{"id":"f9J9naPqLbDt"},"source":["> Note: This is a summary of the course's chapter 2 exercises \"Introduction to Deep Learning with PyTorch\" at datacamp. <br>[Github repo](https://github.com/lnunesAI/Datacamp/) / [Course link](https://www.datacamp.com/tracks/deep-learning-in-python)"]},{"cell_type":"code","metadata":{"id":"7SbXqsjxFOUG"},"source":["import torch\r\n","import torch.nn as nn\r\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UvrKEMkeEF2g"},"source":["## Activation functions"]},{"cell_type":"markdown","metadata":{"id":"Ho1eZTss8AvH"},"source":["### Neural networks"]},{"cell_type":"markdown","metadata":{"id":"ytMyh77w71ix"},"source":["<div class=\"\"><p>Let us see the differences between neural networks which apply <code>ReLU</code> and those which do not apply <code>ReLU</code>. We have already initialized the input called <code>input_layer</code>, and three sets of weights, called <code>weight_1</code>, <code>weight_2</code> and <code>weight_3</code>.</p>\r\n","<p>We are going to convince ourselves that networks with multiple layers which do not contain non-linearity can be expressed as neural networks with one layer.</p>\r\n","<p>The network and the shape of layers and weights is shown below.</p>\r\n","<p><img src=\"https://assets.datacamp.com/production/repositories/4094/datasets/90a76cfc0248297aa65f7cb9bdc17602b6b1d84b/net-ex.jpg\" alt=\"\"></p></div>"]},{"cell_type":"code","metadata":{"id":"9M7PYq8l73Ab"},"source":["input_layer = torch.tensor([[ 0.0401, -0.9005,  0.0397, -0.0876]])\r\n","\r\n","weight_1 = torch.tensor([[-0.1094, -0.8285,  0.0416, -1.1222],\r\n","                        [ 0.3327, -0.0461,  1.4473, -0.8070],\r\n","                        [ 0.0681, -0.7058, -1.8017,  0.5857],\r\n","                        [ 0.8764,  0.9618, -0.4505,  0.2888]])\r\n","\r\n","weight_2 = torch.tensor([[ 0.6856, -1.7650,  1.6375, -1.5759],\r\n","                        [-0.1092, -0.1620,  0.1951, -0.1169],\r\n","                        [-0.5120,  1.1997,  0.8483, -0.2476],\r\n","                        [-0.3369,  0.5617, -0.6658,  0.2221]])\r\n","\r\n","weight_3 = torch.tensor([[ 0.8824,  0.1268,  1.1951,  1.3061],\r\n","                        [-0.8753, -0.3277, -0.1454, -0.0167],\r\n","                        [ 0.3582,  0.3254, -1.8509, -1.4205],\r\n","                        [ 0.3786,  0.5999, -0.5665, -0.3975]])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YqzWz4t27-CV"},"source":["Instructions\r\n","<ul>\r\n","<li>Calculate the first and second hidden layer by multiplying the appropriate inputs with the corresponding weights.</li>\r\n","<li>Calculate and print the results of the output.</li>\r\n","<li>Set <code>weight_composed_1</code> to the product of <code>weight_1</code> with <code>weight_2</code>, then set <code>weight</code> to the product of <code>weight_composed_1</code> with <code>weight_3</code>.</li>\r\n","<li>Calculate and print the output.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"id":"w48_1NTN8ASP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615143517614,"user_tz":180,"elapsed":3586,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"67651bc5-d094-4fd3-ee6e-1e5ca2dd3cd2"},"source":["# Calculate the first and second hidden layer\r\n","hidden_1 = torch.matmul(input_layer, weight_1)\r\n","hidden_2 = torch.matmul(hidden_1, weight_2)\r\n","\r\n","# Calculate the output\r\n","print(torch.matmul(hidden_2, weight_3))\r\n","\r\n","# Calculate weight_composed_1 and weight\r\n","weight_composed_1 = torch.matmul(weight_1, weight_2)\r\n","weight = torch.matmul(weight_composed_1, weight_3)\r\n","\r\n","# Multiply input_layer with weight\r\n","print(torch.matmul(input_layer, weight))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[0.2653, 0.1311, 3.8219, 3.0032]])\n","tensor([[0.2653, 0.1311, 3.8219, 3.0032]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3SoekVPI8e7s"},"source":["**You see how the results are the same.**"]},{"cell_type":"markdown","metadata":{"id":"GOsRvx918g2s"},"source":["### ReLU activation"]},{"cell_type":"markdown","metadata":{"id":"fd70ciIc8jkl"},"source":["<div class=\"\"><p>In this exercise, we have the same settings as the previous exercise. In addition, we have instantiated the <code>ReLU</code> activation function called <code>relu()</code>.</p>\r\n","<p>Now we are going to build a neural network which has non-linearity and by doing so, we are going to convince ourselves that networks with multiple layers and non-linearity functions cannot be expressed as a neural network with one layer.</p>\r\n","<p><img src=\"https://assets.datacamp.com/production/repositories/4094/datasets/90a76cfc0248297aa65f7cb9bdc17602b6b1d84b/net-ex.jpg\" alt=\"\"></p></div>"]},{"cell_type":"code","metadata":{"id":"IItggUNs78Aq"},"source":["relu = nn.ReLU()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uYQF6Fm38lWD"},"source":["Instructions\r\n","<ul>\r\n","<li>Apply non-linearity on <code>hidden_1</code> and <code>hidden_2</code>.</li>\r\n","<li>Apply non-linearity in the product of first two weight.</li>\r\n","<li>Multiply the result of the previous step with <code>weight_3</code>.</li>\r\n","<li>Multiply <code>input_layer</code> with <code>weight</code> and print the results.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K2kD_tVA81qp","executionInfo":{"status":"ok","timestamp":1615143517615,"user_tz":180,"elapsed":3572,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"78762014-ca20-4798-eede-b162e048a89a"},"source":["# Apply non-linearity on hidden_1 and hidden_2\r\n","hidden_1_activated = relu(torch.matmul(input_layer, weight_1))\r\n","hidden_2_activated = relu(torch.matmul(hidden_1_activated, weight_2))\r\n","print(torch.matmul(hidden_2_activated, weight_3))\r\n","\r\n","# Apply non-linearity in the product of first two weights. \r\n","weight_composed_1_activated = relu(torch.matmul(weight_1, weight_2))\r\n","\r\n","# Multiply `weight_composed_1_activated` with `weight_3\r\n","weight = torch.matmul(weight_composed_1_activated, weight_3)\r\n","\r\n","# Multiply input_layer with weight\r\n","print(torch.matmul(input_layer, weight))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[-0.2770, -0.0345, -0.1410, -0.0664]])\n","tensor([[-0.2117, -0.4782,  4.0438,  3.0417]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6usKhkHg83pj"},"source":["**As expected the results are different from the previous exercise.**"]},{"cell_type":"markdown","metadata":{"id":"2qwljPON86wk"},"source":["### ReLU activation again"]},{"cell_type":"markdown","metadata":{"id":"w5zloHbC8-Kt"},"source":["<div class=\"\"><p>Neural networks don't need to have the same number of units in each layer. Here, you are going to experiment with the <code>ReLU</code> activation function again, but this time we are going to have a different number of units in the layers of the neural network. The input layer will still have <code>4</code> features, but then the first hidden layer will have <code>6</code> units and the output layer will have <code>2</code> units.</p>\r\n","<p><img src=\"https://assets.datacamp.com/production/repositories/4094/datasets/d55fe04c7d4cc7e2b1614e39e77e832ce56c3fc8/net-ex2.jpg\" alt=\"\"></p></div>"]},{"cell_type":"markdown","metadata":{"id":"TK_u43C69A_G"},"source":["Instructions\r\n","<ul>\r\n","<li>Instantiate the <code>ReLU()</code> activation function as <code>relu</code> (the function is part of <code>nn</code> module).</li>\r\n","<li>Initialize <code>weight_1</code> and <code>weight_2</code> with random numbers.</li>\r\n","<li>Multiply the <code>input_layer</code> with <code>weight_1</code>, storing results in <code>hidden_1</code>.</li>\r\n","<li>Apply the <code>relu</code> activation function over <code>hidden_1</code>, and then multiply the output of it with <code>weight_2</code>.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N4QQJrw3-LZY","executionInfo":{"status":"ok","timestamp":1615143517616,"user_tz":180,"elapsed":3561,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"5e9a04ae-6a7a-4f58-94c3-47d157d18d55"},"source":["# Instantiate ReLU activation function as relu\r\n","relu = nn.ReLU()\r\n","\r\n","# Initialize weight_1 and weight_2 with random numbers\r\n","weight_1 = torch.rand(4, 6)\r\n","weight_2 = torch.rand(6, 2)\r\n","\r\n","# Multiply input_layer with weight_1\r\n","hidden_1 = torch.matmul(input_layer, weight_1)\r\n","\r\n","# Apply ReLU activation function over hidden_1 and multiply with weight_2\r\n","hidden_1_activated = relu(hidden_1)\r\n","print(torch.matmul(hidden_1_activated, weight_2))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[0., 0.]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SBaQinzk-St1"},"source":["## Loss functions"]},{"cell_type":"markdown","metadata":{"id":"4Y-2Hl1CPMGw"},"source":["### Calculating loss function by hand"]},{"cell_type":"markdown","metadata":{"id":"d5QvKakNPKCY"},"source":["<div class=\"\"><p>Let's start the exercises by calculating the loss function by hand. Don't do this exercise in PyTorch, it is important to first do it using only pen and paper (and a calculator).</p>\r\n","<p>We have the same example as before but now our object is actually a frog, and the predicted scores are <code>-1.2</code> for class <code>0</code> (cat), <code>0.12</code> for class <code>1</code> (car) and <code>4.8</code> for class <code>2</code> (frog).</p>\r\n","<hr>\r\n","<p>What is the result of the softmax cross-entropy loss function?</p>\r\n","<table>\r\n","<thead>\r\n","<tr>\r\n","<th>Class</th>\r\n","<th>Predicted Score</th>\r\n","</tr>\r\n","</thead>\r\n","<tbody>\r\n","<tr>\r\n","<td>Cat</td>\r\n","<td>-1.2</td>\r\n","</tr>\r\n","<tr>\r\n","<td>Car</td>\r\n","<td>0.12</td>\r\n","</tr>\r\n","<tr>\r\n","<td>Frog</td>\r\n","<td>4.8</td>\r\n","</tr>\r\n","</tbody>\r\n","</table></div>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yoS3S3YvCTvv","executionInfo":{"status":"ok","timestamp":1615143517616,"user_tz":180,"elapsed":3550,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"f9263553-7ce6-4c38-d3d1-645902c3ddd1"},"source":["c0 = np.exp(-1.2)\r\n","c1 = np.exp(0.12)\r\n","c2 = np.exp(4.8)\r\n","unnormalized = c0+c1+c2\r\n","p0 = c0/unnormalized\r\n","p1 = c1/unnormalized\r\n","p2 = c2/unnormalized\r\n","np.round(-np.log(p2), 4)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0117"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"8JJFd8baFB1V"},"source":["<pre>\r\n","Possible Answers\r\n","6.0117\r\n","4.6917\r\n","<b>0.0117</b>\r\n","Score for frog is high, so loss is 0.\r\n","</pre>"]},{"cell_type":"markdown","metadata":{"id":"5YtJk-6-FPoQ"},"source":["### Calculating loss function in PyTorch"]},{"cell_type":"markdown","metadata":{"id":"s5i1ILXPFbGL"},"source":["<div class=\"\"><p>You are going to code the previous exercise, and make sure that we computed the loss correctly. Predicted scores are <code>-1.2</code> for class <code>0</code> (cat), <code>0.12</code> for class <code>1</code> (car) and <code>4.8</code> for class <code>2</code> (frog). The ground truth is class <code>2</code> (frog). Compute the loss function in PyTorch.</p>\r\n","<table>\r\n","<thead>\r\n","<tr>\r\n","<th>Class</th>\r\n","<th>Predicted Score</th>\r\n","</tr>\r\n","</thead>\r\n","<tbody>\r\n","<tr>\r\n","<td>Cat</td>\r\n","<td>-1.2</td>\r\n","</tr>\r\n","<tr>\r\n","<td>Car</td>\r\n","<td>0.12</td>\r\n","</tr>\r\n","<tr>\r\n","<td>Frog</td>\r\n","<td>4.8</td>\r\n","</tr>\r\n","</tbody>\r\n","</table></div>"]},{"cell_type":"markdown","metadata":{"id":"d3YyQvD7Fd7c"},"source":["Instructions\r\n","<ul>\r\n","<li>Initialize the tensor of scores with numbers <code>[[-1.2, 0.12, 4.8]]</code>, and the tensor of ground truth <code>[2]</code>.</li>\r\n","<li>Instantiate the cross-entropy loss and call it <code>criterion</code>.</li>\r\n","<li>Compute and print the loss.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cb0k-_4rF3oR","executionInfo":{"status":"ok","timestamp":1615143517617,"user_tz":180,"elapsed":3539,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"b0d330b8-3cfc-485f-adfd-b132e8645186"},"source":["# Initialize the scores and ground truth\r\n","logits = torch.tensor([[-1.2, 0.12, 4.8]])\r\n","ground_truth = torch.tensor([2])\r\n","\r\n","# Instantiate cross entropy loss\r\n","criterion = nn.CrossEntropyLoss()\r\n","\r\n","# Compute and print the loss\r\n","loss = criterion(logits, ground_truth)\r\n","print(loss)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(0.0117)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qAkE7QkYF87u"},"source":["**As you can see, the loss function PyTorch calculated gives the same number as the loss function you calculated. Being proficient in understanding and calculating loss functions is a very important skill in deep learning.**"]},{"cell_type":"markdown","metadata":{"id":"gYFhpEDqF_qG"},"source":["### Loss function of random scores"]},{"cell_type":"markdown","metadata":{"id":"ed6omiYSGCbe"},"source":["<p>If the neural network predicts random scores, what would be its loss function? Let's find it out in PyTorch. The neural network is going to have 1000 classes, each having a random score. For ground truth, it will have class 111. Calculate the loss function.</p>"]},{"cell_type":"markdown","metadata":{"id":"7tV3OtgDGEdv"},"source":["Instructions\r\n","<ul>\r\n","<li>Import <code>torch</code> and <code>torch.nn as nn</code></li>\r\n","<li>Initialize <code>logits</code> with a random tensor of shape <code>(1, 1000)</code> and <code>ground_truth</code> with a tensor containing the number <code>111</code>.</li>\r\n","<li>Instantiate the cross-entropy loss in a variable called <code>criterion</code>.</li>\r\n","<li>Calculate and print the loss function.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RVI1mbu2HhGS","executionInfo":{"status":"ok","timestamp":1615143517617,"user_tz":180,"elapsed":3528,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"fa11a140-a2fb-4496-91d3-ef30649aa12f"},"source":["# Initialize logits and ground truth\r\n","logits = torch.rand(1, 1000)\r\n","ground_truth = torch.tensor([111])\r\n","\r\n","# Instantiate cross-entropy loss\r\n","criterion = nn.CrossEntropyLoss()\r\n","\r\n","# Calculate and print the loss\r\n","loss = criterion(logits, ground_truth)\r\n","print(loss)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(6.6900)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-yPKBK9gHslU"},"source":["**The score is close to -ln(1/1000) = 6.9. This is not surprising, considering that scores were random and close to each other, so the probability for each class was approximately the same (1/1000) = 0.001.**"]},{"cell_type":"markdown","metadata":{"id":"A06uS_KcHupF"},"source":["## Preparing a dataset in PyTorch"]},{"cell_type":"markdown","metadata":{"id":"Ko3UBCzhWPR4"},"source":["### Preparing MNIST dataset"]},{"cell_type":"markdown","metadata":{"id":"vmB24E9jWRuY"},"source":["<p>You are going to prepare dataloaders for <code>MNIST</code> training and testing set. As we explained in the lecture, <code>MNIST</code> has some differences to <code>CIFAR-10</code>, with the main difference being that <code>MNIST</code> images are <code>grayscale</code> (1 channel based) instead of <code>RGB</code> (3 channels).</p>"]},{"cell_type":"markdown","metadata":{"id":"TM2l1GqQWTHp"},"source":["Instructions\r\n","<ul>\r\n","<li>Transform the data to torch tensors and normalize it, <code>mean</code> is <code>0.1307</code> while <code>std</code> is <code>0.3081</code>.</li>\r\n","<li>Prepare the <code>trainset</code> and the <code>testset</code>.</li>\r\n","<li>Prepare the dataloaders for training and testing so that only 32 pictures are processed at a time.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435,"referenced_widgets":["0c9a04e1b1c74d6dbe9144f1d08b138a","e092ab0ee24c4ffd8be849b53ddaac3e","f400e47f99f441a6890dea2dff2acb3a","02f79e1021bb4551b96ccc0c6f018361","d4befbc4b160403b8dee5373ccc79550","c60f64b5ace34e7583056417d6afa69b","0045136b55474462b7906873043030c0","4c6f39047a88436a817b14626807bee5","537aff8af34b49b484291e3e75f76d02","6ca9be9e60144163b2c9d869e29e5e77","6f309262c460410494b01ac6e48169df","8255e5a77f38479987e5dac4334d5bd4","2acb8663b82b403f96651626f391c907","6c25b2732f3748709c4e70c2d531b6c7","c38e8225c8f84fbcbfd17bd42b2a8d0b","db9b3d73ac7841f0b329886cea7305f8","dfdf4fdbc0e546659845e9517626a948","a4375609a6774a0c9ba90061ae77c024","4ccbb2e6486d4d4381d1ad15e6bbea5a","494d23bbe7294b80a8ab06172f464ec6","9ee88712a6594a308a6015f24bc10ca1","0c5602d993354b21aacbcb03f64a06f6","e26153c5565f4bbd8828159bd1e96531","d7813e0e571a4f439ba2751d92703b6a","c4ea63db2ab743828b07bc8ecbcc82a2","5b1fcdc4faec4084ab830832dc7e9deb","84aa38b29e2549a4a771161d87880983","21c4f8bb017047bda86fad5aa7e25ffd","ca93f07a5a864aafbb8bba4c05d7834d","11747556de8c48359f0dfe61606110cc","cfb7383649c1422ab550c4640d742049","8bf45d2d3fcd4f0195fa77a88879e0ed"]},"id":"WWzxZ0LGEEQd","executionInfo":{"status":"ok","timestamp":1615143942064,"user_tz":180,"elapsed":1942,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"4ad461be-08b2-4351-92d2-379d9faabae9"},"source":["import torchvision\r\n","import torchvision.transforms as transforms\r\n","\r\n","from six.moves import urllib\r\n","opener = urllib.request.build_opener()\r\n","opener.addheaders = [('User-agent', 'Mozilla/5.0')]\r\n","urllib.request.install_opener(opener)\r\n","\r\n","# Transform the data to torch tensors and normalize it \r\n","transform = transforms.Compose([transforms.ToTensor(),\r\n","\t\t\t\t\t\t\t\ttransforms.Normalize((0.1307), ((0.3081)))])\r\n","\r\n","# Prepare the datasets\r\n","trainset = torchvision.datasets.MNIST('mnist', train=True, \r\n","\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\r\n","testset = torchvision.datasets.MNIST('mnist', train=False, \r\n","\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\r\n","\r\n","# Prepare the dataloaders\r\n","train_loader = torch.utils.data.DataLoader(trainset, batch_size=32,\r\n","\t\t\t\t\t\t\t\t\t\t  shuffle=True, num_workers=0)\r\n","test_loader = torch.utils.data.DataLoader(testset, batch_size=32,\r\n","\t\t\t\t\t\t\t\t\t\t shuffle=False, num_workers=0)       "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c9a04e1b1c74d6dbe9144f1d08b138a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting mnist/MNIST/raw/train-images-idx3-ubyte.gz to mnist/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"537aff8af34b49b484291e3e75f76d02","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting mnist/MNIST/raw/train-labels-idx1-ubyte.gz to mnist/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dfdf4fdbc0e546659845e9517626a948","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","\n","\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c4ea63db2ab743828b07bc8ecbcc82a2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"6rOboPXFjRgZ"},"source":["## Inspecting the dataloaders"]},{"cell_type":"markdown","metadata":{"id":"RsJhPcV8jULD"},"source":["<p>Now you are going to explore a bit the <code>dataloaders</code> you created in the previous exercise. In particular, you will compute the shape of the dataset in addition to the minibatch size.</p>"]},{"cell_type":"markdown","metadata":{"id":"56AeZwjdjXta"},"source":["Instructions\r\n","<ul>\r\n","<li>Compute the shapes of the <code>trainset</code> and <code>testset</code>.</li>\r\n","<li>Print the computed values.</li>\r\n","<li>Compute the size of the minibatch for both <code>trainset</code> and <code>testset</code>.</li>\r\n","<li>Print the minibatch size.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bc_EQ0vOjPYS","executionInfo":{"status":"ok","timestamp":1615143947348,"user_tz":180,"elapsed":533,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"1e6049dc-98ac-42e6-aff4-0343a7446ca9"},"source":["# Compute the shape of the training set and testing set\r\n","trainset_shape = train_loader.dataset.data.shape #train_loader.dataset.train_data.shape\r\n","testset_shape = test_loader.dataset.data.shape #test_loader.dataset.test_data.shape\r\n","\r\n","# Print the computed shapes\r\n","print(trainset_shape, testset_shape)\r\n","\r\n","# Compute the size of the minibatch for training set and testing set\r\n","trainset_batchsize = train_loader.batch_size\r\n","testset_batchsize = test_loader.batch_size\r\n","\r\n","# Print sizes of the minibatch\r\n","print(trainset_batchsize, testset_batchsize)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n","32 32\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"23QkOLxUjm13"},"source":["## Training neural networks"]},{"cell_type":"markdown","metadata":{"id":"tDw0zQmapYk-"},"source":["### Building a neural network - again"]},{"cell_type":"markdown","metadata":{"id":"x1eXFxLqpbp3"},"source":["<div class=\"\"><p>You haven't created a neural network since the end of the first chapter, so this is a good time to build one (practice makes perfect). Build a class for a neural network which will be used to train on the <code>MNIST</code> dataset. The dataset contains images of shape <code>(28, 28, 1)</code>, so you should deduct the size of the input layer. For hidden layer use 200 units, while for output layer use 10 units (1 for each class). For activation function, use <code>relu</code> in a functional way (<code>nn.Functional</code> is already imported as <code>F</code>).</p>\r\n","<p>For context, the same net will be trained and used to make predictions in the next two exercises.</p></div>"]},{"cell_type":"code","metadata":{"id":"L58n9h-L7-k3"},"source":["import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YYN7KszspdcA"},"source":["Instructions\r\n","<ul>\r\n","<li>Define the class called <code>Net</code> which inherits from <code>nn.Module</code>.</li>\r\n","<li>In the <code>__init__()</code> method, define the parameters for the two fully connected layers.</li>\r\n","<li>In the <code>.forward()</code> method, do the forward step.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"id":"2V_e02iXrTXK"},"source":["# Define the class Net\r\n","class Net(nn.Module):\r\n","    def __init__(self):    \r\n","    \t# Define all the parameters of the net\r\n","        super(Net, self).__init__()\r\n","        self.fc1 = nn.Linear(28 * 28 * 1, 200)\r\n","        self.fc2 = nn.Linear(200, 10)\r\n","\r\n","    def forward(self, x):   \r\n","    \t# Do the forward pass\r\n","        x = F.relu(self.fc1(x))\r\n","        x = self.fc2(x)\r\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rze0hD1drWGA"},"source":["### Training a neural network"]},{"cell_type":"markdown","metadata":{"id":"pd4zgsQer4Ub"},"source":["<p>Given the fully connected neural network (called <code>model</code>) which you built in the previous exercise and a train loader called <code>train_loader</code> containing the <code>MNIST</code> dataset (which we created for you), you're to train the net in order to predict the classes of digits. You will use the Adam optimizer to optimize the network, and considering that this is a classification problem you are going to use cross entropy as loss function.</p>"]},{"cell_type":"code","metadata":{"id":"hiZYeWjr8E1f"},"source":["import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QDfsnh1Ar53r"},"source":["Instructions\r\n","<ul>\r\n","<li>Instantiate the Adam optimizer with learning rate <code>3e-4</code> and instantiate Cross-Entropy as loss function.</li>\r\n","<li>Complete a forward pass on the neural network using the input <code>data</code>.</li>\r\n","<li>Using backpropagation, compute the gradients of the weights, and then change the weights using the <code>Adam</code> optimizer.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"id":"haCHv6PTr2bD"},"source":["# Instantiate the Adam optimizer and Cross-Entropy loss function\r\n","model = Net()   \r\n","optimizer = optim.Adam(model.parameters(), lr=3e-4)\r\n","criterion = nn.CrossEntropyLoss()\r\n","  \r\n","for batch_idx, data_target in enumerate(train_loader):\r\n","    data = data_target[0]\r\n","    target = data_target[1]\r\n","    data = data.view(-1, 28 * 28)\r\n","    optimizer.zero_grad()\r\n","\r\n","    # Complete a forward pass\r\n","    output = model(data)\r\n","\r\n","    # Compute the loss, gradients and change the weights\r\n","    loss = criterion(output, target)\r\n","    loss.backward()\r\n","    optimizer.step()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x513SfDKsBDl"},"source":["### Using the network to make predictions"]},{"cell_type":"markdown","metadata":{"id":"ETeguFX-sDcu"},"source":["<p>Now that you have trained the network, use it to make predictions for the data in the testing set. The network is called <code>model</code> (same as in the previous exercise), and the loader is called <code>test_loader</code>. We have already initialized variables <code>total</code> and <code>correct</code> to <code>0</code>.</p>"]},{"cell_type":"code","metadata":{"id":"4YfwLcv78rmM"},"source":["correct, total = 0, 0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hPh64ypfsE6R"},"source":["Instructions\r\n","<ul>\r\n","<li>Set the network in testing (eval) mode.</li>\r\n","<li>Put each image into a vector using <code>inputs.view(-1, number_of_features)</code> where the number of features should be deducted by multiplying spatial dimensions (shape) of the image.</li>\r\n","<li>Do the forward pass and put the predictions in <code>output</code> variable.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"id":"LBxUH4tPsaqV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615143978432,"user_tz":180,"elapsed":22926,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"e239d51d-21e9-475e-f52e-8cc51678a32e"},"source":["# Set the model in eval mode\r\n","model.eval() #model.eval\r\n","\r\n","for i, data in enumerate(test_loader, 0):\r\n","    inputs, labels = data\r\n","    \r\n","    # Put each image into a vector\r\n","    inputs = inputs.view(-1, 28*28*1)\r\n","    \r\n","    # Do the forward pass and get the predictions\r\n","    outputs = model(inputs)\r\n","    _, outputs = torch.max(outputs.data, 1)\r\n","    total += labels.size(0)\r\n","    correct += (outputs == labels).sum().item()\r\n","print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The testing set accuracy of the network is: 95 %\n"],"name":"stdout"}]}]}