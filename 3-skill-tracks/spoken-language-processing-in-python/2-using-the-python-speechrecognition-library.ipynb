{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2-using-the-python-speechrecognition-library.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOZ/axX1uWKs72cdx1evZjn"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"f5FTJNcbC9gb"},"source":["# Using the Python SpeechRecognition library\r\n",">  Speech recognition is still far from perfect. But the SpeechRecognition library provides an easy way to interact with many speech-to-text APIs. In this section, you'll learn how to use the SpeechRecognition library to easily start converting the spoken language in your audio files to text.\r\n","\r\n","- toc: true \r\n","- badges: true\r\n","- comments: true\r\n","- author: Lucas Nunes\r\n","- categories: [Datacamp]\r\n","- image: images/datacamp/___"]},{"cell_type":"markdown","metadata":{"id":"f9J9naPqLbDt"},"source":["> Note: This is a summary of the course's chapter 2 exercises \"Spoken Language Processing in Python\" at datacamp. <br>[Github repo](https://github.com/lnunesAI/Datacamp/) / [Course link](https://www.datacamp.com/tracks/machine-learning-scientist-with-python)"]},{"cell_type":"markdown","metadata":{"id":"UvrKEMkeEF2g"},"source":["## SpeechRecognition Python library"]},{"cell_type":"markdown","metadata":{"id":"Ho1eZTss8AvH"},"source":["### Pick the wrong speech_recognition API"]},{"cell_type":"markdown","metadata":{"id":"X1LbQskOj_9T"},"source":["<div class=\"\"><p>Which of the following is <strong>not</strong> a speech recognition API within the <code>speech_recognition</code> library?</p>\r\n","<p>An instance of the <code>Recognizer</code> class has been created and saved to <code>recognizer</code>. You can try calling the API on <code>recognizer</code> to see what happens.</p></div>"]},{"cell_type":"markdown","metadata":{"id":"KgluDfq4kBaC"},"source":["<pre>\r\n","Possible Answers+\r\n","recognize_google()\r\n","recognize_bing()\r\n","recognize_wit()\r\n","<b>what_does_this_say()</b>\r\n","</pre>"]},{"cell_type":"markdown","metadata":{"id":"lTcrqpzskLmV"},"source":["**All of the Recognizer class API calls begin with recognize_.**"]},{"cell_type":"markdown","metadata":{"id":"Sydj1OgplL4p"},"source":["### Using the SpeechRecognition library"]},{"cell_type":"markdown","metadata":{"id":"kQJg3A24lOnS"},"source":["<div class=\"\"><p>To save typing <code>speech_recognition</code> every time, we'll import it as <code>sr</code>.</p>\r\n","<p>We'll also setup an instance of the <code>Recognizer</code> class to use later.</p>\r\n","<p>The <code>energy_threshold</code> is a number between 0 and 4000 for how much the <code>Recognizer</code> class should listen to an audio file.</p>\r\n","<p><code>energy_threshold</code> will dynamically adjust whilst the recognizer class listens to audio.</p></div>"]},{"cell_type":"code","metadata":{"id":"4biJK3VbvPyQ"},"source":["%%capture\r\n","! pip install SpeechRecognition"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n7vpoNdOlRRK"},"source":["Instructions\r\n","<ul>\r\n","<li>Import the <code>speech_recognition</code> library as <code>sr</code>.</li>\r\n","<li>Setup an instance of the <code>Recognizer</code> class and save it to <code>recognizer</code>.</li>\r\n","<li>Set the <code>recognizer.energy_threshold</code> to 300.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"id":"w48_1NTN8ASP","executionInfo":{"status":"ok","timestamp":1616010731931,"user_tz":180,"elapsed":551,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}},"source":["# Importing the speech_recognition library\r\n","import speech_recognition as sr\r\n","\r\n","# Create an instance of the Recognizer class\r\n","recognizer = sr.Recognizer()\r\n","\r\n","# Set the energy threshold\r\n","recognizer.energy_threshold = 300"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aFRKB4T9leFO"},"source":["### Using the Recognizer class"]},{"cell_type":"markdown","metadata":{"id":"XQ1r0kfUlhB3"},"source":["<div class=\"\"><p>Now you've created an instance of the <code>Recognizer</code> class we'll use the <code>recognize_google()</code> method on it to access the Google web speech API and turn spoken language into text.</p>\r\n","<p><code>recognize_google()</code> requires an argument <code>audio_data</code> otherwise it will return an error.</p>\r\n","<p>US English is the default language. If your audio file isn't in US English, you can change the language with the <code>language</code> argument. A list of language codes can be seen <a href=\"https://cloud.google.com/speech-to-text/docs/languages\" target=\"_blank\" rel=\"noopener noreferrer\">here</a>.</p>\r\n","<p>An audio file containing English speech has been imported as <code>clean_support_call_audio</code>. You can <a href=\"https://assets.datacamp.com/production/repositories/4637/datasets/393a2f76d057c906de27ec57ea655cb1dc999fce/clean-support-call.wav\" target=\"_blank\" rel=\"noopener noreferrer\">listen to the audio file here</a>. SpeechRecognition has also been imported as <code>sr</code>.</p>\r\n","<p>To avoid hitting the API request limit of Google's web API, we've mocked the <code>Recognizer</code> class to work with our audio files. This means some functionality will be limited.</p></div>"]},{"cell_type":"code","metadata":{"id":"Y1-s4kusyGCd","executionInfo":{"status":"ok","timestamp":1616011366870,"user_tz":180,"elapsed":1479,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}},"source":["%%capture\r\n","!wget https://github.com/lnunesAI/Datacamp/raw/main/3-skill-tracks/spoken-language-processing-in-python/data/clean-support-call.wav"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"r6z-O2FuyQ1Q","executionInfo":{"status":"ok","timestamp":1616011479338,"user_tz":180,"elapsed":542,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}},"source":["clean_support_call = sr.AudioFile(\"clean-support-call.wav\")\r\n","with clean_support_call as source:\r\n","    clean_support_call_audio = recognizer.record(clean_support_call)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YQQ3ViW9llyQ"},"source":["Instructions\r\n","<ul>\r\n","<li>Call the <code>recognize_google()</code> method on <code>recognizer</code> and pass it <code>clean_support_call_audio</code>.</li>\r\n","<li>Set the language argument to <code>\"en-US\"</code>.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"id":"zPdkd25Ol_mQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616011490698,"user_tz":180,"elapsed":1584,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"96010b6e-5a01-4c6a-87fd-d841cfae9927"},"source":["# Create a recognizer class\r\n","recognizer = sr.Recognizer()\r\n","\r\n","# Transcribe the support call audio\r\n","text = recognizer.recognize_google(\r\n","  audio_data=clean_support_call_audio, \r\n","  language=\"en-US\")\r\n","\r\n","print(text)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["hello I'd like to get some help setting up my account please\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9sMbAVFYmJsc"},"source":["**You just transcribed your first piece of audio using speech_recognition's Recognizer class! Well, we've set it a mock version of Recognizer so we don't hit the API max requests limit. Notice how the 'hello' wasn't seperate from the rest of the text. As powerful as recognize_google() is, it doesn't have sentence separation.**"]},{"cell_type":"markdown","metadata":{"id":"LW8ADyp8mVI2"},"source":["## Reading audio files with SpeechRecognition"]},{"cell_type":"markdown","metadata":{"id":"OQ0TZ6Fy35Q2"},"source":["### From AudioFile to AudioData"]},{"cell_type":"markdown","metadata":{"id":"3t90NkpK373O"},"source":["<div class=\"\"><p>As you saw earlier, there are some transformation steps we have to take to make our audio data useful. The same goes for SpeechRecognition. </p>\r\n","<p>In this exercise, we'll import the <code>clean_support_call.wav</code> <a href=\"https://assets.datacamp.com/production/repositories/4637/datasets/393a2f76d057c906de27ec57ea655cb1dc999fce/clean-support-call.wav\" target=\"_blank\" rel=\"noopener noreferrer\">audio file</a> and get it ready to be recognized.</p>\r\n","<p>We first read our audio file using the <code>AudioFile</code> class. But the <code>recognize_google()</code> method requires an input of type <code>AudioData</code>.</p>\r\n","<p>To convert our <code>AudioFile</code> to <code>AudioData</code>, we'll use the <code>Recognizer</code> class's method <code>record()</code> along with a context manager. The <code>record()</code> method takes an <code>AudioFile</code> as input and converts it to <code>AudioData</code>, ready to be used with <code>recognize_google()</code>.</p>\r\n","<p>SpeechRecognition has already been imported as <code>sr</code>.</p></div>"]},{"cell_type":"markdown","metadata":{"id":"0OE3hGGb3-vw"},"source":["Instructions\r\n","<ul>\r\n","<li>Pass the AudioFile class <code>clean_support_call.wav</code>.</li>\r\n","<li>Use the context manager to open and read <code>clean_support_call</code> as <code>source</code>.</li>\r\n","<li>Record <code>source</code> and run the code.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"id":"wgDDTqDK4Fua","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616011570259,"user_tz":180,"elapsed":1339,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"c1d0df77-fdd6-45f9-ea1c-75ef23ea29be"},"source":["# Instantiate Recognizer\r\n","recognizer = sr.Recognizer()\r\n","\r\n","# Convert audio to AudioFile\r\n","clean_support_call = sr.AudioFile(\"clean-support-call.wav\")\r\n","\r\n","# Convert AudioFile to AudioData\r\n","with clean_support_call as source:\r\n","    clean_support_call_audio = recognizer.record(clean_support_call)\r\n","\r\n","# Transcribe AudioData to text\r\n","text = recognizer.recognize_google(clean_support_call_audio,\r\n","                                   language=\"en-US\")\r\n","print(text)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["hello I'd like to get some help setting up my account please\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sTz4xOMc4J1s"},"source":["**You've gone end to end with SpeechRecognition, you've imported an audio file, converted it to the right data type and transcribed it using Google's free web API! Now let's see a few more capabilities of the record() method.**"]},{"cell_type":"markdown","metadata":{"id":"WnplbyjV4MIz"},"source":["### Recording the audio we need"]},{"cell_type":"markdown","metadata":{"id":"7hz2dKb14Ous"},"source":["<div class=\"\"><p>Sometimes you may not want the entire audio file you're working with. The <code>duration</code> and <code>offset</code> parameters of the <code>record()</code> method can help with this.</p>\r\n","<p>After exploring your dataset, you find there's one file, imported as <code>nothing_at_end</code> which has <a href=\"https://assets.datacamp.com/production/repositories/4637/datasets/ca799cf2a7b093c06e1a5ae1dd96a49d48d65efa/30-seconds-of-nothing-16k.wav\" target=\"_blank\" rel=\"noopener noreferrer\">30-seconds of silence at the end</a> and a support call file, imported as <code>out_of_warranty</code> has <a href=\"https://assets.datacamp.com/production/repositories/4637/datasets/dbc47d8210fdf8de42b0da73d1c2ba92e883b2d2/static-out-of-warranty.wav\" target=\"_blank\" rel=\"noopener noreferrer\">3-seconds of static at the front</a>.</p>\r\n","<p>Setting <code>duration</code> and <code>offset</code> means the <code>record()</code> method will record up to <code>duration</code> audio starting at <code>offset</code>. They're both measured in seconds.</p></div>"]},{"cell_type":"code","metadata":{"id":"4Go-EcmKzk6Z","executionInfo":{"status":"ok","timestamp":1616011837643,"user_tz":180,"elapsed":2785,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}},"source":["%%capture\r\n","!wget https://github.com/lnunesAI/Datacamp/raw/main/3-skill-tracks/spoken-language-processing-in-python/data/30-seconds-of-nothing-16k.wav\r\n","!wget https://github.com/lnunesAI/Datacamp/raw/main/3-skill-tracks/spoken-language-processing-in-python/data/static-out-of-warranty.wav"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z9X8r9qWzqvT","executionInfo":{"status":"ok","timestamp":1616011879563,"user_tz":180,"elapsed":543,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}},"source":["nothing_at_end = sr.AudioFile(\"30-seconds-of-nothing-16k.wav\")\r\n","static_at_start = sr.AudioFile(\"static-out-of-warranty.wav\")"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"938RpfwX4RDG"},"source":["Instructions 1/2\r\n","<p>Let's get the first 10-seconds of <code>nothing_at_end_audio</code>. To do this, you can set <code>duration</code> to 10.</p>"]},{"cell_type":"code","metadata":{"id":"RSz_6Br64d6B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616011886753,"user_tz":180,"elapsed":2248,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"38ba43cc-6c0e-4cc6-f6ac-7ca351fa9315"},"source":["# Convert AudioFile to AudioData\r\n","with nothing_at_end as source:\r\n","    nothing_at_end_audio = recognizer.record(source,\r\n","                                             duration=10,\r\n","                                             offset=None)\r\n","\r\n","# Transcribe AudioData to text\r\n","text = recognizer.recognize_google(nothing_at_end_audio,\r\n","                                   language=\"en-US\")\r\n","\r\n","print(text)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["this ODI fall has 30 seconds of nothing at the end of it\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y33AUgoQ0SbH"},"source":["\"ODI\" = It would be \"audio\""]},{"cell_type":"markdown","metadata":{"id":"2sVirp8S4RDG"},"source":["Instructions 2/2\r\n","<p>Let's remove the first 3-seconds of static of <code>static_at_start</code> by setting <code>offset</code> to 3.</p>"]},{"cell_type":"code","metadata":{"id":"KBhxHm2N4r49","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616011959831,"user_tz":180,"elapsed":1605,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"adcb1e1f-8d55-42a9-df19-dedab99ba199"},"source":["# Convert AudioFile to AudioData\r\n","with static_at_start as source:\r\n","    static_art_start_audio = recognizer.record(source,\r\n","                                               duration=None,\r\n","                                               offset=3)\r\n","\r\n","# Transcribe AudioData to text\r\n","text = recognizer.recognize_google(static_art_start_audio,\r\n","                                   language=\"en-US\")\r\n","\r\n","print(text)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["hello I'd like to get some help with my device please I think it's out of warranty I bought it about 2 years ago\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e86LLy2a4yDH"},"source":["**Speech recognition can be resource intensive, so in practice, you'll want to explore your audio files to make you're not wasting any compute power trying to transcribe static or silence.**"]},{"cell_type":"markdown","metadata":{"id":"32-9oOq340zQ"},"source":["## Dealing with different kinds of audio"]},{"cell_type":"markdown","metadata":{"id":"bN8XyBGmjMt-"},"source":["### Different kinds of audio"]},{"cell_type":"markdown","metadata":{"id":"TYvcF54sjQZX"},"source":["<div class=\"\"><p>Now you've seen an example of how the <code>Recognizer</code> class works. Let's try a few more. How about speech from a different language?</p>\r\n","<p>What do you think will happen when we call the <code>recognize_google()</code> function on a <a href=\"https://assets.datacamp.com/production/repositories/4637/datasets/cd9b801670d0664275cdbd3a24b6b70a8c2e5222/good-morning-japanense.wav\" target=\"_blank\" rel=\"noopener noreferrer\">Japanese version of <code>good_morning.wav</code></a> (<code>japanese_audio</code>)? </p>\r\n","<p>The default language is <code>\"en-US\"</code>, are the results the same with the <code>\"ja\"</code> tag?</p>\r\n","<p>How about non-speech audio? Like this <a href=\"https://assets.datacamp.com/production/repositories/4637/datasets/5720832b2735089d8e735cac3e0b0ad9b5114864/leopard.wav\" target=\"_blank\" rel=\"noopener noreferrer\">leopard roaring</a> (<code>leopard_audio</code>).</p>\r\n","<p>Or speech where the sounds may not be real words, such as <a href=\"https://assets.datacamp.com/production/repositories/4637/datasets/e9fd46a06d74431e3baa942c489e1b119d85a233/charlie-bit-me-5.wav\" target=\"_blank\" rel=\"noopener noreferrer\">a baby talking</a> (<code>charlie_audio</code>)?</p>\r\n","<p>To familiarize more with the <code>Recognizer</code> class, we'll look at an example of each of these.</p></div>"]},{"cell_type":"code","metadata":{"id":"hkJLgfVZ07cC","executionInfo":{"status":"ok","timestamp":1616012162445,"user_tz":180,"elapsed":3243,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}},"source":["%%capture\r\n","!wget https://github.com/lnunesAI/Datacamp/raw/main/3-skill-tracks/spoken-language-processing-in-python/data/good-morning-japanense.wav\r\n","!wget https://github.com/lnunesAI/Datacamp/raw/main/3-skill-tracks/spoken-language-processing-in-python/data/leopard.wav\r\n","!wget https://github.com/lnunesAI/Datacamp/raw/main/3-skill-tracks/spoken-language-processing-in-python/data/charlie-bit-me-5.wav"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"gaz-xo191LBP","executionInfo":{"status":"ok","timestamp":1616012467558,"user_tz":180,"elapsed":549,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}},"source":["japanese_audio = sr.AudioFile(\"good-morning-japanense.wav\")\r\n","leopard_audio = sr.AudioFile(\"leopard.wav\")\r\n","charlie_audio = sr.AudioFile(\"charlie-bit-me-5.wav\")\r\n","\r\n","with japanese_audio, leopard_audio, charlie_audio as source:\r\n","    japanese_audio = recognizer.record(japanese_audio)\r\n","    leopard_audio = recognizer.record(leopard_audio)\r\n","    charlie_audio = recognizer.record(charlie_audio)"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z9a7LfvdjUm2"},"source":["Instructions 1/4\r\n","<p>Pass the Japanese version of good morning (<code>japanese_audio</code>) to <code>recognize_google()</code> using <code>\"en-US\"</code> as the language.</p>"]},{"cell_type":"code","metadata":{"id":"PFWTI38UjnmQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616012429065,"user_tz":180,"elapsed":1150,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"427e4e32-415c-47af-f722-dc61c6024bde"},"source":["# Create a recognizer class\r\n","recognizer = sr.Recognizer()\r\n","\r\n","# Pass the Japanese audio to recognize_google\r\n","text = recognizer.recognize_google(japanese_audio, language=\"en-US\")\r\n","\r\n","# Print the text\r\n","print(text)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["ohayo gozaimasu\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Cy7PwdDYjUm3"},"source":["Instructions 2/4\r\n","<p>Pass the same Japanese audio (<code>japanese_audio</code>) using <code>\"ja\"</code> as the language parameter. Do you see a difference?</p>"]},{"cell_type":"code","metadata":{"id":"Xl6pMbFSjr9g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616012474376,"user_tz":180,"elapsed":1130,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"58fa7788-f339-4c9e-f825-443303df4d5e"},"source":["# Create a recognizer class\r\n","recognizer = sr.Recognizer()\r\n","\r\n","# Pass the Japanese audio to recognize_google\r\n","text = recognizer.recognize_google(japanese_audio, language=\"ja\")\r\n","\r\n","# Print the text\r\n","print(text)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["おはようございます\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ugyt6TRnjUm4"},"source":["Instructions 3/4\r\n","<p>What about about non-speech audio? Pass <code>leopard_audio</code> to <code>recognize_google()</code> with <code>show_all</code> as <code>True</code>.</p>"]},{"cell_type":"code","metadata":{"id":"P7FR8IVVj1Ba","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616012477498,"user_tz":180,"elapsed":899,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"65adc91b-7baf-4fe5-b309-30c49ebc3f66"},"source":["# Create a recognizer class\r\n","recognizer = sr.Recognizer()\r\n","\r\n","# Pass the leopard roar audio to recognize_google\r\n","text = recognizer.recognize_google(leopard_audio, \r\n","                                   language=\"en-US\", \r\n","                                   show_all=True)\r\n","\r\n","# Print the text\r\n","print(text)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["[]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GaaV8bFsjUm5"},"source":["Instructions 4/4\r\n","<p>What if your speech files have non-audible human sounds? Pass <code>charlie_audio</code> to <code>recognize_google()</code> to find out.</p>"]},{"cell_type":"code","metadata":{"id":"ePl06KKMj41s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616012482430,"user_tz":180,"elapsed":3183,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"3adee2cd-ddd6-48a5-c373-587555e37bc5"},"source":["# Create a recognizer class\r\n","recognizer = sr.Recognizer()\r\n","\r\n","# Pass charlie_audio to recognize_google\r\n","text = recognizer.recognize_google(charlie_audio, \r\n","                                   language=\"en-US\")\r\n","\r\n","# Print the text\r\n","print(text)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["charlie bit me\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"we06smqej_R0"},"source":["**You've seen how the recognize_google() deals with different kinds of audio. It's worth noting the recognize_google() function is only going to return words, as in, it didn't return the baby saying 'ahhh!' because it doesn't recognize it as a word. Speech recognition has come a long way but it's far from perfect.**"]},{"cell_type":"markdown","metadata":{"id":"8_45sN3bkN-6"},"source":["### Multiple Speakers 1"]},{"cell_type":"markdown","metadata":{"id":"YSxO45txkRGL"},"source":["<div class=\"\"><p>If your goal is to transcribe conversations, there will be more than one speaker. However, as you'll see, the <code>recognize_google()</code> function will only transcribe speech into a single block of text.</p>\r\n","<p>You can hear in <a href=\"https://assets.datacamp.com/production/repositories/4637/datasets/925c8c31d6e4af9c291c692f13e4f41c7b5e86b2/multiple-speakers-16k.wav\" target=\"_blank\" rel=\"noopener noreferrer\">this audio file</a> there are three different speakers.</p>\r\n","<p>But if you transcribe it on its own, <code>recognize_google()</code> returns a single block of text. Which is still useful but it doesn't let you know which speaker said what.</p>\r\n","<p>We'll see an alternative to this in the next exercise.</p>\r\n","<p>The multiple speakers audio file has been imported and converted to <code>AudioData</code> as <code>multiple_speakers</code>.</p></div>"]},{"cell_type":"code","metadata":{"id":"wBsLeI3O2rAs","executionInfo":{"status":"ok","timestamp":1616012617909,"user_tz":180,"elapsed":1366,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}},"source":["%%capture\r\n","!wget https://github.com/lnunesAI/Datacamp/raw/main/3-skill-tracks/spoken-language-processing-in-python/data/multiple-speakers-16k.wav"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kf7rFYtz2-Qh","executionInfo":{"status":"ok","timestamp":1616012663145,"user_tz":180,"elapsed":547,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}},"source":["multiple_speakers = sr.AudioFile(\"multiple-speakers-16k.wav\")\r\n","with multiple_speakers as source:\r\n","    multiple_speakers = recognizer.record(multiple_speakers)"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WfZzQX9x2tbE"},"source":["Instructions\r\n","<ul>\r\n","<li>Create an instance of <code>Recognizer</code>.</li>\r\n","<li>Recognize the <code>multiple_speakers</code> variable using the <code>recognize_google()</code> function.</li>\r\n","<li>Set the language to US English (<code>\"en-US\"</code>).</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"id":"g98Tmws4kY6d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616012667855,"user_tz":180,"elapsed":2591,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"5a5442f7-f882-4784-b429-15b1e8740196"},"source":["# Create a recognizer class\r\n","recognizer = sr.Recognizer()\r\n","\r\n","# Recognize the multiple speaker AudioData\r\n","text = recognizer.recognize_google(multiple_speakers, \r\n","                       \t\t\t   language=\"en-US\")\r\n","\r\n","# Print the text\r\n","print(text)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["is that it doesn't recognize different speakers invoices it will just return it all as one block of text\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sdeyLUiw4crl"},"source":["one of the limitations of the speech recognition..."]},{"cell_type":"markdown","metadata":{"id":"s5MlmQtvkcWu"},"source":["**But see how all of the speakers speech came out in one big block of text?**"]},{"cell_type":"markdown","metadata":{"id":"3mTJmNbAkojT"},"source":["### Multiple Speakers 2"]},{"cell_type":"markdown","metadata":{"id":"ejW84xZ7kxlU"},"source":["<div class=\"\"><p>Deciphering between multiple speakers in one audio file is called speaker diarization. However, you've seen the free function we've been using, <code>recognize_google()</code> doesn't have the ability to transcribe different speakers. </p>\r\n","<p>One way around this, without using one of the paid speech to text services, is to ensure your audio files are single speaker.</p>\r\n","<p>This means if you were working with phone call data, you would make sure the caller and receiver are recorded separately. Then you could transcribe each file individually.</p>\r\n","<p>In this exercise, we'll transcribe each of the speakers in our <a href=\"https://assets.datacamp.com/production/repositories/4637/datasets/925c8c31d6e4af9c291c692f13e4f41c7b5e86b2/multiple-speakers-16k.wav\" target=\"_blank\" rel=\"noopener noreferrer\">multiple speakers audio file</a> individually.</p></div>"]},{"cell_type":"code","metadata":{"id":"bG_GIIO73whJ","executionInfo":{"status":"ok","timestamp":1616012892892,"user_tz":180,"elapsed":3147,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}},"source":["%%capture\r\n","!wget https://github.com/lnunesAI/Datacamp/raw/main/3-skill-tracks/spoken-language-processing-in-python/data/speaker_0.wav\r\n","!wget https://github.com/lnunesAI/Datacamp/raw/main/3-skill-tracks/spoken-language-processing-in-python/data/speaker_1.wav\r\n","!wget https://github.com/lnunesAI/Datacamp/raw/main/3-skill-tracks/spoken-language-processing-in-python/data/speaker_2.wav"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mLQ2YYNRkzUt"},"source":["Instructions\r\n","<ul>\r\n","<li>Pass <code>speakers</code> to the <code>enumerate()</code> function to loop through the different speakers.</li>\r\n","<li>Call <code>record()</code> on <code>recognizer</code> to convert the <code>AudioFile</code>s into <code>AudioData</code>.</li>\r\n","<li>Use <code>recognize_google()</code> to transcribe each of the <code>speaker_audio</code> objects.</li>\r\n","</ul>"]},{"cell_type":"code","metadata":{"id":"ZsWR3EphlFOj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616012903144,"user_tz":180,"elapsed":3515,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"02d2cb6b-1d9e-435d-8bca-e4b62ce06e92"},"source":["recognizer = sr.Recognizer()\r\n","\r\n","# Multiple speakers on different files\r\n","speakers = [sr.AudioFile(\"speaker_0.wav\"), \r\n","            sr.AudioFile(\"speaker_1.wav\"), \r\n","            sr.AudioFile(\"speaker_2.wav\")]\r\n","\r\n","# Transcribe each speaker individually\r\n","for i, speaker in enumerate(speakers):\r\n","    with speaker as source:\r\n","        speaker_audio = recognizer.record(source)\r\n","    print(f\"Text from speaker {i}:\")\r\n","    print(recognizer.recognize_google(speaker_audio,\r\n","         \t\t\t\t  language=\"en-US\"))"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Text from speaker 0:\n","one of the limitations of the speech recognition Lottery\n","Text from speaker 1:\n","is that it doesn't recognize different speakers invoices\n","Text from speaker 2:\n","I'll just return it all as one block a text\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3G8Oduh94fh2"},"source":["Lottery..."]},{"cell_type":"markdown","metadata":{"id":"sCVkoF1HlNmt"},"source":["**Something to remember is I had to manually split the audio file into different speakers. You can see this solution still isn't perfect but it's easier to deal with than having a single block of text. You could think about automating this process in the future by having a model split the audio when it detects different speakers.**"]},{"cell_type":"markdown","metadata":{"id":"-NHN4fbflRxX"},"source":["### Working with noisy audio"]},{"cell_type":"markdown","metadata":{"id":"L8iIbF7_lUbf"},"source":["<div class=\"\"><p>In this exercise, we'll start by transcribing a clean speech sample to text and then see what happens when we add some background noise.</p>\r\n","<p>A clean audio sample has been imported as <code>clean_support_call</code>.</p>\r\n","<p><a href=\"https://assets.datacamp.com/production/repositories/4637/datasets/393a2f76d057c906de27ec57ea655cb1dc999fce/clean-support-call.wav\" target=\"_blank\" rel=\"noopener noreferrer\">Play clean support call</a>.</p>\r\n","<p>We'll then do the same with the noisy audio file saved as <code>noisy_support_call</code>. It has the same speech as <code>clean_support_call</code> but with additional background noise.</p>\r\n","<p><a href=\"https://assets.datacamp.com/production/repositories/4637/datasets/f3edd5024944eac2f424b592840475890c86d405/2-noisy-support-call.wav\" target=\"_blank\" rel=\"noopener noreferrer\">Play noisy support call</a>.</p>\r\n","<p>To try and negate the background noise, we'll take advantage of <code>Recognizer</code>'s <code>adjust_for_ambient_noise()</code> function.</p></div>"]},{"cell_type":"markdown","metadata":{"id":"LckiZaq2lXPH"},"source":["Instructions 1/4\r\n","<p>Let's transcribe some clean audio. Read in <code>clean_support_call</code> as the source and call <code>recognize_google()</code> on the file.</p>"]},{"cell_type":"code","metadata":{"id":"-iMglkrOltGH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616013064530,"user_tz":180,"elapsed":1412,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"d19fd947-cb19-4ae8-93c9-1702d5497853"},"source":["recognizer = sr.Recognizer()\r\n","\r\n","# Record the audio from the clean support call\r\n","with clean_support_call as source:\r\n","  clean_support_call_audio = recognizer.record(clean_support_call)\r\n","\r\n","# Transcribe the speech from the clean support call\r\n","text = recognizer.recognize_google(clean_support_call_audio,\r\n","\t\t\t\t\t   language=\"en-US\")\r\n","\r\n","print(text)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["hello I'd like to get some help setting up my account please\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yPAmq_QQlXPI"},"source":["Instructions 2/4\r\n","<p>Let's do the same as before but with a noisy audio file saved as <code>noisy_support_call</code> and <code>show_all</code> parameter as <code>True</code>.</p>"]},{"cell_type":"code","metadata":{"id":"c7M4BWWM5FVw","executionInfo":{"status":"ok","timestamp":1616013203107,"user_tz":180,"elapsed":1161,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}}},"source":["%%capture\r\n","!wget https://github.com/lnunesAI/Datacamp/raw/main/3-skill-tracks/spoken-language-processing-in-python/data/2-noisy-support-call.wav\r\n","noisy_support_call = sr.AudioFile(\"2-noisy-support-call.wav\")"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"xQOTru8Jl_eU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616013208453,"user_tz":180,"elapsed":3005,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"06d7810c-2a99-49e4-d9ec-bd3d313e9f3a"},"source":["recognizer = sr.Recognizer()\r\n","\r\n","# Record the audio from the noisy support call\r\n","with noisy_support_call as source:\r\n","  noisy_support_call_audio = recognizer.record(noisy_support_call)\r\n","\r\n","# Transcribe the speech from the noisy support call\r\n","text = recognizer.recognize_google(noisy_support_call_audio,\r\n","                         language=\"en-US\",\r\n","                         show_all=True)\r\n","\r\n","print(text)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["{'alternative': [{'transcript': \"hello I'd like to get to help setting up my account\", 'confidence': 0.89570123}, {'transcript': \"hello I'd like to get some help setting up my account\"}, {'transcript': \"hello I'd like to get to help thinning out my account\"}, {'transcript': \"hello I'd like to get to help setting up my calendar\"}, {'transcript': \"hello I'd like to get to help setting up my account.\"}], 'final': True}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DiaGk5AalXPI"},"source":["Instructions 3/4\r\n","<p>Set the <code>duration</code> parameter of <code>adjust_for_ambient_noise()</code> to 1 (second) so <code>recognizer</code> adjusts for background noise.</p>"]},{"cell_type":"code","metadata":{"id":"Ycyvt2FGmOux","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616013254427,"user_tz":180,"elapsed":2952,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"7436e665-03d1-42e7-f34c-d0bf1e260848"},"source":["recognizer = sr.Recognizer()\r\n","\r\n","# Record the audio from the noisy support call\r\n","with noisy_support_call as source:\r\n","\t# Adjust the recognizer energy threshold for ambient noise\r\n","    recognizer.adjust_for_ambient_noise(source, duration=1)\r\n","    noisy_support_call_audio = recognizer.record(noisy_support_call)\r\n"," \r\n","# Transcribe the speech from the noisy support call\r\n","text = recognizer.recognize_google(noisy_support_call_audio,\r\n","                                   language=\"en-US\",\r\n","                                   show_all=True)\r\n","\r\n","print(text)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["{'alternative': [{'transcript': \"I'd like to get to help setting up my account\", 'confidence': 0.83045131}, {'transcript': \"I'd like to get to help setting up my calendar\"}, {'transcript': \"I'd like to get to help setting up my account.\"}, {'transcript': \"I'd like to get some help setting up my account\"}, {'transcript': \"I'd like to get to help thinning out my account\"}], 'final': True}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TYikSEh7lXPI"},"source":["Instructions 4/4\r\n","<p>A <code>duration</code> of 1 was too long and it cut off some of the audio. Try setting <code>duration</code> to 0.5.</p>"]},{"cell_type":"code","metadata":{"id":"5TjH-eTkmY3k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616013276775,"user_tz":180,"elapsed":4087,"user":{"displayName":"Lucas Nunes","photoUrl":"","userId":"13884079641685385195"}},"outputId":"2d7b842a-5e6d-4011-fecf-82bf5098ebe4"},"source":["recognizer = sr.Recognizer()\r\n","\r\n","# Record the audio from the noisy support call\r\n","with noisy_support_call as source:\r\n","\t# Adjust the recognizer energy threshold for ambient noise\r\n","    recognizer.adjust_for_ambient_noise(source, duration=0.5)\r\n","    noisy_support_call_audio = recognizer.record(noisy_support_call)\r\n"," \r\n","# Transcribe the speech from the noisy support call\r\n","text = recognizer.recognize_google(noisy_support_call_audio,\r\n","                                   language=\"en-US\",\r\n","                                   show_all=True)\r\n","\r\n","print(text)"],"execution_count":48,"outputs":[{"output_type":"stream","text":["{'alternative': [{'transcript': \"hello I'd like to get to help setting up my account\", 'confidence': 0.90365565}, {'transcript': \"hello I'd like to get to help setting up my calendar\"}, {'transcript': \"hello I'd like to get to help setting up my account.\"}, {'transcript': \"hello I'd like to get to help setting up my calculator\"}, {'transcript': \"hello I'd like to get to help setting up my account page\"}], 'final': True}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"42BY898jmhaV"},"source":["**Well, the results still weren't perfect. This should be expected with some audio files though, sometimes the background noise is too much. If your audio files have a large amount of background noise, you may need to preprocess them with an audio tool such as Audacity before using them with speech_recognition.**"]}]}